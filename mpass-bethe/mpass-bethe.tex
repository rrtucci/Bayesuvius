\chapter{Message Passing, Bethe's theory
(COMING SOON)}
\label{ch-mpass-bethe}

\newcommand{\ttheta}[0]{\TIL{\theta}}
\newcommand{\tP}[0]{\TIL{p}}

This chapter is based
on Refs. \cite{WainJordan}
and \cite{yedidia}.

\section{Pairwise MRFs and Message Passing}





\begin{figure}[h!]
$$\xymatrix{
&*+[F]{\Delta}
&
&*+[F]{\Delta}
&
&*+[F]{\Delta}
\\
*++[o][F]{x_{11}}
\ar@{-}[d]\ar@{-}[r]\ar@{-}[ru]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_{12}}\ar@{-}[d]\ar@{-}[r]
\ar@{-}[ru]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_{13}}\ar@{-}[d]
\ar@{-}[ru]
\\
*+[F]{\Delta}\ar@{-}[d]
&*+[F]{\Delta}
&*+[F]{\Delta}\ar@{-}[d]
&*+[F]{\Delta}
&*+[F]{\Delta}\ar@{-}[d]
&*+[F]{\Delta}
\\
*++[o][F]{x_{21}}\ar@{-}[r]\ar@{-}[ru]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_{22}}\ar@{-}[r]\ar@{-}[ru]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_{23}}\ar@{-}[ru]
}$$
\caption{Example
of factor graph
for a pairwise MRF.
In this figure,
a boxed $\Delta$
between variables $x_i$
and $x_j$,
denotes the function
$\Delta(x_i, x_j)$.
Also, a boxed
$\Delta$
connected to a
single variable $x_i$,
denotes the function
$\Delta(x_i, k)$,
where $k$
is a fixed number.
}
\label{fig-paiwise-mrf}
\end{figure}

Factor graphs
are discussed in Chapter \ref{ch-factor-g}.

A pairwise
Markov Random Field (MRF)
is a statistical model 
whose probability
distribution
is of the form

\beq
p(x)=\caln(!x)\prod_{i-j}\Delta(x_i, x_j)
\label{eq-pairwise-fg}
\eeq
where $x=(x_1, x_2,
\ldots, x_n )$,
where $i-j$
represents the edge
that connects
nodes $i$ and $j$
in an undirected graph $G$,
and where  the product 
is over all edges of $G$.
$G$ can be represented
graphically
by a factor graph.
Fig.\ref{fig-paiwise-mrf}
shows an example
of a pairwise
MRF
and its
representation as a
factor graph.

Note that a bnet can
be easily converted to an
equivalent
bipartite MRF.
You just
set $\Delta(x_i, k)=p(x_i)$
if $x_i$ is a root node
of the bnet,
and $\Delta(x_i, x_j)=p(x_i|x_j) $
if $x_i$ isn't a root node.
Of course, one
must choose
the arrow directions
of the resulting
graph
so that the final
choices assure
that the bnet
is acyclic.

In what follows,
we shall use
{\bf messages (a.k.a. cavity fields)}
 $m_{a\rdart i}(x_i)$,
Note
that in our
notation
for messages, the letter $i$
appears twice,
and both occurrences
are next to each other.
This is always the case in
our notation for messages.

In what follows,
we shall use the notation
$\partial i$  
to denote indices
$j$ such that
$x_j$ is a 
neighbor of $x_i$.


\begin{enumerate}
\item 
Assume $\Delta(x_i, x_j)$ is known and
the full
probability $p(x)$
of the model
is given by
Eq.(\ref{eq-pairwise-fg}).




\item Calculate $m_{j\rdart i}$
for all 
edges $i-j$ using the recursion
relation

\beq
m_{j\rdart i}^{new}
(x_i) =
\sum_{x_j}
\Delta(x_i, x_j)
\prod_{b\in
\partial j\setminus i}
m_{b\rdart j} (x_j) 
\eeq

\beq
\xymatrix@C=.7pc{
\\
*++[o][F]{x_i}\ar@{-}[r]
&*+[F]{m^{new}_{j\rdart i}(x_i)}
&=\sum_{x_j}
}
\xymatrix@C.7pc{
&&&*+[F]{m_{b_1\rdart j}(x_j)
}
\\
*++[o][F]{x_i}\ar@{-}[r]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_j}\ar@{-}[r]
\ar@{-}[ru]\ar@{-}[rd]
&*+[F]{
m_{b_2\rdart j}(x_j)
}
\\
&&&*+[F]{
m_{b_1\rdart j}(x_j)
}
}
\eeq

\item Calculate $\tP (x_i
, x_j )$ for all edges $i-j$ using 
 
\beq
\tP (x_i
, x_j ) 
=\caln(!x)
 \Delta(x_i
, x_j )
\prod_{a\in \partial i \setminus j}
m_{a\rdart i}(x_i)
\prod_{b\in \partial j \setminus i}
m_{b\rdart j}(x_j)
\eeq

\beq
\xymatrix@C=.7pc{
\\
*++[o][F]{x_i}\ar@{-}[r]
&
*+[F]{\tP}
\ar@{-}[r]
&*++[o][F]{x_j}
&=
\caln(!x)
}
\xymatrix@C.7pc{
*+[F]{m_{a_1\rdart i}(x_i)
}\ar@{-}[dr]
&&&&*+[F]{m_{b_1\rdart j}(x_j)
}
\\
*+[F]{m_{a_2\rdart i}(x_i)
}\ar@{-}[r]
&*++[o][F]{x_i}\ar@{-}[r]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_j}\ar@{-}[r]
\ar@{-}[ru]\ar@{-}[rd]
&*+[F]{
m_{b_2\rdart j}(x_j)
}
\\
*+[F]{m_{a_3\rdart i}(x_i)
}\ar@{-}[ur]
&&&&*+[F]{
m_{b_1\rdart j}(x_j)
}
}
\eeq

\beq
\tP(x_i)=\sum_{x_j}\tP(x_i, x_j)
\eeq
\end{enumerate}

Why it works?

\beq
\Delta(x_i, x_j)
\approx m_{j\rdart i}(x_i)
m_{i\rdart j}(x_j)
\eeq

\beq
\xymatrix@C=.7pc{
*++[o][F]{x_i}\ar@{-}[r]
&*+[F]{\Delta}\ar@{-}[r]
&*++[o][F]{x_j}
&\approx
&*++[o][F]{x_i}\ar@{-}[r]
&*+[F]{m_{j\rdart i}(x_i)}
&*+[F]{m_{i\rdart j}(x_j)}\ar@{-}[r]
&*++[o][F]{x_j}
}
\eeq

\beq 
\tP(x)\approx 
\caln(!x)
\prod_{i-j}
m_{j\rdart i}(x_i)
m_{i\rdart j}(x_j)
\eeq
\begin{enumerate}
\item
\beq 
p(x)\approx 
\tP(x)
\eeq

\item 

\beqa
m_{j\rdart i}^{new}
(x_i) &\approx&
\sum_{x_j}
m_{i\rdart j}(x_j)m_{j\rdart i}(x_i)
\prod_{b\in
\partial j\setminus i}
m_{b\rdart j} (x_j)
\\
&=&
 m_{j\rdart i}(x_i)
 \sum_{x_j}
 \prod_{b\in \partial j}
 m_{b\rdart j} (x_j)
 \\
 &=&
 \caln(!x)
 m_{j\rdart i}(x_i)
\eeqa
\item

\beqa
\tP(x_i, x_j) 
&=&
\sum_{x\setminus x_i, x_j}\tP(x)
\\
&\approx&
\caln(!x)
\sum_{x\setminus x_i, x_j}
\prod_{i-j}
m_{j\rdart i}(x_i)
m_{i\rdart j}(x_j)
\\
&\approx &
\caln(!x)
 \Delta(x_i
, x_j )
\prod_{a\in \partial i \setminus j}
m_{a\rdart i}(x_i)
\prod_{b\in \partial j \setminus i}
m_{b\rdart j}(x_j)
\eeqa
\end{enumerate}

More compressed notation
pairwise MRF factor graph.
Instead of using
circles for variables
and squares for functions,
we use two labeled arrows between two
nodes $x_1, x_2$.
\beq
\xymatrix@C=.7pc{
*++[o][F]{x_1}\ar@{-}[r]
&*+[F]{m_{2\rdart 1}(x_1)}
&*+[F]{m_{1\rdart 2}(x_2)}\ar@{-}[r]
&*++[o][F]{x_2}
}
=\quad
\xymatrix@C=4pc{
x_1\ar@<1ex>[r]^{m_{1\rdart 2}(x_2)}
&x_2\ar@<1ex>[l]^{m_{2\rdart 1}(x_1)}
}
\eeq

How it works?
Next, we give an 
example
of how message 
passing
works. Refer to
Fig\ref{fig-mp-3node-example}
for this example.

\begin{figure}[h!]
$$\xymatrix@C=5pc{
&&x_3\ar@<1ex>[ld]^{m_{3\rdart 2}(x_2)}
\\
x_1\ar@<1ex>[r]^{m_{1\rdart 2}(x_2)}
&x_2\ar@<1ex>[l]^{m_{2\rdart 1}(x_1)}
\ar@<1ex>[ru]^{m_{2\rdart 3}(x_3)}
\ar@<1ex>[rd]^{m_{2\rdart 4}(x_4)}
\\
&&x_4\ar@<1ex>[lu]^{m_{4\rdart 2}(x_2)}
}$$
\caption{
Example of compressed factor graph 
for a pairwise MRF.}
\label{fig-mp-3node-example}
\end{figure}

\begin{align}
\tP(x_1)
&=
\caln(!x)m_{2\rdart 1}(x_1)
\\
&=
\caln(!x)
\sum_{x_2}
\Delta(x_1,x_2)
m_{3\rdart 2}(x_2)
m_{4\rdart 2}(x_2)
\\
&=
\caln(!x)
\sum_{x_2}
\Delta(x_1,x_2)
\sum_{x_3}
\Delta(x_2,x_3)
\sum_{x_4}
\Delta(x_2, x_4)
\end{align}





\section{ $-\ln Z_\theta$=
Free Energy (FE)}
Define the {\bf partition function} $Z_\theta$ by
\beq
Z_\theta = \sum_x   e^{-\theta^T \calu(x)}
\eeq



\beqa
\underbrace{P(x|\theta)
}_{e^{-\cals_\theta(x)}} &=& 
\exp( -\theta^T \calu (x) - \ln Z_\theta)
\label{eq-px-at-theta}
\\
&=&
\frac{
e^{-\theta^T \calu(x)}}{Z}
\eeqa
$\calu(x)$ is called {\bf sufficient
statistic (SS)} for $\rvx$ because
$P(x|\theta)$
is a functional (i.e.,
a function of a function) of $\calu(x)$.

\beqa
-\partial_{\theta_i} \ln Z_\theta
&=&
\frac{1}{Z_\theta}
\sum_x   
\calu_i(x)
e^{-\theta^T \calu(x)}
\\
&=&
E_{\rvx|\theta}[\calu_i(\rvx)]=\av{\calu_i}
\eeqa


\begin{align}
\partial_{\theta_j}
\partial_{\theta_i} \ln Z_\theta
&=
\partial_{\theta_j}\frac{1}{Z_\theta}
\sum_x   
-\calu_i(x)
e^{-\theta^T \calu(x)}
\\
&=
\left\{
\begin{array}{l}
\frac{1}{Z_\theta}
\sum_x   
\calu_j(x)\calu_i(x)
e^{-\theta^T \calu(x)}
\\
+\frac{-1}{Z_\theta^2}
\left[
\sum_x   
-\calu_j(x)
e^{-\theta^T \calu(x)}
\right]
\left[
\sum_x   
-\calu_i(x)
e^{-\theta^T \calu(x)}
\right]
\end{array}
\right.
\\
&=
\av{\calu_j\calu_i}
-\av{\calu_j}\av{\calu_i}
\\
&=
\av{\calu_j, \calu_i}
\end{align}




\beq
-\cals_\theta(x)= -\theta^T \calu(x) 
-\ln Z_\theta
\eeq
Define the {\bf entropy} $S$ by
\footnote{In Thermodynamics,
the entropy is denoted by the letter
$S$. In Shannon Information
Theory, and elsewhere in this
book, it is denoted by the letter $H$.}

\beqa
S &=& \sum_x
 P(x|\theta)\cals_\theta(x)
 \\
 &=&
 -\sum_x P(x|\theta)\ln P(x|\theta)
\eeqa
Define the {\bf internal energy} $U$ by 
\beq
U = \sum_x P(x|\theta)\calu_\theta(x)
\eeq

\beq
-S=-\theta^T U - \ln Z_\theta
\eeq

\beq
\partial_{U_i} S= \theta_i
\eeq
$S$ is concave.
$S$ and $-\ln Z_\theta=F/T$
are concave dual functions.\footnote{
Concave dual functions
are discussed in Chapter \ref{ch-var-bay-medical}}.

\begin{mdframed}[hidealllines=true,backgroundcolor=gray!10]
{\bf Relationship to Thermodynamics}

In Thermodynamics,
$U$ is the internal energy
and $S$ is the entropy
of a system
at {\bf temperature} $T$.
Define $\theta\in\RR$ to be
the inverse temperature 
\beq
\theta = \frac{1}{T}
\eeq
Define the {\bf free energy} $F$ by
\beqa
F&=& -T \ln Z_\theta
\\
&=&
-T\ln 
\sum_x e^{-\frac{\calu(x)}{T}}
\eeqa
Then

\beq
U-TS = F
\eeq
So the free energy equals
the internal energy minus
the energy held in disordered form.
\end{mdframed}

\section{$-\ln Z_{\theta^*}$=
Minimum FE}


\beq
p(x) = P(x|\theta), 
\;
\tP(x)=P(x|\TIL{\theta})
\eeq

\beqa
0&\leq& D_{KL}(\tP(x))
\parallel p(x))
\\
&=&
\sum_x \tP(x)\ln
\frac{\tP(x)}
{p(x)}
\\
&=&
-\TIL{S}
-\sum_x \tP(x)
\left[
-(\theta)^T\calu(x)-\ln Z_{\theta}
\right]
\\
&=&
-\TIL{S}
+(\theta)^T\TIL{U} + \ln Z_{\theta}
\quad\text{($\TIL{S}, \TIL{U}$ correspond to parameter $\ttheta$)}
\eeqa

\beq
-\ln Z_\theta\leq 
-\TIL{S}
+(\theta)^T\TIL{U}
\eeq

\beq
\theta^*=
\argmin_\theta\left[
-\TIL{S}
+(\theta)^T\TIL{U}\right]
\eeq

Henceforth,
we will refer to
$-\ln Z_\theta$ as the 
{\bf FE (Free Energy)}
and to 
$-\ln Z_{\theta^*}$
as the
{\bf minimum FE}.

Relationship to 
convex dual functions\footnote{Convex dual functions are discussed
in Chapter \ref{ch-var-bay-medical}}

\beq
\TIL{S} = \min_{\theta}\left[
(\theta)^T\TIL{U} + \ln Z_{\theta}\right]
\eeq

\beq
-\ln Z_{\theta}=
\min_{\TIL{U}}\left[
(\theta)^T\TIL{U} -\TIL{S}
\right]
\eeq
$\TIL{S}$ and $-\ln Z_\theta$ are
convex dual functions.

\beq
-\ln Z_{\theta^*}=
(\theta^*)^T\TIL{U} -\TIL{S}
\label{eq-duality-theta-star}
\eeq

\section{$-\ln Z^{tree}_\theta$=Tree FE
(a.k.a. Bethe FE)}

Mean Field approximation, 
variables $x_i$
are independently
distributed: 
\beq
\tP^{ind}(x)=
\prod_
k
\tP(x_k)
\eeq




\beqa
\TIL{S}^{ind}
&=&
-\sum_x\tP(x)\ln \prod_i \tP(x_i)
\\
&=&
-\sum_{x_i} \tP(x_i)\ln \tP(x_i)
\\
&=&
\sum_i \TIL{H}(\rvx_i)
\eeqa

\beq
\tP^{tree}(x)=
\tP^{ind}(x)
\prod_
{i-j}
\frac{
\tP (x_i
, x_j )}{
\tP(x_i)\tP (x_j )}
\label{eq-tP-tree}
\eeq

\beqa
\TIL{S}^{tree}
&=&
\sum_i\TIL{H}(\rvx_i)
-
\sum_{i-j}\sum_{x_i, x_j}
\tP(x_i,x_j)
\ln \frac{\tP(x_i, x_j)}
{\tP(x_i)\tP(xj)}
\\
&=&
\sum_i \TIL{H}(\rvx_i)
-
\sum_{i-j} \TIL{H}(\rvx_i:\rvx_j)
\eeqa

Note that $\TIL{S}^{tree}$
can be write using the
joint entropy $\TIL{H}(\rvx_i, \rvx_j)$
instead of the mutual entropy
$\TIL{H}(\rvx_i:\rvx_j)$.

\beq
\TIL{S}^{tree}=
-\sum_i(d_i-1)\TIL{H}(\rvx_i)
+ \sum_{i-j}\TIL{H}(\rvx_i, \rvx_j)
\eeq
where $d_i$
is the number of neighbors of node $i$.




{\bf Bethe approximation}

\beq
-\ln Z_{\theta^*}
\approx -\ln Z_{\theta^*}^{tree}
\eeq
In the next section, we 
will evaluate
$ -\ln Z_{\theta^*}^{tree}$
using a message passing ansatz (an
ansatz is an initial guess).


\section{ 
$-\ln Z^{tree}_{\theta^*}$=
Tree Minimum FE,
and message passing}


If we replace $\TIL{S}$ by
$\TIL{S}^{tree}$ in Eq.(\ref{eq-duality-theta-star}),
we get 

\beq
-\ln Z^{tree}_{\theta^*}=\min_{\TIL{U}}\left[
(\theta)^T\TIL{U} -\TIL{S}^{tree}
\right]
\eeq

\beqa
(\theta)^T\TIL{U} &=&
\sum_i \theta_i\sum_x \tP(x)\calu_i(x)
\\
&=&
\sum_x\tP(x)
\underbrace{\sum_i \theta_i \calu_i(x)}
_{\text{ call } \Theta(x)}
\eeqa

\beq
-\ln Z^{tree}_{\theta^*}=
\min_{\tP}\left[
\sum_x \tP(x)\Theta(x)
-\sum_i\TIL{H}(\rvx_i)
+\sum_{i-j}\TIL{H}(\rvx_i:\rvx_j)
\right]
\eeq
subject to $\sum_x \tP(x)=1$.

\begin{claim}
$-\ln Z^{tree}_{\theta^*}$
is achieved if

\beq
\tP(x) = \caln(!x)e^{-\Theta(x)}
\eeq

\beq
\Theta(x)
=
\sum_i \Theta(x_i)
+\sum_{i-j}\Theta(x_i, x_j)
\eeq
(This form for $\tP(x)$ and 
$\Theta(x)$ agrees with Eq.(\ref{eq-tP-tree}))


\beq
m_{t\rdart s}(x_s)=
e^{\lam_{t\rdart s}(x_s)}
\eeq

\beq
\tP(x_i)
=\caln(!x)
e^{-\Theta(x_i)}
\prod_{a\in \partial i}
m_{a\rdart i}(x_i)
\eeq

\beq
\tP(x_i, x_j)=
\caln(!x)
e^{-\Theta(x_i, x_j) 
- \Theta(x_i)
-\Theta(x_j)}
\left[\prod_{a\in \partial i
\setminus j} m_{a\rdart i}(x_i)
\right]
\left[\prod_{b\in \partial j
\setminus i} m_{b\rdart j}(x_j)
\right]
\eeq
\end{claim}
\proof

\beq
\call=
\left\{
\begin{array}{l}
\sum_x \tP(x)\Theta(x)
\\
+\sum_i (1-d_i) 
\sum_{x_i}
\tP(x_i)
\ln
\tP(x_i)
\\
+\sum_{i-j}\sum_{x_i, x_j}\tP(x_i, x_j)
\ln \tP(x_i, x_j)
\\
\sum_x \lam(x)\left[
1-\tP(x)
\right]
\end{array}
\right\}
\eeq


\beqa
\delta\left[f(x_i) \tP(x_i)\right] 
&=&f( x_i)\delta 
\sum_{x\setminus x_i}\tP(x)
\\
&=&
f(x_i)
\sum_{x\setminus x_i}\delta\tP(x)
\\
&=&
\sum_{x'}
\delta\tP(x')
\left[
\delta(x_i', x_i )f(x_i')
\right]
\eeqa
Likewise,
\beq
\delta\left[f(x_i,x_j) \tP(x_i,x_j)\right] 
=
\sum_{x'}
\delta\tP(x')
\left[
\delta(x_i', x_i )
\delta(x_j', x_j )f(x_i', x_j')
\right]
\eeq

\beq
\delta\call=
\sum_{x'}\delta\tP(x')
\left\{
\begin{array}{l}
\Theta(x')
\\
+\sum_i (1-d_i) 
\left[1+\ln
\tP(x_i')\right]
\\
+\sum_{i-j}
\left[1+
\ln \tP(x_i', x_j')\right]
\\
-\lam(x')
\end{array}
\right\}
\eeq

\beq
0=
\left\{
\begin{array}{l}
\Theta(x)
\\
+\sum_i  
\left[1+\ln
\tP(x_i)\right]
\\
+\sum_{i-j}
\left[1+
\ln \frac{\tP(x_i, x_j)}
{\tP(x_i)\tP(x_j)}
\right]
\\
-\lam(x)
\end{array}
\right\}
\eeq





\beq
0=
\left\{
\begin{array}{l}
\Theta(x)
\\
-\sum_i \Theta(x_i)
\\
-\sum_{i-j}\Theta(x_i, x_j)
\end{array}
\right\}
\eeq

\beqa
0&=&
\left\{
\begin{array}{l}
+\sum_i \ln 
\prod_{a\in \partial i}m_{a\rdart i}(x_i)
\\
+\sum_{i-j}\ln 
\frac{\left[\prod_{a\in \partial i
\setminus j} m_{a\rdart i}(x_i)
\right]
\left[\prod_{b\in \partial j
\setminus i} m_{b\rdart j}(x_j)
\right]
}{
\prod_{a\in \partial i}m_{a\rdart i}(x_i)
\prod_{b\in \partial j}m_{b\rdart j}(x_j)
}
\\
-\lam(x)
\end{array}
\right\}
\\
&=&
\left\{
\begin{array}{l}
\sum_i
\sum_{a\in \partial i} \lam_{a\rdart i}(x_i)
\\
-
\sum_{i-j}\left[
\lam_{j\rdart i}(x_i)+ \lam_{i\rdart j}(x_j)
\right]
\\
-\lam(x)
\end{array}
\right\}
\\
&=&
-\lam(x)
\eeqa
\qed








