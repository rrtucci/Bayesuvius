\chapter{LATE (Local Average Treatment Effect)}
\label{ch-late}

This
chapter is based 
on Refs.\cite{book-brady-neal,
alves-book}.





The {\bf Local Average Treatment Effect (LATE)} is
the same as the ATE estimand\footnote{ATE 
is defined 
in the Potential Outcomes chapter,
i.e.,  Chapter
\ref{ch-pot-out}.},
but it only 
counts 
``compliers" (i.e., individuals
that comply with the
treatment they've been 
assigned). LATE
assumes 
the same bnet
that we considered
when we 
discussed Instrumental
Variables (IV)
\footnote{Instrumental
Variables are discussed 
in Chapters \ref{ch-instrumental}
and \ref{ch-inst-ineq}.} 

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}
\begin{table}[h!]
\centering
\begin{tabular}{|
>{\columncolor[HTML]{F6F694}}l |l|l|l|l|l|}
\hline
\cellcolor[HTML]{9AFF99}$\s$ & \cellcolor[HTML]{9AFF99}$a^\s$ & \cellcolor[HTML]{9AFF99}$d^\s(a^\s=0)$ & \cellcolor[HTML]{9AFF99}$d^\s(a^\s=1)$ & \cellcolor[HTML]{9AFF99}$y^\s(d^\s=0)$ & \cellcolor[HTML]{9AFF99}$y^\s(d^\s=1)$ \\ \hline
1 & 0 & 1 & \cellcolor[HTML]{FFCCC9} & \cellcolor[HTML]{FFCCC9} & 0 \\ \hline
2 & 0 & 0 & \cellcolor[HTML]{FFCCC9} & 1 & \cellcolor[HTML]{FFCCC9} \\ \hline
3 & 0 & 1 & \cellcolor[HTML]{FFCCC9} & \cellcolor[HTML]{FFCCC9} & 1 \\ \hline
4 & 0 & 0 & \cellcolor[HTML]{FFCCC9} & 0 & \cellcolor[HTML]{FFCCC9} \\ \hline
5 & 0 & 0 & \cellcolor[HTML]{FFCCC9} & 1 & \cellcolor[HTML]{FFCCC9} \\ \hline
6 & 1 & \cellcolor[HTML]{FFCCC9} & 1 & \cellcolor[HTML]{FFCCC9} & 0 \\ \hline
\cellcolor[HTML]{FFFC9E}7 & 1 & \cellcolor[HTML]{FFCCC9} & 0 & 0 & \cellcolor[HTML]{FFCCC9} \\ \hline
\cellcolor[HTML]{FFFC9E}8 & 1 & \cellcolor[HTML]{FFCCC9} & 1 & \cellcolor[HTML]{FFCCC9} & 0 \\ \hline
\cellcolor[HTML]{FFFC9E}9 & 1 & \cellcolor[HTML]{FFCCC9} & 0 & 1 & \cellcolor[HTML]{FFCCC9} \\ \hline
\cellcolor[HTML]{FFFC9E}10 & 1 & \cellcolor[HTML]{FFCCC9} & 1 & \cellcolor[HTML]{FFCCC9} & 1 \\ \hline
\end{tabular}
\caption{Hypothetical dataset for LATE problem. Pink cells indicate missing data.}
\label{tab-late-table}
\end{table}
Table \ref{tab-late-table}
shows a typical dataset
for the LATE problem.

\begin{figure}[h!]
$$
\begin{array}{ccccc}
\xymatrix{
&&\rvx\ar[ddl]\ar[ddr]
\\
\\
\rva\ar[r]
&\rvd\ar[rr]&&\rvy
}
&
\xymatrix{
&&\rvx\ar[dl]\ar[dr]
\\
&
[\rvd(a')]_{a'=0}^1\ar[d]
&
&[\rvy(d')]_{d'=0}^1\ar[d]
\\
\rva\ar[r]
&\rvd\ar[rr]&&\rvy
}
\\
G
&
G_+=
\cali_{\rvd\rarrow \rvy}
\cali_{\rva\rarrow \rvd}G
\end{array}
$$
\caption{
Bnet $G_+$ is bnet $G$
after application of 2
imagine operators.
Imagine operators
are discussed in Chapter \ref{ch-counterf}.
}
\label{fig-late-g-gplus}
\end{figure}

Consider
the bnets
$G$
and $G_+$
of 
Fig.\ref{fig-late-g-gplus}.\footnote{If there were an arrow
$\rva\rarrow \rvy$
in bnet $G$,
then we could also
apply the imagine 
operator $\cali_{\rva\rarrow
\rvy}$ to $G$.
This would lead to
nodes 
$[\rvy(a',d')]_{a'=0}^1|_{d'=0}^1$.
Since
there is no arrow
$\rva\rarrow \rvy$, we would have
$y(a, d)=y(d)$
for all $a,d$,
i.e., $y$
does not depend
directly on 
the instrument $a$.
This independence
of $y(a,d)$ on $a$ is called the
{\bf excludability
assumption}.
One could say
the excludability
assumption
is built into
our bnet $G_+$.}

Let

$\rva\in \bool$, instrumetal
variable,
initially assigned dose

$\rvd\in \bool$, actual treatment 
dose

$\rvy\in \bool$, treatment outcome

The  definition of the 
imagine
operators 
used in $G_+$
stipulates
that nodes
$\rvy$ and
$\rvd$
in $G_{+}$
must be have the following
deterministic TPMs
(printed in blue below).


\beq\color{blue}
P(d|a,
[d(a')]_{a'=0}^1
) = \indi(\quad
d= \underbrace 
{a d(a) + (1-a)d(1-a)}
_{=\sum_{a'=0}^1
\delta(a,a')d(a')\quad=\quad d(a)}
\quad)
\eeq

\beq\color{blue}
P(y|d,
[y(d')]|_{d'=0}^1)
= \indi(\quad
y= 
y(d)
\quad)
\eeq

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|}
\hline
 & \cellcolor[HTML]{ECF4FF}$d^\s(0)$ & \cellcolor[HTML]{ECF4FF}$d^\s(1)$ \\ \hline
\cellcolor[HTML]{ECF4FF}never-takers & 0 & 0 \\ \hline
\cellcolor[HTML]{ECF4FF}compliers & 0 & 1 \\ \hline
\cellcolor[HTML]{ECF4FF}defiers & 1 & 0 \\ \hline
\cellcolor[HTML]{ECF4FF}always-takers & 1 & 1 \\ \hline
\end{tabular}
\caption{Possible compliance
behaviors  for individual $\s$.}
\label{tab-late compliance}
\end{table}

Table \ref{tab-late compliance}
gives a name
to the 4 possible compliance
behaviors
that might be exhibited by
an individual
$\s$ of
a dataset.
Below, we will
use $\calc$ to
denote the 
conditions that 
define a {\bf complier}:

\beq
\calc=\{\rvd(0)=0, \rvd(1)=1\}
\eeq
{\bf Monotonicity}
is said to hold if
\beq
d^\s(1)
\geq
 d^\s(0)
\eeq
Note
that monotonicity
rules out defiers
(i.e., 
$d^\s(1)=0,
\;
d^\s(0)=1$),
but
allows the other 3 
compliance behaviors.
 
It is
convenient
to define
the following
expected values:
\beq
\cald_{|a} = \sum_d d\; P(d|a)
=
E_{|a}[\rvd]
\eeq

\beq
\caly_{|d,a}=\sum_y y\;P(y|d,a)
=
E_{|d,a}[\rvy]
\eeq

\beq
\caly_{|\rvd=d}=\sum_y y\;P(y|d)
= E_{|d}[\rvy]
\eeq

\beq
\caly_{|\rva=a}=
\sum_y y\;P(y|a)
=
E_{|a}[\rvy]
\eeq


Assume that $
\cald_{|1}\neq\cald_{|0}
$. Then
LATE is defined by

\beq
\boxed{LATE = \frac{\caly_{|\rva=1}-
\caly_{|\rva=0}}
{\cald_{|1}-\cald_{|0}}
}
\eeq



\begin{claim}
If monotonicity is satisfied, then

\beq
P(\calc)=
\cald_{|1}-\cald_{|0}
\eeq
\end{claim}
\proof
\beqa
\cald_{|1}-\cald_{|0}
&=&
\sum_{d(0), d(1)}
P(d(0), d(1))[d(1)-d(0)]
\\
&=&
\left\{
\begin{array}{r}
P(d(0)=0, d(1)=0)
\underbrace{[d(1)-d(0)]}_{0}
\\
+P(d(0)=0, d(1)=1)
\underbrace{[d(1)-d(0)]}
_{1}
\\
+\underbrace{P(d(0)=1, d(1)=0)}
_{=0 \text{ by monotonicity}}
[d(1)-d(0)]
\\
+P(d(0)=1, d(1)=1)
\underbrace{[d(1)-d(0)]}_{0}
\end{array}
\right.
\\
&=& P(\calc)
\eeqa

\qed


\begin{claim}
Recall
\beq
ATE = E[\rvy(1)-\rvy(0)]
\eeq
If monotonicity is satisfied, then

\beq
LATE=
E_{|\calc}[\rvy(1)-\rvy(0)]
\eeq
 
\end{claim}
\proof

\begin{align}
\caly_{|\rva=1}-
\caly_{|\rva=0}
&=
E_{|\rva=1}[\rvy]
-
E_{|\rva=0}[\rvy]
\\
&=
\sum_x
\sum_{y(0), y(1)}
\sum_{d(0), d(1)}
\left\{
\begin{array}{l}
[y(d(1))-y(d(0))]
\\
*P(y(0), y(1)|x)
\\
*P(d(0), d(1)|x)
\\
*P(x)
\end{array}
\right.
\\
&=
\sum_{y(0), y(1)}
\sum_{d(0), d(1)}
[y(d(1))-y(d(0))]
\left\{
\begin{array}{l}
P(y(0), y(1)|d(0), d(1))
\\
*P(d(0), d(1))
\end{array}
\right.
\\
&=
\sum_{y(0), y(1)}
\left\{
\begin{array}{r}
\underbrace{[y(0)-y(0)]}_{0}
\left\{
\begin{array}{l}
P(y(0), y(1)|d(0)=0, d(1)=0)
\\
*P(d(0)=0, d(1)=0)
\end{array}
\right.
\\
\\
+
[y(1)-y(0)]
\left\{
\begin{array}{l}
P(y(0), y(1)|d(0)=0, d(1)=1)
\\
*P(d(0)=0, d(1)=1)
\end{array}
\right.
\\
\\
+
[y(0)-y(1)]
\left\{
\begin{array}{l}
P(y(0), y(1)|d(0)=0, d(1)=0)
\\
*\underbrace{P(d(0)=0, d(1)=0)}
_{=0 \text{  monotonicity}}
\end{array}
\right.
\\
\\
+
\underbrace{[y(1)-y(1)]}_{0}
\left\{
\begin{array}{l}
P(y(0), y(1)|d(0)=1, d(1)=1)
\\
*P(d(0)=1, d(1)=1)
\end{array}
\right.
\end{array}
\right.
\\
&=
P(\calc)
\sum_{y(0), y(1)}
[y(1)-y(0)]
P(y(0), y(1)|\calc)
\\
&=
P(\calc)
E_{|\calc}[\rvy(1)-\rvy(0)]
\end{align}
\qed

It
is instructive
to evaluate 
LATE for
the special case 
in which $G$
of
Fig.\ref{fig-late-g-gplus}
is an LDEN (Linear
Deterministic
with External
 Noise) bnet.\footnote{LDEN bnets are discussed in Chapter
 \ref{ch-linear-sys}.}
 
 Consider Fig.\ref{fig-late-lden}.
 From that figure

\begin{figure}[h!]
$$
\xymatrix{
&&\rvx\ar[ddl]_\mu
\ar[ddr]^\nu
\\
\\
\rva\ar[r]^\alp
&\rvd\ar[rr]^\delta
&&\rvy
}
$$
\caption{
LDEN bnet for LATE}
\label{fig-late-lden}
\end{figure}

\beq
\rvd=\alp\rva +\mu\rvx
\eeq

\beq
\rvy = \delta \rvd + \nu\rvx
\eeq
Note that

\beq
\av{\rvx, \rva}=0
\eeq
because 
both possible paths
from
$\rva$ to $\rvx$
(i.e., $\rva-\rvd-\rvx$
and $\rva-\rvd-\rvy-\rvx$)
are blocked by colliders.
\begin{claim}
For the LDEN bnet of Fig.\ref{fig-late-lden},

\beq
LATE = \delta =
\frac{\av{\rvy,\rva}}
{\av{\rvd, \rva}}
\eeq
\end{claim}
\proof


\beq
\av{\rvd, \rva}=\alp
\av{\rva, \rva}
\eeq

\beqa
\av{\rvy, \rva}&=&
\av{\delta(\alp\rva+\mu\rvx)
+\nu\rvx, \rva}
\\
&=&
\alp\delta
\av{\rva, \rva} 
\eeqa
Hence,

\beq
\frac{\av{\rvy,\rva}}
{\av{\rvd, \rva}}=\delta
\eeq

\beqa
E_{\rva=1}[\rvy]-
E_{\rva=0}[\rvy]&=&
E_{\rva=1}[\delta \rvd +\nu\rvx]-
E_{\rva=0}[\delta \rvd +\nu\rvx]
\\
&=&
\delta(E_{\rva=1}[\rvd]-
E_{\rva=0}[\rvd])
+ \nu
\underbrace{(E_{\rva=1}[\rvx]-
E_{\rva=0}[\rvx])}_{0}
\eeqa

\qed

