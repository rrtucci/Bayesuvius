\chapter{Structure and Parameter
 Learning for Bnets}\label{ch-struc-learn}


Learning a bnet
from data
is a computationally intensive NP-complete
problem. 
Therefore,
the best one can hope
for is for heuristic algorithms 
that solve this problem
approximately. A huge number 
of such algorithms have been tried
and continue to be tried.
Luckily,
there exists a free open source
 software library
called \bnlearn
that covers many of
them. The goal
of this chapter
is to give
a brief
overview
of the subject
of bnet 
learning,
after 
which
we recommend
to
those readers who
want to
pursue this subject
further,
to 
learn \bnlearn.

This chapter
is based on  
the \bnlearn website Ref.\cite{bnlearn}, and
on a 2019 survey
paper 
\cite{scutari2019}
by Scutari et al.
I highly recommend looking
at both. Refs.
\cite{carvalho} and \cite{margaritis}
were also
helpful to me in understanding the subject.


How things stand
in the field of
bnet learning software reminds me
of how things stand in 
the field of linear 
algebra (LA) software. Perfecting and
optimizing
LA software
takes many years so
I would not
advise you to write your own
LA software library starting
from scratch.
There is no need to do so. You
can use LAPACK (free, open source)
instead, which
has been perfected and expanded
for decades by world experts. 
I view \bnlearn as the LAPACK
of bnet learning. 

\bnlearn was
written by Marco Scutari
and collaborators
over a time period of
more than 10 years,
and is still
under active development.
Marco is a very kind and friendly
person who does his best to
answer the emails he receives.
Here is the \bnlearn website: Ref.\cite{bnlearn}.



\section*{Overview}

To give
the reader an overview
of the subject
and of \bnlearn itself,
here is a highly
simplified tree,
compiled from
the \bnlearn website
and documentation,
of some of the
subjects covered by \bnlearn.



\dirtree{%
.1 Parameter Learning.
.2 missing data.
.1 Structure Learning.
.2 tree-like structures given a priori.
.3 Naive Bayes.
.3 Chow-Liu tree.
.3 Tree Augmented Naive Bayes (TAN).
.3 ARACNE.
.2 score based.
.3 algorithms.
.4 hill climbing (HC).
.4 HC with random restarts.
.4 HC with Tabu list (Tabu).
.4 simulated annealing.
.4 genetic algorithms.
.3 scoring functions.
.4 Information Theoretic scores.
.4 Bayesian Information Criterion (BIC).
.4 Bayesian Dirichlet (BD) family.
.2 constraint based.
.3 algorithms.
.4 PC family.
.4 Grow-Shrink (GS).
.4 Incremental Association Markov Blanket (IAMB) family.
.3 conditional independence tests.
.4 mutual information (parametric, semiparametric and permutation tests).
.4 shrinkage-estimator for the mutual information.
.2 hybrid.
.3 Max-Min Hill Climbing (MMHC).
.3 Hybrid HPC (H2PC).
.3 General 2-Phase Restricted Maximization (RSMAX2).
.1 parallel mode structure learning.
.1 node types.
.2 all-discrete.
.2 all-continuous.
.2 mixed.
.1 utility functions.
.2 model comparison and manipulation.
.2 random data generation.
.2 arc orientation testing.
.2 simple and advanced plots.
.2 parameter estimation (maximum likelihood 
and Bayesian).
.2 inference, conditional probability queries. 
.2 cross-validation.
.2 bootstrap.
.2 model averaging.
}
     

\hrule
Let
\begin{itemize}
\item
PL=parameters learning (i.e, 
learning the TPMs)
\item
SL= structure learning 
(i.e.,learning the DAG)
\end{itemize}

PL is easy, once the
structure is known. PL 
assuming no missing data
goes as follows.
Using the notation of Chapter 
\ref{ch-scoring}, define
\beq
\pi_\kbarmu^i=
P(\rvx_i=k\cond pa(\rvx_i)=\mu )
\;.
\eeq
Then $\pi_\kbarmu^i$
can be estimated
from the data $N^i_\kmu$ 
using:

\beq
\pi_\kbarmu^i
\approx 
N^i_\kbarmu
=
\frac{N^i_\kmu}{N^i_\plusmu}
\;.
\label{eq-PL-simple}
\eeq
PL
described by Eq.(\ref{eq-PL-simple})
 is only for discrete nodes
with no missing data.
\bnlearn  can also do PL
with missing data
and continuous 
(Gaussian linear only) nodes. 
See Chapter \ref{ch-missing-d}
on missing data
and Chapter \ref{ch-gauss-lin}
on Gaussian linear nodes.
SL
actually
does PL and SL
at the same time. 
 
There are 3 main 
types of SL: score based,
constraint based, and hybrid.
\bnlearn 
 can perform many
 algorithms
of each of these 3 types
of SL.
It can perform
most of them with either all-discrete,
or all-continuous
or mixed nodes.
It can perform
many of them
in parallel mode.
The 2019 survey paper
Ref.\cite{scutari2019} by
Scutari et al
compares 
the performance 
of many different
bnet learning algorithms.

\hrule\noindent
{\bf Score based SL algorithms}

Score based SL algorithms
require
scoring bnets (with either
all-discrete, all-continuous
or mixed nodes).
See Chapter \ref{ch-scoring}
for an introduction
to scoring bnets.
The BIC score
explained
in that chapter is
very popular
and works for all-discrete,
all-continuous or mixed nodes.

Score-based SL algorithms apply
standard
optimisation techniques. 
In the Hill Climbing algorithm,
the current best
bnet is changed
slightly
and then given a score
that measures how well
it fits the data.
The bnet with the highest (=best) 
score so far, as well as that highest score,
are stored. (Hence,
this is called a greedy search).
The process continues
until the latest highest score stops changing.
The problem with being
greedy all the time is that
the answer might
converge to a local maximum.
To mitigate
this problem
and allow some
probability of visiting more
than one
local maximum, one uses a
Tabu Table, random restarts,
simulated annealing, genetic algorithms,
etc.

\hrule\noindent
{\bf Constraint based SL algorithms}

To fully understand
 constraint based SL 
algorithms,
the reader 
is advised to read Chapters 
\ref{ch-dsep} and \ref{ch-obs-equi}
first.

Constraint based SL algorithms
require
estimating from the data
the conditional independence
$\rvx.\perp_P \rvy.|\rva.$ 
for any 3 disjoint
multinodes $\rvx., \rvy., \rva.$.
This can be done by
estimating the conditional
mutual information (CMI)
$H(\rvx.:\rvy.|\rva.)$.
\bnlearn  can calculate CMI and
other metrics
of $\rvx.\perp_P \rvy.|\rva.$.
All these metrics are very
similar; they 
all measure
how close
$P(x.|y., a.)$
and $P(x.|a.)$ are.

The first
constraint-based SL algorithm
was the Inductive Causation (IC) algorithm
 proposed by Pearl and Verma in 1991.
Incremental
improvements
have been
proposed since then, such as
the PC family
of algorithms,
Grow-Shrink and
the
Incremental Association Markov Blanket (IAMB)
family of algorithms.

\newpage
\section*{Pseudo-code 
for some bnet learning algorithms}






\begin{algorithm}
	\DontPrintSemicolon
    \SetKwInOut{KwIn}{Input}
    \SetKwInOut{KwOut}{Output}

    \KwIn{Data $D$, Vertices $V$}
    \KwOut{a bnet $B=(G, T)$,
	where $G=(V, E)$ is a DAG, where
	$V$ are its vertices (nodes) and $E$ 
	are its edges (arrows).
 	$T$ are all its
	Transition Probability Matrices (TPMs)
 	$T=TPMs(G, D)$. }

    $E\larrow \emptyset$\;
	$T\larrow \emptyset$\;
	$B\larrow (V, E, T)$\;
	$maxscore \larrow-\infty$\;
	\tcp{$DE$= all possible directed edges}
	$DE=\{\rvx\rarrow\rvy\in V\times V: \rvx\neq \rvy\}$\;
	$again\larrow True$\;
	\While{$again$}{
		\For{all $\rvx\rarrow\rvy\in DE$}{
			\tcp{add arrow}
			$E_+\larrow E\cup\{\rvx\rarrow\rvy\}$\;
			\tcp{delete arrow}
			$E_-\larrow E-\{\rvx\rarrow\rvy\}$\;
			\tcp{reverse arrow}
			$E_R\larrow E_-\cup\{\rvy\rarrow\rvx\}$\;
			\For{$E'=E_+,E_-, E_R$}{
				\If{$E'\neq E$ and $G'=(V, E')$ is a legal DAG}{
					$T'\larrow TPMs(G', D)$\;
					$B'\larrow (G', T')$\;
					$newscore= \text{BIC-score}(B')$\;
					\eIf{$newscore>maxscore$}{
						$B\larrow B'$\;
						$maxscore\larrow newscore$\;
					}{
						$again\larrow False$
					}
				}
			}
		}
	}
    \KwRet{$B$}
    \caption{Pseudo-code for Hill Climbing algorithm}
\end{algorithm}



\begin{algorithm}
	\DontPrintSemicolon
    \SetKwInOut{KwIn}{Input}
    \SetKwInOut{KwOut}{Output}

    \KwIn{Data $D$, Vertices (nodes) $V$,
	tolerance in CMI $\eps>0$}
    \KwOut{partially oriented
	acyclic graph $G=(V, E, UE)$, where $V$ are 
	the vertices (nodes),
	$E$ are the oriented edges (arrows)
	and $UE$ are the unoriented edges.}
	$E\larrow \emptyset$\;
	\tcp{initialize $UE$ to fully-connected
	undirected graph} 
	$UE\larrow \{\rvx-\rvy\in V\times V: \rvx-\rvy=\rvy-\rvx,
	\rvx\neq \rvy\}$\;
	\tcp{Shrink phase. Deletes edges from $E$.}
	\For{$\lam=0, 1, 2, \ldots, |V|-2$}{
		\For{all $\rvx-\rvy\in UE$}{
			\For{all $S=\{\rva\in V:\rvx-\rva\in UE, 
			\rva\neq \rvx, \rvy\} \ni |S|=\lam$}{
				\If{$H(\rvx:\rvy|S)<\eps$}{
					\tcc{If there were an arrow between $\rvx$ and $\rvy$, 
						then conditioning on $S$ would not be enough
						to interrupt info transmission $H(\rvx:\rvy|S)$
						 between $\rvx$ and $\rvy$}
					$UE\larrow UE-\{\rvx-\rvy\}$\;
					$S(\rvx-\rvy)\larrow S$\;
				}
			}
		}
	}
	\tcp{Growth phase. Adds v structures to $E$.}
	\For{all $\rvx,\rvy, \rva$ such that
	$\rvx-\rva\in UE, \rva-\rvy\in UE,
	\rvx-\rvy\not \in UE, \rva\not\in S(\rvx-\rvy)$}{
		\tcc{If there were no collider at $\rva$, then 
		there would be info transmission  between $\rvx$ and
		$\rvy$}
		$UE\larrow UE-\{\rvx-\rva, \rva-\rvy\}$\;
		$E\larrow E\cup \{\rvx\rarrow\rva, \rvy\rarrow\rva\}$\;
	}
	\tcp{Orienting edges.}
	$again\larrow True$\;
	$size\larrow |UE|$\;
	\While{$again$}{
		\For{all $\rvx-\rvy\in UE$}{
			\If{$\rvx\rarrow\rvy\in E$,
			$\rvy-\rvz\in UE$,
			$\rvx-\rvz\not\in UE$,
			$\not\exists \rvw \ni \rvw\rarrow\rvy\in E$}{
				\tcp{to avoid introducing new v structure}
				$UE\larrow UE- \{\rvy-\rvz\}$\;
				$E\larrow E\cup \{\rvy\rarrow \rvz\}$\;
			}
			\If{$\rvx\rarrow\rvy\in E$
			and there is directed path from $\rvx$ to
			$\rvy$ in $E$}{
				\tcp{to avoid introducing cycles}
				$UE\larrow UE- \{\rvx-\rvy\}$\;
				$E\larrow E\cup \{\rvx\rarrow \rvy\}$\;
			}
		}
		$newsize\larrow |UE|$\;
		\eIf{$size==newsize$}{
			$again\larrow False$\;
		}{
			$size\larrow newsize$\;
		}
	}
    \KwRet{$G=(V, E, UE)$}
    \caption{Pseudo-code for PC-Stable algorithm}
\end{algorithm}