\chapter{Renormalization Group for Bayesian Networks}
\label{ch-renorm-group-bnets}
\section{Information Theory Conventions}
\beq
H(\rvx)=-\sum_{x\in val(\rvx)} P(x)\ln P(x)
\eeq

\beq
H(\rvy\mid \rvx) =-
\sum_{x\in val(\rvx)}
\sum_{y\in val(\rvy)}
P(x,y)\ln P(y|x)
\eeq

\beqa
H(\rvx:\rvy)&=&\sum_{x\in val(\rvx)}
\sum_{y\in val(\rvy)}
P(x,y)\ln \frac{P(x,y)}{P(x)P(y)}
\\
&=& H(\rvy)-H(\rvy|\rvx)=H(\rvx)-H(\rvx|\rvy)
\eeqa


\begin{claim}
\beq
0\leq H(\rvx)\leq \ln|val(\rvx)|
\eeq
\beq
0\leq H(\rvx: \rvy)\leq \min(H(\rvx), H(\rvy))
\eeq
\end{claim}
\proof

The minimum occurs when $P(x,y)=P(x)P(y)$
(i.e., $\rvx$ and $\rvy$ are uncorrelated).

The maximum occurs when $\rvx$ becomes
deterministic 
or $\rvy$ becomes deterministic. 
When $\rvx$ becomes deterministic,

\beq
H(\rvx|\rvy)=0\implies 
 H(\rvx: \rvy)= H(\rvx)
\eeq
Likewise, when $\rvy$ becomes determinstic, 
$H(
\rvx: \rvy)= H(\rvy)$
\qed

\section{Scaling a General Bnet}

Let

$I_R=$ set of indices of roots. In Fig.\ref{fig-fishnet},
$I_R=\{1,2,3,4,5 \}$

$I_{NR}=$ set of non-root indices. In Fig.\ref{fig-fishnet},
$I_{NR}=\{6,7,8, \ldots 25\}$

$|I_R| + |I_{NR}|=n=$ total number of nodes


\beq
P(x^{:n}) = \left[ \prod_{i\in I_{NR}}P(x_i\mid pa(\rvx_i))\right]\prod_{i\in I_R}P(x_i)
\eeq

$1<b<\infty$
\beq
P(x_i\mid pa(\rvx_i); b)=
\frac{P(x_i\mid pa(\rvx_i))^b}
{Z_i}
\eeq

\beq
Z_i=\sum_{x_i\in val(x_i)}P(x_i\mid pa(\rvx_i))^b
\eeq

As $b\rarrow \infty$,

\beq
P(x_i\mid pa(\rvx_i); b)\rarrow \delta[1, \max_i P(x_i\mid pa(\rvx_i);b=1)]
\eeq



\section{Scaling Ising Model Bnet}

$Bool=\bool$

 
$S_i, S_a, S_b\in \{1, -1\} =2 Bool-1=\ZZ_\pm$



\beq
\calh_i = \frac{1}{2}g S_i (S_a + S_b) + h S_i,\quad \calh=\sum_i \calh_i
\eeq

\beq
b = \beta = 1/T
\eeq



\beq
Z_i = \sum_{S_i\in \ZZ_{\pm}}e^{-\beta \calh_i}
\eeq

\beq
\begin{array}{l}
\xymatrix@C=1pc@R=1pc{
\rvS_a\ar[dr]
&&\rvS_b\ar[dl]
\\
&\rvS_i
}
\end{array}
\quad
P(S_i|S_a, S_b; \beta)=  \frac{e^{-\beta \calh_i}}{Z_i}
\eeq

\begin{figure}[h!]
\xymatrix@R=.8pc@C=.8pc{
\rvS_1\ar[dr] 
&& \rvS_2 \ar[dl]\ar[dr]
&& \rvS_3 \ar[dl]\ar[dr]
&& \rvS_4\ar[dl]\ar[dr]
&& \rvS_5\ar[dl]\ar[dr]
\\
& 
\rvS_{6}\ar[dr] 
&& \rvS_{7} \ar[dl]\ar[dr]
&& \rvS_{8} \ar[dl]\ar[dr]
&& \rvS_{9}\ar[dl]\ar[dr]
&& \rvS_{10}\ar[dl]\ar[dr]
\\
&&
\rvS_{11}\ar[dr] 
&& \rvS_{12} \ar[dl]\ar[dr]
&& \rvS_{13}\ar[dl]\ar[dr]
&& \rvS_{14}\ar[dl]\ar[dr]
&& \rvS_{15}\ar[dl]\ar[dr]
\\
&&&
\rvS_{16}\ar[dr] 
&& \rvS_{17} \ar[dl]\ar[dr]
&& \rvS_{18} \ar[dl]\ar[dr]
&& \rvS_{19}\ar[dl]\ar[dr]
&& \rvS_{20}\ar[dl]\ar[dr]
\\
&&&&
\rvS_{21} 
&& \rvS_{22} 
&& \rvS_{23} 
&& \rvS_{24}
&& \rvS_{25}
}
\caption{Fishnet bnet used for Ising model simulation}
\label{fig-fishnet}
\end{figure}

\beq
\begin{array}{l}
P(S_6\mid S_1, S_2;\beta)=\frac{e^{-\beta \calh_6}}{Z_6}
\\
\calh_6 = \frac{1}{2}g S_6 (S_1 + S_2) + h S_6
\end{array}
\eeq

\beq
\begin{array}{l}
P(S_{10}\mid S_5;\beta)=\frac{e^{-\beta \calh_{10}}}{Z_{10}}
\\
\calh_{10} = g S_{10} S_5 + h S_{10}
\end{array}
\eeq



\beq
P(S^{:n})=\left[\prod_{i\in I_{NR}}  P(S_i\mid pa(\rvS_i))\right]
\prod_{j\in I_R} P(S_j)
\eeq



\begin{claim}

\beq
\sum_{i=1}^n H(\rvS_i)-H(\rvS^{:n})=
\sum_{i\in I_{NR}} H(\rvS_i : pa(\rvS_i))
\leq \sum_{i\in I_{NR}}H(\rvS_i)
\eeq
Note that both sides equal zero
when all the nodes are uncorrelated.
\end{claim}
\proof

\beq
H(\rvS_i : pa(\rvS_i))=
\sum_{S_i\in \ZZ_\pm}\sum_{pa(\rvS_i)\in \ZZ^2_{\pm}}P(S_i, pa(\rvS_i))
\ln \frac{P(S_i\mid pa(\rvS_i))}{P(S_i)}
\eeq

\beq
H(\rvS_i)=-\sum_{S_i\in \ZZ_\pm}P(S_i)\ln P(S_i)
\eeq

\beq
H(\rvS^{:n})=-\sum_{S^{:n}\in \ZZ^n_\pm}P(S^{:n})\ln P(S^{:n})
\eeq

\beq
\frac{P(S^{:n})}{\prod_{i=1}^n
P(S_i)}=\prod_{i\in I_{NR}}  \frac{P(S_i\mid pa(\rvS_i))}{P(S_i)}
\eeq


\beq
\sum_{S^{:n}\in \ZZ_{\pm}^n}P(S^{:n})\ln \frac{P(S^{:n})}{\prod_{i=1}^n P(S_i)}=
\sum_{i\in I_{NR}}H(\rvS_i : pa(\rvS_i))
\eeq



\qed

