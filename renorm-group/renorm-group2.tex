\chapter{Renormalization Group for Bayesian Networks}
\label{ch-renorm-group-bnets}
\section{Information Theory Conventions}
\beq
H(\rvx)=-\sum_{x\in val(\rvx)} P(x)\ln P(x)
\eeq

\beq
H(\rvy\mid \rvx) =-
\sum_{x\in val(\rvx)}
\sum_{y\in val(\rvy)}
P(x,y)\ln P(y|x)
\eeq

\beqa
H(\rvx:\rvy)&=&\sum_{x\in val(\rvx)}
\sum_{y\in val(\rvy)}
P(x,y)\ln \frac{P(x,y)}{P(x)P(y)}
\\
&=& H(\rvy)-H(\rvy|\rvx)=H(\rvx)-H(\rvx|\rvy)
\eeqa


\begin{claim}
\beq
0\leq H(\rvx)\leq \ln|val(\rvx)|
\eeq
\beq
0\leq H(\rvx: \rvy)\leq \min(H(\rvx), H(\rvy))
\eeq
\end{claim}
\proof

The minimum occurs when $P(x,y)=P(x)P(y)$
(i.e., $\rvx$ and $\rvy$ are uncorrelated).

The maximum occurs when $\rvx$ becomes
deterministic 
or $\rvy$ becomes deterministic. 
When $\rvx$ becomes deterministic,

\beq
H(\rvx|\rvy)=0\implies 
 H(\rvx: \rvy)= H(\rvx)
\eeq
Likewise, when $\rvy$ becomes determinstic, 
$H(
\rvx: \rvy)= H(\rvy)$
\qed

\section{Scaling a General Bnet}

Let

$\calr=$ set of root nodes. 

$\calr^c=$ set of non-root indices.

$n=$ total number of nodes

$x^{:n}= (x_1, x_2, \ldots, x^n)$


\beq
P(x^{:n}) = \left[ \prod_{\rvx_i\in \calr^c}P(x_i\mid pa(\rvx_i))\right]\prod_{\rvx_i\in\calr}P(x_i)
\eeq

$1<b<\infty$
\beq
P(x_i\mid pa(\rvx_i); b)=
\frac{P(x_i\mid pa(\rvx_i))^b}
{Z_i}
\eeq

\beq
Z_i=\sum_{x_i\in val(x_i)}P(x_i\mid pa(\rvx_i))^b
\eeq

As $b\rarrow \infty$,

\beq
P(x_i\mid pa(\rvx_i); b)\rarrow \delta[1, \max_i P(x_i\mid pa(\rvx_i);b=1)]
\eeq



\section{Scaling the Bnet for a 2-dim cubic Ising Model}

\begin{figure}[h!]
$$
\bcen
\xymatrix{
\rvS_i\ar@{<->}[r]&\rvS_j
}
\ecen
=
\bcen
\xymatrix@R=1pc@C=3pc{
\rvS_i^X\ar[d]\ar@/^1pc/[r]
&\rvS_j^X\ar[d]
\\
\rvS_i^Y
&\rvS_j^Y\ar\ar@/^1pc/[l]
}
\ecen
$$
\caption{DAG definition of bidirectional arrow.}
\label{fig-def-bi-ar-dag}
\end{figure}


\begin{figure}[h!]
$$
\bcen
\xymatrix@C=1pc@R=1pc{
\rvS_a\ar@{<->}[dr]
&&\rvS_b\ar@{<->}[dl]
\\
&\rvS_i
\\
\rvS_c\ar@{<->}[ur]
&&\rvS_d\ar@{<->}[ul]
}
\ecen
=
\bcen
\xymatrix@C=2pc@R=1pc{
\rvS_a^X\ar[d]
&&\rvS_b^X\ar[d]
\\
\rvS_a^Y\ar[ddr]
&&\rvS_b^Y\ar[ddl]
\\
&\rvS_i^X
\ar[d]
\ar[luu]\ar[ruu]
\ar[ddl]\ar[ddr]
\\
&\rvS_i^Y
\\
\rvS_c^X\ar[d]
&&\rvS_d^X\ar[d]
\\
\rvS_c^Y\ar[uur]
&&\rvS_d^Y\ar[uul]
}
\ecen
$$
\caption{DAG definition of a 
4-point bidirectional interaction.}
\label{fig-4pt-bi}
\end{figure}



\begin{figure}[h!]
$$
\xymatrix@R=.8pc@C=.8pc{
\rvS_1\ar@{<->}[dr] 
&& \rvS_2 \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_3 \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_4\ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_5\ar@{<->}[dl]\ar@{<->}[dr]
\\
&\rvS_{6}\ar@{<->}[dl]\ar@{<->}[dr] 
&& \rvS_{7} \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{8} \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{9}\ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{10}\ar@{<->}[dl]
\\
\rvS_{11}\ar@{<->}[dr] 
&& \rvS_{12} \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{13}\ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{14}\ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{15}\ar@{<->}[dl]\ar@{<->}[dr]
\\
&\rvS_{16}\ar@{<->}[dl]\ar@{<->}[dr] 
&& \rvS_{17} \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{18} \ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{19}\ar@{<->}[dl]\ar@{<->}[dr]
&& \rvS_{20}\ar@{<->}[dl]
\\
\rvS_{21} 
&& \rvS_{22} 
&& \rvS_{23} 
&& \rvS_{24}
&& \rvS_{25}
}$$
\caption{Bnet used for 2D cubic Ising model simulation}
\label{fig-fishnet}
\end{figure}

$Bool=\bool$

 
$S_i, S_i^X, S_i^Y\in \{1, -1\} =2 Bool-1=\ZZ_\pm$

$D_i=(S_i^X, S_i^Y)$

$
b = \beta = 1/T
$

$\calb=$ border nodes

$\calb^c=$ non-border, internal nodes


Note that $\rvS_i^X\in \calb^c$ 
are all
root nodes.
\beq \color{blue}
P(S_i^X)=\quad \text{given for  $\rvS_i^X\in \calb^c$}
\eeq

We will assume that $\rvS_a^X\in \calb$ 
are all
root nodes too.

\beq \color{blue}
P(S_a^X|S_i^X)=P(S_a^X)=\quad \text{given for  $\rvS_a^X\in \calb$ and $\rvS_i^X\in \calb^c$}
\eeq

\beq \color{blue}
P(S_i^Y\mid S_i^X)=\delta(S_i^Y, S_i^X)\quad
\text{for $\rvS_i^X\in \calb$}
\eeq

\beq \color{blue}
P(S_i^Y\mid S_i^X,  S_a^Y, S_b^Y, S_c^Y, S_d^Y;\beta)=
  \frac{e^{-\beta \calh_i}}{Z_i}\quad 
\text{for $\rvS_i^Y\in \calb^c$}
\eeq



\beq
\left\{
\begin{array}{l}
\calh_i = \frac{1}{2}J S_i^Y (S_a^Y + S_b^Y+
S_c^Y + S_d^Y) + h S_i^Y +\lam_i (S_i^X - S_i^Y)
\\
\calh=\sum_i \calh_i
\end{array}
\right.
\eeq
$\lam_i\rarrow \infty$





\beq
Z_i = \sum_{S_i\in \ZZ_{\pm}}e^{-\beta \calh_i}
\eeq

\beq
P(D^{:n})=\left[
\prod_{\rvS_i^X \in \calb}\delta(S_i^X, S_i^Y)
\right]
\left[\prod_{\rvS_i^Y\in \calb^c}  P(S_i\mid pa(\rvS_i))\right]
\prod_{\rvS^X_i\in \calb^c} P(S_i^X)
\eeq



\begin{claim}

\beq
\sum_{i=1}^n H(\rvS_i)-H(\rvS^{:n})=
\sum_{i\in I_{NR}} H(\rvS_i : pa(\rvS_i))
\leq \sum_{i\in I_{NR}}H(\rvS_i)
\eeq
Note that both sides equal zero
when all the nodes are uncorrelated.
\end{claim}
\proof

\beq
H(\rvS_i : pa(\rvS_i))=
\sum_{S_i\in \ZZ_\pm}\sum_{pa(\rvS_i)\in \ZZ^2_{\pm}}P(S_i, pa(\rvS_i))
\ln \frac{P(S_i\mid pa(\rvS_i))}{P(S_i)}
\eeq

\beq
H(\rvS_i)=-\sum_{S_i\in \ZZ_\pm}P(S_i)\ln P(S_i)
\eeq

\beq
H(\rvS^{:n})=-\sum_{S^{:n}\in \ZZ^n_\pm}P(S^{:n})\ln P(S^{:n})
\eeq

\beq
\frac{P(S^{:n})}{\prod_{i=1}^n
P(S_i)}=\prod_{i\in I_{NR}}  \frac{P(S_i\mid pa(\rvS_i))}{P(S_i)}
\eeq


\beq
\sum_{S^{:n}\in \ZZ_{\pm}^n}P(S^{:n})\ln \frac{P(S^{:n})}{\prod_{i=1}^n P(S_i)}=
\sum_{i\in I_{NR}}H(\rvS_i : pa(\rvS_i))
\eeq



\qed

