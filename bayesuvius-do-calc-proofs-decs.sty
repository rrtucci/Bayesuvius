\newcommand{\bnetInstantiations}[0]{
Random variables are underlined
and their values are not.
For example, $\rva=a$ means
the random variable
$\rva$ takes the value $a$.
A diagram
with all its nodes
underlined represents a
Bayesian Network (bnet),
whereas the same diagram
with the letters not underlined
represents a specific
{\bf instantiation} of that bnet.
For example $\rva\rarrow\rvb\rarrow \rvc$
is a bnet for which
$P(a,b,c)$ equals $P(c|b)P(b|a)P(a)$,
whereas  $a\rarrow b\rarrow c$
is identically equal to  $P(c|b)P(b|a)$. Note that, for convenience,
we define $a\rarrow b\rarrow c$ to
exclude the priors of root nodes such as $P(a)$.

If $\rva$ is a root node,
then $\EE a$ signifies
a weighted sum $\sum_a P(a)$.
For example,

\beq\EE a\rarrow b\rarrow c=\sum_a P(c|b)P(b|a)P(a)
\eeq
If $\rva$ is not
a root node, then
$\sum a$ signifies
a simple unweighted sum $\sum_a$.
For example,

\beq
x\rarrow\sum a \rarrow y=
\sum_a P(y|a)P(a|x)
\eeq

A bnet promises a particular full probability distribution
function. We will sometimes refer to that full probability distribution function as the {\bf bnet promise}. 
For example, the bnet 

\beq
\xymatrix{
\rva\ar[r]
&\rvb\ar[r]
&\rvc}
\eeq
promises that

\beq
P(a,b,c)=P(c|b)P(b|a)P(a)
\eeq
Two bnets are said to be equal iff their promises are equal. 
An instantiation alone makes no promises.
Think of a bnet promise as being the equality
of two instantiations.}

\newcommand{\hiddenNodes}[0]{
Unobserved (a.k.a. hidden, latent) nodes are
indicated in a bnet by enclosing their
label
in a dashed circle. For example,
$\xymatrix{*++[F-o]{u}}$.
Alternatively, they are indicated by
using dashed arrows for all arrows emanating from the unobserved node.}



\newcommand{\selectionGraphs}
[0]{In a selection diagram
with a bnet-switch $\rvs\in \bool$,
if  a node $\rvx$
has parents $pa(\rvx)$
where $\rvs\not\in pa(\rvx)$,
then the
TPM of $\rvx$ is $P(x|pa(x))$.
If, on the other hand,
$\rvx$ has
parents $pa(\rvx)=pa^-(\rvx)\cup
\rvs$, where $pa^-(\rvx)=pa(\rvx)-\rvs$, then
the TPM of $\rvx$ is

\beq
P(x|pa^-(x), s)=
\left\{
\begin{array}{ll}
P(x|pa^-(x))& \text{ if } s=0
\\
P^*(x|pa^-(x))
& \text{ if } s=1
\end{array}
\right.
\eeq
}

\newcommand{\bdoordef}[0]{
Suppose that we have access to data
that allows us to
estimate a probability
distribution
 $P(x., y., z.)$.
Then we say that the
backdoor $\rvz.$
satisfies the
{\bf backdoor adjustment criterion}
relative to $(\rvx., \rvy.)$
if
\begin{enumerate}
\item
All backdoor paths from $\rvx.$
to $\rvy.$
 are blocked by  conditioning on
 $\rvz.$.
\item
$\rvz. \cap de(\rvx.)=\emptyset$.
\end{enumerate}
}

\newcommand{\bdoorconclusion}[0]{
\beqa
P(y. | \cald \rvx.=x.)&=&
\sum_{z.} P(y.|x., z.)P(z.)
\\
&=&
\xymatrix{
\EE z.\ar[dr]
\\
x.\ar[r]
&y.
}
\eeqa
}

\newcommand{\bdoorclaim}[0]{
If $\rvz.$ satisfies the
backdoor criterion relative to
 $(\rvx., \rvy.)$, then

\bdoorconclusion

}

\newcommand{\fdoordef}[0]{
Suppose that we have access to data
that allows us to
estimate a probability
distribution
 $P(x., m., y.)$.
Hence, the variables
$\rvx., \rvm., \rvy.$ are
ALL observed (i.e, not hidden).
Then we say that
the frontdoor $\rvm.$
satisfies the
{\bf frontdoor adjustment criterion}
relative to $(\rvx., \rvy.)$
if
\begin{enumerate}
\item
All directed paths from
$\rvx.$ to $\rvy.$ are intercepted by
(i.e., have a node in) $\rvm.$.
\item
All backdoor paths from $\rvx.$ to
$\rvm.$ are blocked.
\item
All backdoor paths from
on $\rvm.$ to $\rvy.$
are blocked by conditioning
on  $\rvx.$.
\end{enumerate}
}

\newcommand{\fdoorconclusion}[0]{
\beqa
P(y. | \cald \rvx.=x.)&=&\sum_{m.}
\left[\sum_{x'.}
P(y.|m., x'.)P(x'.)\right]
P(m.|x.)
\\
&=&
\xymatrix{
&\EE x'.\ar[dr]
\\
x.\ar[r]
&\sum m.\ar[r]&y.
}
\eeqa
}

\newcommand{\fdoorclaim}[0]{
If $\rvm.$ satisfies the
frontdoor criterion
relative to $(\rvx., \rvy.)$,
and $P(x.,m.)>0$, then

\fdoorconclusion
}


\newcommand{\SeqBdoorDef}[0]{
Suppose that we have access to data
that allows us to
estimate a probability
distribution
 $P(x^n, y, z^n)$.
Hence, the variables
$\rvx^n, \rvy, \rvz^n$ are
ALL observed (i.e, not hidden).
Then we say that the
 multinode
of \enquote{covariates} $\rvz^n$
satisfies the
{\bf sequential backdoor (SBD) adjustment criterion}
relative to $(\rvx^n, \rvy)$
if for all $t\in\{0,1, \ldots, n-1\}$,

\begin{enumerate}
\item
$\rvy\perp\rvx_t|
\underbrace{(\rvx_0, \rvx_1, \ldots,\rvx_{t-1},
\rvz_0, \rvz_1, \ldots, \rvz_t)}
_{\text{Past of $\rvx_t$}}$
in $\call_{\rvx_{t}}
\cald_{\rvx_{t+1},\rvx_{t+2}
,\ldots, \rvx_{n-1}}G$.
\item
$\rvz_t \cap de(\rvx_t)=\emptyset$.
\end{enumerate}
}


\newcommand{\SeqBdoorClaim}[0]{
If $\rvz^n$ satisfies the
sequential backdoor criterion relative to
 $(\rvx^n, \rvy)$, then

\beq
P(y | \cald \rvx^n=x^n)=
\calq(y|x^n)
\;,
\eeq
where $\calq(y|x^n)$
is defined by
Eq.(\ref{def-q-y-xn-seqbdoor}).
}

\newcommand{\decBackDoor}[0]{
 (Backdoor
Adjustment Formula)

If $G_{hypo}=$
$
\xymatrix{
{\rvz}\ar[d]\ar[rd]
\\
\rvx\ar[r]&\rvy
}$
then

\bdoorconclusion
}



\newcommand{\decFrontDoor}[0]{(Frontdoor
Adjustment Formula)

If $G_{hypo}=$
$
\xymatrix{
&*++[F-o]{\rvc}\ar[ld]\ar[rd]
\\
\rvx\ar[r]&\rvm\ar[r]&\rvy
}$
then

\fdoorconclusion
Using the node summation identities, 
the $\EE x'$ node may be removed from the final instantiation.
}


\newcommand{\decNapkin}[0]{(Napkin problem from Ref.\cite{book-why})

If $G_{hypo}=$ $
\xymatrix{
&*++[F-o]{\rvu_1}\ar[ddl]\ar[ddrr]
\\
&*++[F-o]{\rvu_2}\ar[dl]\ar[dr]
\\
\rvw\ar[r]
&\rvz\ar[r]
&\rvx\ar[r]
&\rvy
}$ then
\begin{align}
P(y|\cald \rvx = x)
&=
\text{Not identifiable}
\end{align}
}

\newcommand{\decWhy}[0]{(from Ref.\cite{book-why})

If $G_{hypo}=$ $
\xymatrix{
\rvx\ar[d]\ar[drr]
\\
\rvw\ar[r]
&\rvz\ar[r]
&\rvy
\\
*++[F-o]{\rvu}\ar[u]\ar[urr]
}$ then
\beqa
P(y|\cald\rvz=z, x)
&=&
P(y|z,x)
\\
&=&
\xymatrix{
x\ar[rrd]
\\
&z\ar[r]
&y
}\eeqa
}


\newcommand{\decTransferTrivial}[0]
{(Trivial Memoryless
 Transfer,
from Ref.\cite{pearl2011trans})

If $G_{hypo}=$ $
\xymatrix{
&\rvz\ar[ld]\ar[rd]
&\rvs\ar[d]
\\
\rvx\ar[rr]
\ar@{<-->}@/^1pc/[ru]
\ar@{<-->}@/_1pc/[rr]
&&\rvy
}$
where $\rvs\in\bool$ is a
bnet-switch,
then

\beq
P^*(y|\cald \rvx=x, z)=P^*(y|x, z)
\quad
\text{(replace $\cald$ by $1$,
keep $P^*$)}
\eeq

\beq
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{
\\=
}
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
x\ar[rr]
&&y
}
\eeq
}

\newcommand{\decTransferDirect}[0]
{(Direct
 Transfer, a.k.a.
External Validity,
from Ref.\cite{pearl2011trans})

If $G_{hypo}=$ $
\xymatrix{
\rvs\ar[r]
&\rvz\ar[ld]\ar[rd]
&
\\
\rvx\ar[rr]
\ar@{<-->}@/^1pc/[ru]
\ar@{<-->}@/_1pc/[rr]
&&\rvy
}$
where $\rvs\in\bool$ is a
bnet-switch,
then

\beq
P^*(y|\cald\rvx=x, z)=
P(y|\cald\rvx=x, z)
\quad
\text{(replace $P^*$ by $P$,
keep $\cald$)}
\eeq

\beq
\xymatrix{
\rvs=1\ar[r]
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}\eeq
Furthermore,
\beq
P^*(y|\cald \rvx=x)=
\sum_z
P(y|\cald \rvx=x,z)P^*(z)
\eeq

\beq
\xymatrix{
\rvs=1\ar[drr]
\\
\cald \rvx=x\ar[rr]
&&y
}\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum z\ar[rd]
\\
\cald\rvx=x\ar[rr]
&&y
}
\eeq
}



\newcommand{\decTransferBox}[0]
{(S-Admissible Transfer,
from Ref.\cite{pearl2011trans})

If $G_{hypo}=$
$
\xymatrix{
\rvs\ar[r]
&*++[F-o]{\rvz}\ar[r]\ar[ld]
&\rva\ar[d]
\\
\rvx\ar[rr]
\ar@{<-->}@/^1pc/[ru]
\ar@{<-->}@/_1pc/[rr]
&&\rvy
\\
\\
}$
where $\rvs\in\bool$ is a
bnet-switch,
then

\beq
P^*(y|\cald \rvx=x)=
\sum_{a}P(y|\cald \rvx=x, a)P^*(a)
\eeq
\beq
\xymatrix{
\rvs=1\ar[dr]
\\
\cald \rvx=x\ar[r]
&y
}\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum a\ar[d]
\\
\cald \rvx=x\ar[r]
&y
}
\eeq
}

%\decTransferOne merged
%with decDirectTransfer

\newcommand{\decTransferNon}[0]
{(Non-transportability,
from Ref.\cite{pearl2011trans})

If $G_{hypo}=$ $
\xymatrix{
&*++[F-o]{\rvh}\ar[ld]\ar[rd]
&\rvs\ar[d]
\\
\rvx\ar[rr]
&&\rvy
}$
where $\rvs\in\bool$ is a
bnet-switch,
then

\beq
P^*(y|\cald \rvx=x)=
\xymatrix{
&*++[F-o]{\rvh}\ar[rd]
&\rvs=1\ar[d]
\\
x\ar[rr]
&&y
}
\eeq
The right hand side is not identifiable.}

\newcommand{\decTransferTwo}[0]{(from Ref.\cite{pearl2011trans})
\\
\\

If $G_{hypo}=$
$\xymatrix{
\rvs\ar@/^1.5pc/[rr]
&*++[F-o]{\rvh}\ar[dl]\ar[dr]\ar[r]
\ar@{<-->}@/_1pc/[dl]
&\rvz
\\
\rvx\ar[rr]\ar@{<-->}@/_1pc/[rr]
&&\rvy
}$
where $\rvs\in\bool$ is a
bnet-switch,
then

\beq
P^*(y|\cald \rvx=x)=
P(y|\cald \rvx=x)
\eeq
\beq
\xymatrix{
\rvs=1\ar[drr]
\\
\cald \rvz=z\ar[rr]
&&y
}\xymatrix{\\=}
\xymatrix{
\\
\cald \rvx=x\ar[rr]
&&y
}
\eeq
}

\newcommand{\decTransferThree}[0]{(from Ref.\cite{pearl2011trans})

If $G_{hypo}=$
$\xymatrix{
\rvs\ar[rd]
&*++[F-o]{\rvh}\ar[dl]\ar[dr]
\ar@{<-->}@/_1pc/[dl]
\\
\rvx\ar[r]\ar@{<-->}@/_1pc/[rr]
&\rvz\ar[r]
&\rvy
}$
where $\rvs\in\bool$ is a
bnet-switch,
then

\beq
P^*(y|\cald \rvx=x)=
\sum_z
P(y|\cald \rvx=x, \cald \rvz=z)P^*(z|x)
\eeq
\beq
\xymatrix{
\rvs=1\ar[dr]
\\
\cald\rvx=x\ar[r]&y
}
\xymatrix{
\\= \sum_z}
\xymatrix{
\rvs=1\ar[rd]
\\
x\ar[r]
&z
}
\xymatrix@R=.5pc{
\EE u_1\ar@{-->}[r]
&*++[F-o]{\su h}\ar[dr]
\\
x
&z\ar[r]
&y\\
&\EE u_2\ar@{-->}[ur]\ar@{-->}[ul]
}
\eeq
}

\newcommand{\decMediationSimple}
[0]{(Unconfounded Mediation,
from Ref.\cite{pearl-2019review})

If $G_{hypo}=$
$\xymatrix{
&\rvm\ar[rd]
\\
\rvd\ar[rr]\ar[ru]
&&\rvy}$
then

\beq
P(y|\cald\rvd=d, \cali_\rvm\rvd=d')=
\sum_m
P(y|d, m)
P(m|d')
\eeq

\beq
\xymatrix{
\cali\rvd=d'\ar[rd]
\\
\cald\rvd=d\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
d'\ar[r]
&\sum m\ar[rd]
\\
d\ar[rr]
&&y}
\eeq
}

\newcommand{\decMediationPlus}
[0]{(Mediation
with universal prior $\rvxi$
and universal confounder $\rvu$,
from Ref.\cite{pearl-2019review})

If $G_{hypo}=$
$\xymatrix{
&*++[F-o]{\rvu}\ar[dl]
\ar[ddr]\ar[ddl]\ar[d]
\\
\rvxi\ar[rrd]\ar[d]\ar[r]
&\rvm\ar[rd]
\\
\rvd\ar[rr]\ar[ru]
&&\rvy}$
then

\beq
P(y|\cald\rvd=d, \cali_\rvm\rvd=d')=
\sum_\xi
\sum_m
P(y|d, m, \xi)
P(m|d', \xi)P(\xi)
\eeq

\beq
\xymatrix{
\cali\rvd=d'\ar[rd]
\\
\cald\rvd=d\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
d'\ar@/_1pc/[rr]
&\EE\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
d\ar[rrr]
&&&y}
\eeq
}

\newcommand{\SeqBackDoorConclusion}[0]{

}

\newcommand{\decSeqBackDoor}[0]{(Sequential
backdoor (SBD) adjustment formula,
from Ref.\cite{pearl-robins-95})

If $G_{hypo}=$
\xymatrix{
\rvz_0\ar[r]\ar@/^1pc/[rr]\ar[drrr]
\ar[dd]
&\rvz_1\ar[r]\ar[drr]
\ar[dd]
&\rvz_2\ar[dr]
\ar[dd]
\\
&&&\rvy
\\
\rvx_0\ar[uur]\ar[uurr]\ar[urrr]
\ar[r]\ar@/_1pc/[rr]
&\rvx_1\ar[uur]
\ar[urr]\ar[r]
&\rvx_2
\ar[ur]
}
then

\beq
P(y|\cald \rvx^3=x^3)
=
\calq(y|x^3)
\eeq
\beq
\xymatrix{\\
\cald \rvx^3=x^3\ar[r]&y}
\xymatrix{\\=}
\xymatrix{
\EE z_0\ar[r]\ar@/^1pc/[rr]
\ar[drrr]
&\sum z_1\ar[r]
\ar[drr]
&\sum z_2
\ar[dr]
\\
&&&y
\\
x_0\ar[uur]\ar[uurr]
\ar[urrr]
&x_1\ar[uur]
\ar[urr]
&x_2
\ar[ur]
}
\eeq
The result
shown here for $n=3$
is true for any integer $n\geq 1$.
}

\newcommand{\decSBBackDoorConclusion}[0]{
\beq
P(y|\cald\rvx=x)
=\sum_z P(y|x, z, \rvs=1)P(z)
\eeq

\beq
\xymatrix{
%\rvs=1
%\ar[rd]
\\
\cald\rvx=x\ar[r]
&y
}
\\
\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[dr]
&\EE z\ar[d]
\\
x\ar[r]&y
}
\eeq
}

\newcommand{\decSBBackDoor}[0]{
 (Selection Bias (SB) Backdoor
Adjustment Formula,
from Ref.\cite{bare-sb-removal})
\\
\\
If $G_{hypo}=$
$
\xymatrix{
\rvs\ar[d]\ar[r]\ar@/^1pc/[rr]
&\rvz^-\ar[ld]\ar[d]\ar[r]
&\rvz^+
\\
\rvx\ar[rru]\ar[r]
&\rvy
}$
where $\rvs\in\bool$
is a bnet-switch and
$\rvz=(\rvz^-, \rvz^+)$,
then
\decSBBackDoorConclusion
}
