\chapter{LDEN with feedback loops}\label{ch-LDEN-feedback}

This chapter assumes that
the reader has read Chapter 
\ref{ch-LDEN} on LDEN  (linear
deterministic with external noise) diagrams
and Section \ref{sec-z-transform} on the Z-transform.
The algorithm described in this 
chapter
was first published here, and 
is implemented 
in my software SCuMpy (see Ref.\cite{scumpy}).

\begin{figure}[h!]
$$
\begin{array}{cc}
\xymatrix@R=4pc{
\rvx_0\ar@(ul,ur)@[green]@{-->}[]^{\beta_{0|0}}
\ar@[green]@{-->}@/_3pc/[d]_{\beta_{1|0}}
\ar[d]^{\alp_{1|0}}
\\
\rvx_1\ar@(dl,dr)@[green]@{-->}[]_{\beta_{1|1}}
\ar@[green]@{-->}@/_3pc/[u]_{\beta_{0|1}}
}
&
\xymatrix{
\rvx_0^{[1]}\ar[d]
\ar@[green][r]\ar@[green][rd]
&\rvx_0^{[2]}\ar[d]
\ar@[green][r]\ar@[green][rd]
&\rvx_0^{[3]}\ar[d]
\\
\rvx_1^{[1]}\ar@[green][r]\ar@[green][ru]
&\rvx_1^{[2]}\ar@[green][r]\ar@[green][ru]
&\rvx_1^{[3]}
}
\\
(a)&(b)
\end{array}
$$
\caption{
LDEN diagrams with two $\rvx_j$
nodes
(exogenous nodes $\rvu_j$
not shown). Figure $(a)$ shows a single time-slice
with feedback loops. Figure $(b)$ is an
\qt{unrolled} version of figure $(a)$
showing 3 time-slices.
LDEN diagrams with feedback loops are
a special case of Dynamic Bayesian networks  (DBN) (see Chapter \ref{ch-dyn-bnets})}
\label{fig-LDEN-fb-2nds}
\end{figure}

Consider Fig.\ref{fig-LDEN-fb-2nds}
of an LDEN diagram
with feedback loops. It represents the
following two \qt{structural equations}:

\beqa
\rvx_0^{[n+1]} &=& \underbrace{\sum_{j=0}^1\beta_{0|j}\rvx_j^{[n]}
 }_{\text{from past}}
 +\rvu_0^{[n+1]}
\\
\rvx_1^{[n+1]} &=&
\underbrace{\sum_{j=0}^1\beta_{1|j}\rvx_j^{[n]}
}_{\text{from past}}
+  \alp_{1|0}\rvx_0^{[n+1]} + \rvu_1^{[n+1]}
\eeqa

for $n=0,1,2, \dots$ with
$
\rvx^{[0]}_j=
\rvu^{[0]}_j=0$ for all $j$.

From the
results of Section \ref{sec-z-transform}, we
conclude that


\beq
\calz(\rvx^{[n+1]}_j)
=
z\left(
\TIL{\rvx}_j(z)
-z
\rvx^{[0]}_j
\right)= z\TIL{\rvx}_j(z)
\eeq

\beq
\calz(\rvu^{[n+1]}_j)
= z\TIL{\rvu}_j(z)
\eeq
Therefore, in $z$-space, the
two structural equations are
as follows:

\beqa
z\TIL{\rvx}_0(z) &=& \sum_{j=0}^1\beta_{0|j}
\TIL{\rvx}_j(z)
 +z\TIL{\rvu}_0(z)
\\
z\TIL{\rvx}_1(z) &=&
\sum_{j=0}^1\beta_{1|j}\TIL{\rvx}_j(z)
+  \alp_{1|0}z\TIL{\rvx}_0(z) + z\TIL{\rvu}_1(z)
\eeqa
We can express these two $z$-space structural 
equations in matrix form. 
Let
 
\beq
\TIL{x}=\left[
\begin{array}{c}
\TIL{x}_0
\\
\TIL{x}_1
\end{array}
\right],
\quad
\TIL{u}=\left[
\begin{array}{c}
\TIL{u}_0
\\
\TIL{u}_1
\end{array}
\right]
,\quad
A=\left[
\begin{array}{cc}
0
&0
\\
\alp_{1|0}
&0
\end{array}
\right]
,\quad
B=\left[
\begin{array}{cc}
\beta_{0|0}
&\beta_{0|1}
\\
\beta_{1|0}
&\beta_{1|1}
\end{array}
\right]
\eeq

\beq
\indi_A = 1 - A
\eeq

\beq
M(z)= \indi_A -B/z
\eeq
Then the two $z$-space structural equations 
reduce to the single matrix equation:

\beq
M(z)\TIL{x}(z) =\TIL{u}(z)
\eeq
If the DAG for a single
time-slice has $N>2$ nodes, then this matrix equation is still valid. In that case,
$A$  and $B$ must be $N\times N$ matrices.
The graph for a single time slice is 
acyclic (i.e., a DAG), so we 
can order its nodes topologically.
This just means
that $\rvx_i$ is a child of
$\rvx_j$ if $i>j$. If the nodes are
indexed topologically,
then $\alpha_{i|j}=0$ for $i\leq j$,
so matrix $A$ is strictly lower diagonal.
Henceforth, everything we say
will be valid for an arbitrary number $N\geq 2$ of nodes.
 

For $\rva = \rvx, \rvu$, let
\beq
[C_{\rva}^{[n]}]_{i,j} =\av{\rva_i^{[n]}, \rva_j^{[n]}},
\quad
[C_{\rva}^{[n, n+1]}]_{i,j} =\av{\rva_i^{[n]}, \rva_j^{[n+1]}}
\eeq
and

\beq
[C_{\TIL{\rva}}^{z_1,z_2}]_{i,j} =\av{\TIL{\rva}_i(z_1), \TIL{\rva}_j(z_2)},
\eeq



Let 

$\calc$ = single time covariance matrices $[C^{[n]}_\rvx]_{i,j}=\langle \underline{x}_i^{[n]}, \underline{x}_j^{[n]}\rangle$ and $[C^{[n+1]}_\rvx]_{i,j}=\langle \underline{x}_i^{[n+1]}, \underline{x}_j^{[n+1]}\rangle$, and two-times covariance matrix $[C^{[n, n+1]}_\rvx]_{i,j}=\langle \underline{x}_i^{[n]}, \underline{x}_j^{[n+1]}\rangle$.

$A=$ strictly lower triangular matrix with entries $\alpha_{i|j}$ = gain of arrow 
$x^{[n]}_j\rightarrow x^{[n]}_i$

$B=$ matrix with entries $\beta_{i|j}$ = gain of arrow 
$x^{[n]}_j\rightarrow x^{[n+1]}_i$

The rest of this chapter will
be dedicated to 
accomplishing the following 2 tasks:

\begin{enumerate}
\item
Express $\calc$ in terms of $A$ and $B$

\item
Express $A$ and $B$ in terms of $\calc$

\end{enumerate}
Due to the linearity of the model,
we will find that these two tasks
can be accomplished exactly, in closed form.



\begin{claim}
$C_\rvx^{[n]}=\av{\rvx^{[n]},\rvx^{[n]T}}$
satisfies
\beq
C_\rvx^{[n]}= G^{n-1}\; C_\rvx^{[1]} \;(G^T)^{n-1}
\eeq
for $n=1,2,3 \ldots$,
where the \qt{growth matrix} $G$ is given by

\beq
G=\indi_A^{-1}B
\eeq
and the \qt{initial covariance matrix}
$C_\rvx^{[1]}=\av{\rvx^{[1]},\rvx^{[1]T}}$ by

\beq C_\rvx^{[1]} =
\indi_A^{-1}
diag(\s^2_{\rvu_i})
 (\indi_A^{-1})^T
\eeq

Once we know the single time covariance matrix $\av{\rvx^{[n]},\rvx^{[n]T}}$,
the 2 times covariance matrix $\av{\rvx^{[n]},\rvx^{[n+1]T}}$ can be found using the equation

\beq
\av{\rvx^{[n]}, \rvx^{[n+1]T}}=
\av{\rvx^{[n]}, \rvx^{[n]T}}G^T
\label{eq-2-time-one-g}
\eeq

\end{claim}
\proof

Recall from Section \ref{sec-z-transform}
that

Z-transform of same-time product
\beq
x_1^{[n]} x_2^{[n]}=
\calz^{-1}\left[
\frac{1}{2\pi i}
\oint_C \frac{dw}{w}\;
\TIL{x}_1(w)
\TIL{x}_2\left(
\frac{z}{w}
\right)
\right]
\eeq


It follows that
\beq
\underbrace{
\av{\rvx^{[n]},\rvx^{[n]T}}
}_{C^{[n]}_\rvx}
=
\calz^{-1}\left[
\frac{1}{2\pi i}
\oint_C \frac{dw}{w}\;
\underbrace{
\av{
\TIL{\rvx}(w),
\TIL{\rvx}^T\left(
\frac{z}{w}
\right)}
}_{C^{w,z/w}_{\TIL{\rvx}}}
\right]
\eeq
where

\beq
C_{\TIL{\rvx}}^{w, z/w}=
M^{-1}(w)
C_{\TIL{\rvu}}^{w,z/w}
(M^{-1})^T(z/w)
\eeq
so therefore


\beq
C^{[n]}_\rvx
=
\calz^{-1}
\left[
\frac{1}{2\pi i}
\oint_C \frac{dw}{w}\;
M^{-1}(w)C_{\TIL{\rvu}}^{w,z/w}
(M^{-1})^T(z/w)
\right]
\label{eq-cov-missing-uutilde}
\eeq
\begin{mdframed}[hidealllines=true,backgroundcolor=blue!10]
At this
juncture,
we would like to
find an expression for $C_{\TIL{\rvu}}^{w,z/w}$
to plug into Eq.(\ref{eq-cov-missing-uutilde}).
This shaded frame is dedicated
to finding such an expression.

For all $i$,
$\rvu_i^{[0]}=0$.
Keep in mind that $\heavy_0^{[n]}=1$ at $n=0$,
so we must have



\beq
\av{\rvu_i^{[n]},\rvu_j^{[n]}
} =\delta(i,j)\s^2_{\rvu_i}
\heavy_1^{[n]}
\eeq


Recall from Section \ref{sec-z-transform}
that:

Z-transform of Heavyside unit step function:
\beq\calz\left[
a^n \heavy_0^{[n]}\right]=
\frac{1}{1-a/z}=
\frac{z}{z-a}
\quad \text{for $|z|>|a|$}
\label{eq-z-transform-heavy}
\eeq

Z-transform of discrete Kronecker
delta function:
\beq
\calz[\delta_{n_0}^{[n]}] = z^{-n_0}
\eeq

Unit step function
as a sum of delta functions:
\beq
H_0^{[n]}=\sum_{k=0}^\infty\delta^{[n]}_k
\eeq
It follows that

\beq
\heavy^{[n]}_{1} = 
\heavy^{[n]}_{0} -\delta^{[n]}_0
\eeq

\beqa
\calz[\heavy^{[n]}_{1}]
&=&
\calz[\heavy^{[n]}_{0}]-
\calz[\delta^{[n]}_0]
\\
&=&
\frac{z}{z-1}-1
\\
&=&
\frac{1}{z-1}
\eeqa
Therefore,
\beq
\calz[\av{\rvu_i^{[n]},\rvu_j^{[n]}}]
= \delta(i,j)\s^2_{\rvu_i}\frac{1}{z-1}
\label{eq-cov-un-un}
\eeq
We can satisfy Eq.(\ref{eq-cov-un-un})
and the following equation

\beq
\calz[\av{\rvu_i^{[n]}, \rvu_j^{[n]}}]=
\frac{1}{2\pi i}
\oint_C \frac{dw}{w}\;
\av{\TIL{\rvu}_i(w),
\TIL{\rvu}_j\left(
\frac{z}{w}
\right)}
\label{eq-contour-u-tilde}
\eeq
if we set

\beq
\av{\TIL{\rvu}_i(w),\TIL{\rvu}_j(z/w)}
= \delta(i,j)\s^2_{\rvu_i}\frac{1}{z-1}
\approx
\delta(i,j)\s^2_{\rvu_i}\frac{1}{z}
\label{eq-utilde-utilde}
\eeq
I believe that approximating $1/(z-1)$ 
by $1/z$ leads to a very small
change in the subsequent results 
of this chapter. This 
approximation merely shifts a pole 
from $z=1$ to $z=0$,
and we will only use this expression
to do complex contour integrals
over a circle in the
complex plane with radius $|z|>>1$.
\end{mdframed}

Plugging
 Eq.(\ref{eq-utilde-utilde}) into
 Eq.(\ref{eq-cov-missing-uutilde})
 now yields
\beq
C^{[n]}_\rvx
=
\calz^{-1}
\left[
\frac{1}{2\pi i}
\oint_C \frac{dw}{w}\;
M^{-1}(w)\frac{diag(\s^2_{\rvu_i})}
{z}
(M^{-1})^T(z/w)
\right]
\eeq
where

\beqa
M^{-1}(w)&=&(\indi_A - B/w)^{-1}
\\
&=&
(\indi_Aw -B)^{-1}w
\\
&=&
(w-\indi_A^{-1}B)^{-1}w\indi_A^{-1}
\\
&=&
\frac{w}
{w-\indi_A^{-1}B}
\indi_A^{-1}
\eeqa
and

\beqa
(M^{-1})^T(z/w)&=&
(\indi_A^{-1})^T
\frac{z/w}
{z/w-B^T(\indi_A^{-1})^T}
\\
&=&
(\indi_A^{-1})^T
\frac{z}
{z-B^T(\indi_A^{-1})^Tw}
\eeqa

Next, we will avail
ourselves of 2 more 
results from Section \ref{sec-z-transform}:

Inverse Z-transform:
\beq
\underbrace{\calz^{-1}[\TIL{x}(z)]}
_{x^{[n]}}=
\frac{1}{2\pi i}
\oint_C dz\;
\TIL{x}(z)z^{n-1}
\label{eq-z-transform-inverse}
\eeq

Time delay:
\beq
x^{[n-1]}=
\calz^{-1}\left[
\frac{1}{z}\TIL{x}(z)\right] 
\label{eq-z-delay}
\eeq

Using Eq.(\ref{eq-z-transform-heavy})
and Eq.(\ref{eq-z-delay}), we get
\beq
\calz^{-1}_z\left[
\frac{1}{z}
(M^{-1})^T(z/w)\right]
=
 (\indi_A^{-1})^T
\left[B^T(\indi_A^{-1})^Tw\right]^{n-1}
\eeq

\begin{align}
C_\rvx^{[n]}
&=
\frac{1}{2\pi i}
\oint_C \frac{dw}{w}\;
M^{-1}(w)
diag(\s^2_{\rvu_i})
\calz^{-1}_z\left[\frac{1}{z}
(M^{-1})^T(z/w)\right]
\\
&=
\left[
\frac{1}{2\pi i}
\oint_C dw\;
\frac{w^{n-1}}
{w-\indi_A^{-1}B}
\right]
\indi_A^{-1}
diag(\s^2_{\rvu_i})
 (\indi_A^{-1})^T
\left[B^T(\indi_A^{-1})^T\right]^{n-1}
\\
&=
\calz_{w}^{-1}
\left[
\frac{1}
{w-\indi_A^{-1}B}
\right]
\indi_A^{-1}
diag(\s^2_{\rvu_i})
 (\indi_A^{-1})^T
\left[B^T(\indi_A^{-1})^T\right]^{n-1}
\quad\text{(by Eq.(\ref{eq-z-transform-inverse}))}
\\
&=
[\indi_A^{-1}B]^{n-1}
\indi_A^{-1}
diag(\s^2_{\rvu_i})
 (\indi_A^{-1})^T
\left[B^T(\indi_A^{-1})^T\right]^{n-1}
\;\text{(by Eqs.(\ref{eq-z-transform-heavy})(\ref{eq-z-delay}))}
\end{align}

Eq.(\ref{eq-2-time-one-g})
is the same as Eq.(\ref{eq-A-B-linear-full}),
and the latter is proven below.
\qed

The structural equations in $n$ (i.e., time) space,
and in matrix form, can be expressed as:
\beq
\rvx^{[n+1]} = B\rvx^{[n]} + A\rvx^{[n+1]}
+ \rvu^{[n+1]}
\label{eq-struc-time}
\eeq

Applying $\av{\cdot, \rvx^{[n]T} }$
from the right to Eq.(\ref{eq-struc-time}), we get

\beq 
(1-A)\av{\rvx^{[n+1]}, \rvx^{[n]T}}=
B \av{\rvx^{[n]}, \rvx^{[n]T}}
+ \av{\rvu^{[n+1]}, \rvx^{[n]T}}
\eeq
Note that

\beq
\av{\rvu^{[n+1]}, \rvx^{[n]T}}=0
\eeq
by causality, 
because the $\rvx^{[n]}$
can't be affected by the noise in the future.
Therefore

\beq
\boxed{
\indi_A\av{\rvx^{[n]}, \rvx^{[n+1]T}}^T=
B \av{\rvx^{[n]}, \rvx^{[n]T}}}
\label{eq-A-B-linear-full}
\eeq


Applying $\av{\cdot, \rvx^{[n+1]T} }$
from the right to Eq.(\ref{eq-struc-time}), we get
\beq
\av{\rvx^{[n+1]}, \rvx^{[n+1]T} }
= B
\av{\rvx^{[n]},\rvx^{[n+1]T} } + A\av{\rvx^{[n+1]},\rvx^{[n+1]T} }
+ \av{\rvu^{[n+1]}, \rvx^{[n+1]T} }
\eeq

For any matrix $A$,
define $SL(A)$ 
to be the strictly lower triangular
matrix obtained from matrix $A$ by
setting to zero all entries 
on the main diagonal of $A$ and above it.
Note that

\beq 
SL(\av{\rvu^{[n+1]}, \rvx^{[n+1]T} })=0
\eeq
by causality,
because the nodes are assumed to be topologically ordered (when the feedback
arrows are removed),
and the future noise $\rvu^{[n+1]}_i$
cannot be
correlated with $\rvx^{[n+1]}_j$
where  $i>j$.
Thus,

\beq
\boxed{
SL\left(\av{\rvx^{[n+1]}, \rvx^{[n+1]^T} }
-\underbrace{B
\av{\rvx^{[n]},\rvx^{[n+1]T} }
}_{K}
\right)
= SL\left(A\av{\rvx^{[n+1]},\rvx^{[n+1]^T} }\right)}
\label{eq-A-B-linear-sl}
\eeq

$A$ and $B$ satisfy a system of 2 linear equations (the two boxed
equations above, Eq.(\ref{eq-A-B-linear-full})
and Eq.(\ref{eq-A-B-linear-sl})) with two unknowns $A,B$.
To solve that system of 2 equations in $(A, B)$, we can:

\begin{enumerate}
\item First solve
Eq.(\ref{eq-A-B-linear-sl})) for $A$ in terms of $B$ and $\calc$, thus obtaining $A(B,
\calc)$.
To do this step,
we can use the same method that was used
in Chapter \ref{ch-LDEN},
for LDEN without feedback loops, to solve for
$A$ when $K= 0$.
 
Caveat: Eq.(\ref{eq-A-B-linear-sl})) for $A$ has the same number of equations as unknowns as long as, for all $i>j$,
$\alp_{i|j}\neq 0$. If some of those $\alp_{i|j}$ are zero, then we get an
overdetermined system of linear equations.
To solve that problem, for every 
$i, j$ such that $i>j$ and  $\alp_{i|j}= 0$,
replace that unknown by $\av{\rvx_i^{[n]},
\rvx_j^{[n]}}$.

\item Then we can substitute $A(B, \calc)$ into the remaining equation
Eq.(\ref{eq-A-B-linear-full})
to obtain $B(\calc)$. 

Caveat: Eq.(\ref{eq-A-B-linear-full})) for $B$ has the same number of equations as unknowns as long as
all $\beta_{i|j}\neq 0$ for all $i,j$. If some of those $\beta_{i|j}$ are zero, then we get an
overdetermined system of linear equations.
To solve that problem, for every 
$i, j$ such that $\beta_{i|j}= 0$,
replace that unknown by $\av{\rvx_j^{[n]},
\rvx_i^{[n+1]}}$.

\item Finally, we can substitute $B(\calc)$ into $A(B,
\calc)$ to get $A(B(\calc), \calc)$.
\end{enumerate}
 
 


