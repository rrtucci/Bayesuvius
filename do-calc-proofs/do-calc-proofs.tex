\chapter{Do Calculus proofs}
\label{ch-do-calc-proofs}

In Chapter \ref{ch-do-calc},
we explained Do Calculus,
but referred to this
chapter for proofs
of claims that
use Do Calculus.
In this chapter, we've
aggregated
 all proofs, from
throughout the book,
of claims that use Do Calculus.

Note that even though the 3
rules of Do Calculus
are great for proving
adjustment formulae
for general classes of DAGs,
they are sometimes overkill
for proving
 adjustment formulae
for a single specific DAG.
Indeed, since the
 3 rules of Do Calculus
are a consequence
of the d-separation theorem, it follows that
all adjustment
formulae should be
provable from first principles,
assuming only
the d-separation theorem
and the standard rules of
probability theory.

In this chapter, we use the
 following conventions for bnet diagrams.

\bnetInstantiations

\hiddenNodes

Selection diagrams
with selection nodes 
 are discussed 
in Chapter \ref{ch-transport}.
\selectionGraphs

Some identities
that are used in this chapter:

\begin{enumerate}
\item
\beq
P(y|x_1, x_2)= 
\sum_a P(y|a, x_1, x_2)P(a|x_1, x_2)
\;.
\eeq

\beq
\xymatrix{
x_1\ar[rrd]
\\
&&y
\\
x_2\ar[urr]
}
\xymatrix{\\=}
\xymatrix{
x_1\ar[rd]\ar[drr]
\\
&\sum a\ar[r]
&y
\\
x_2\ar[ru]\ar[rru]
}
\label{eq-univ-bdoor}
\;.
\eeq
One can describe
this identity as
``giving $\rvy$
a universal backdoor", 
because $\sum a$ is a backdoor
(i.e., input) to $y$, and $\sum a$
is universal in the sense that it
 is entered
by every arrow that enters $y$
except $\sum a$ itself.

\item

\beq
\sum_a 
P(a|x_1, x_2)=1
\eeq

\beq
\xymatrix@R=.3pc{
x_1\ar[dr]
\\
&\sum a\ar[r]_0&&=1
\\
x_2\ar[ur]
}
\label{eq-collider-sum}
\eeq
One can describe this
identity as ``summing over 
the values of a collider node
which has no emerging 
arrows"\footnote{A zeroed 
arrow means the same as no arrow.}.
Eq.(\ref{eq-collider-sum})
can be understood as an 
edge case (when $\rvy=\emptyset$)
of Eq.(\ref{eq-univ-bdoor}).

\item
\beq
\sum_a P(x_2|a)P(a|x_1)=P(x_2|x_1)
\eeq

\beq
\xymatrix{
x_1\ar[r]
&\sum a\ar[r]
&x_2
&=&
x_1\ar[r]
&x_2}
\label{eq-med-sum}
\eeq
One can describe this
identity as
``summing over the 
values of a mediator node".

\item
\beq
P(x)=\sum_a P(x|a)P(a)=
\sum_b P(x|b)P(b)
\eeq

\beq
\xymatrix{
P(x)&=&
\ar[r]_0
&\sum a\ar[r]
&x
&=&
\ar[r]_0
&\sum b\ar[r]
&x
}
\label{eq-diff-priors}
\eeq
One can describe 
this identity 
as ``averaging
over different 
priors".
Eq.(\ref{eq-diff-priors})
can be understood as 
an edge case of Eq.(\ref{eq-med-sum}).

\end{enumerate}

A {\bf do-adjustment 
formula} expresses
a {\bf do-query} (i.e., 
a conditional probability
with do operators
in its condition) by
an equivalent expression
without do operators.
The equivalent expression must 
satisfy 2 constraints
to be discussed  below.
If a do-adjustment formula
exists for a
particular do-query, 
then we say the do-query is
 {\bf do-identifiable (DI)}.
% \footnote{
%To prove that a do-query $P(y|\cald\rvx=x, z)$
%is do-identifiable
%for a graph $G$,
%just prove that $\rvy\perp\rvx|\rvz$
%in $\call_\rvx G$. 
%This is called Rule 2 of Do Calculus,
%but it is easy to understand just from
%the d-separation theorem.
%Info can be transmitted 
%between $\rvy$ and $\rvx$ by
%either (1) paths
%in $\cald_\rvx G$
%or (2) paths in $\call_\rvx G$.
%$P(y|\cald\rvx=x, z)=
%P(y|x, z)$
%means the info is being transmitted only
%by (1).
%So the Rule 2 premise is checking
%that no info is being transmitted
%by (2). }
A {\bf do-transport formula}
is a relationship between 2  do-queries.
This chapter deals with both
do-adjustment and do-transport
formulae.

See Fig.\ref{fig-iden-noniden}
for some simple
examples of of 
bnets for which
the do-query $P(y|\cald\rvx=x)$
is
DI
and non-DI.

\begin{figure}[h!]
$$
\begin{array}{ccc}
\xymatrix{
&\rvz\ar[ld]\ar[rd]
\\
\rvx\ar[rr]&&\rvy
}
&\quad\quad&
\xymatrix{
&*++[F-o]{\rvz}\ar[ld]\ar[rd]
\\
\rvx\ar[rr]&&\rvy
}
\\
(a) \text{$P(y|\cald\rvx=x)$ is DI}
&&(b) \text{$P(y|\cald\rvx=x)$ is non-DI}
\end{array}
$$
\caption{Examples of 
bnets for which
the do-query $P(y|\cald\rvx=x)$
is
DI
and non-DI.
}
\label{fig-iden-noniden}
\end{figure}

In general, the
following is always true,
whether it applies to a bnet
with or without hidden nodes:

\beq
P(y|\cald\rvx=x)=P(y|x)
\eeq
However, the right hand side of this equation is 
seldom a valid adjustment formula
for this query.
We define a valid adjustment formula
for query
$P(y|\cald\rvx=x)$
to be a bnet instantiation diagram
that satisfies the
following 2 constraints:
Call the original bnet $G_0$

\begin{enumerate}
\item {\bf(structural constraint)}

The adjustment formula must be
representable by a bnet instantiation 
that has a DAG structure identical
to the DAG structure of $G_0$,
except that arrows entering node
$\rvx$ have been amputated.
All nodes  of that instatiation, except
nodes  $x$ and $y$,
must be summed over.

\item {\bf (probabilitistic constraint)}

\begin{itemize}
\item If $G_0$ has hidden nodes,
these must be renamed and 
assigned a TPM that
can be constructed 
from the {\it observable }
TPMs of $G_0$.
\item The observable
nodes of $G_0$ 
with hidden
parents, must also be assigned a TPM that
can be constructed 
from the {\it observable }
TPMs of $G_0$.
\item The observable
nodes of $G_0$ with no hidden
parents, must be assigned
the same TPM as they have in $G_0$.
\end{itemize}
\end{enumerate}
The reason for
these 2 constraints
is that we want
an adjustment
formula to utilize 
as much information
as possible
from the original bnet $G_0$.
Adjustment formulae are
always numerically equal to $P(y|x)$,
but when you
effect that reduction,
you throw
away a lot of
valuable information
carried by $G_0$.



Based on these 2 constraints,
we can easily see why the 
query $P(y|\cald\rvx=x)$
is DI (resp., non-DI)
for bnet $(a)$ (resp., bnet $(b)$)
of Fig.\ref{fig-iden-noniden}.
For bnet $(a)$, after amputating arrow 
$z\rarrow x$ and summing over node $z$,
we get 

\beqa
P(y|\cald\rvx=x)
&=&
\xymatrix{
\sum z\ar[dr]
\\
x\ar[r]
&y
}
\label{eq-simplest-identifiable}
\eeqa
The right hand
side of Eq.(\ref{eq-simplest-identifiable})
is a valid
adjustment formula
because it satisfies both constraints.
For bnet $(b)$,
if we amputate arrow 
$z\rarrow x$ 
and sum over node $z$,
we get

\beqa
P(y|\cald \rvx =x)
&=&
\xymatrix{
*++[F-o]{\sum z}\ar[rd]
\\
x\ar[r]
&y
}
\label{eq-simplest-non-DI}
\eeqa
The right hand
side of Eq.(\ref{eq-simplest-non-DI})
is not a valid
adjustment formula
because it violates the
second constraint. Furthermore,
try as we may,  there
is no way to replace the sum over
hidden  node $z$ by a sum over an observed node,
such that 
constraint 2 is satisfied.





\begin{claim} 
\label{cl-decBackDoor}
\decBackDoor
\end{claim}

\proof

{\bf * proof 1:}
\beqa
P(y|\cald\rvx=x)
&=&
\xymatrix{
\sum z\ar[dr]
\\
x\ar[r]
&y
}
\eeqa


{\bf * proof 2:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)
=
\sum_z
P(y|\cald\rvx=x, z)
P(z|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z|\cald\rvx=x)$
\\
\quad $P(y|\cald \rvx=x, z)\rarrow
P(y|x, z)$
\\
\quad  by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvy\perp\rvx|\rvz$ in
$\call_\rvx\cald_\emptyset G:
\xymatrix{
\rvz\ar[d]\ar[rd]
\\
\rvx
&\rvy
}$
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z)$
\\
\quad $P(z|\cald \rvx=x)\rarrow
P(z)$
\\
\quad  by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvz\perp \rvx$ in
$\cald_\rvx \cald_\emptyset G:
\xymatrix{
\rvz\ar[rd]
\\
\rvx\ar[r]
&\rvy
}
$
\end{longtable}
\qed




\begin{claim}
\label{cl-decFrontDoor}
\decFrontDoor
\end{claim}

\proof


{\bf * proof 1:}
\\
\beqa
P(y|\cald\rvx=x)
&=&
\xymatrix{
&*++[F-o]{\sum c}\ar[rd]
\\
x\ar[r]
&\sum m\ar[r]
&y
}
\\
&=&
\xymatrix{
\sum x'\ar[r]
&*++[F-o]{\sum c}\ar[rd]
\\
x\ar[r]
&\sum m\ar[r]
&y
}
\\
&=&
\xymatrix{
&\sum x'\ar[dr]
\\
x\ar[r]&\sum m\ar[r]
&y
}
\eeqa


{\bf * proof 2:}
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_m
P(y|\cald\rvx=x, m)
P(m|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m|\cald\rvx=x)$
\\
\quad $P(y|\cald\rvx=x, m)\rarrow
P(y|\cald\rvx=x, \cald m=m)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad $\rvy\perp \rvm|\rvx$ in
$\call_\rvm\cald_\rvx G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m| x)$
\\
\quad $P(m|\cald\rvx=x)\rarrow P(m|x)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvm\perp \rvx$ in
$\call_\rvx\cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[ld]\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvx=x, \cald\rvm=m)
\rarrow
 P(y|\cald\rvm=m)$
\\
\quad by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvy\perp\rvx|\rvm$ in
$\cald_\rvx\cald_\rvm G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|\cald\rvm=m, x')
P(x'|\cald\rvm=m)
P(m|x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|m, x')
P(x'|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvm=m, x')
\rarrow
\quad P(y|m, x')$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvy\perp\rvm|\rvx$ in
$\call_\rvm \cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]\ar[ld]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|m, x')
P(x')
P(m|x)$
\\
\quad $P(x'|\cald\rvm=m)
\rarrow
P(x')$
\\
\quad by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvx\perp\rvm$ in
$\cald_\rvm \cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]\ar[ld]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\end{longtable}
\qed



\begin{claim}
\label{cl-decNapkin}
\decNapkin
\end{claim}
\proof
\\
\begin{align}
P(y|\cald\rvx=x)&=
\xymatrix{
&*++[F-o]{\sum u_1}\ar[ddl]\ar[ddrr]
\\
&*++[F-o]{\sum u_2}\ar[dl]
\\
\sum w\ar[r]
&\sum z
&x\ar[r]
&\rvy
}
\\
&=
\xymatrix{
&*++[F-o]{\sum u_1}\ar[ddl]\ar[ddrr]
&&\sum z'\ar[ll]
\\
&*++[F-o]{\sum u_2}\ar[dl]
&&
\sum z''\ar[ll]
\\
\sum w\ar[r]
&\sum z
&x\ar[r]
&\rvy
}
\\
&=
\xymatrix{
&{\sum z'}\ar[ddl]\ar[ddrr]
\\
&{\sum z''}\ar[dl]
\\
\sum w\ar[r]
&\sum z
&x\ar[r]
&\rvy
}
\end{align}
\qed


\begin{claim}
\label{cl-decWhy}
\decWhy
\end{claim}
\proof
\beqa
P(y|\cald\rvz=z,x)
&=&
\xymatrix{
x\ar[d]\ar[drr]
\\
\sum w
&z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[u]\ar[urr]
}
\\
&=&
\xymatrix{
x\ar[d]\ar[drr]
\\
\sum w
&z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[u]\ar[urr]
&\sum w'\ar[l]
}
\\
&=&
\xymatrix{
x\ar[d]\ar[drr]
\\
\sum w
&z\ar[r]
&y
\\
{\sum w'}\ar[u]\ar[urr]
}
\\
&=&
\xymatrix{
x\ar[drr]
\\
\sum w\ar@/_1pc/[rr]
&z\ar[r]
&y
}
\eeqa
\qed

\begin{claim}
\label{cl-decTransportTrivial}
\decTransportTrivial
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, z, \rvs=1)=
P(y|x, z, \rvs=1)$
\\
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{
\\=
}
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
x\ar[rr]
&&y
}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportDirect}
\decTransportDirect
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, z, \rvs=1)=
P(y|\cald\rvx=x, z)$
\\
\xymatrix{
\rvs=1\ar[r]
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\begin{tabular}{l}
Because $\rvs\perp\rvy|\rvz$
\end{tabular}
\end{longtable}
Furthermore,
\begin{longtable}{l}
\color{red}
$P(y|\cald \rvx=x, \rvs=1)
=\sum_z P(y|\cald\rvx=x,z)P(z|\rvs=1)$
\\
\xymatrix{
\rvs=1\ar[r]
&\sum z\ar[rd]
\\
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportBox}
\decTransportBox
\end{claim}
\proof
\begin{longtable}{l}
\color{red}$
P(y|\cald\rvx=x, \rvs=1)
=\sum_{a}
P(y|\cald\rvx=x,a)P(a|\rvs=1)$
\\
\xymatrix{
\rvs=1\ar[r]
&*++[F-o]{\sum z}\ar[r]
&\sum a\ar[d]
\\
&\cald \rvx=x\ar[r]
&y
}\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum a\ar[d]
\\
\cald \rvx=x\ar[r]
&y
}
\end{longtable}
\qed

%\decTransportOne merged 
%with decDirectTransport

\begin{claim}
\label{cl-decTransportNon}
\decTransportNon
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P^*(y|\cald\rvx=x)=P^*(y|\cald\rvx=x)$
\\
\\
\xymatrix{
&*++[F-o]{\sum h}\ar[dr]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
Can't replace $\cald\rvx=x$ 
by $x$ because 
$\rvy\not\perp \rvx$ in 
$\call_\rvx G$.
Hence, Rule 2 not satisfied.
\qed


\begin{claim}
\label{cl-decTransportTwo}
\decTransportTwo
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald \rvx=x, \rvs=1)=
\sum_h P(y|\cald\rvx=x, h)P(h)$
\\
\\
\xymatrix{
\rvs=1\ar@/^1.5pc/[rr]
&*++[F-o]{\sum h}\ar[r]\ar[rd]
&\sum z
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&*++[F-o]{\sum h}\ar[rd]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\\
\color{red}
$=P(y|\cald\rvx=x)$
\\
\xymatrix{=}
\xymatrix{
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
\qed
\begin{claim}
\label{cl-decTransportThree}
\decTransportThree
\end{claim}
\proof

\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, \rvs=1)=
\sum_h
\sum_z P(y|h, z)P(h)
P(z|\cald\rvx=x, \rvs=1)$
\\
\\
\xymatrix{
\rvs=1\ar[rd]
&*++[F-o]{\sum \rvh}\ar[dr]
\\
\cald\rvx=x\ar[r]
&\sum z\ar[r]
&y
}
\\
\\
\color{red}
$=\sum_h\sum_z P(y|h,z)P(h|\cald\rvx=x)
P(z|x, \rvs=1)$
\\
\\
\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[rd]
&*++[F-o]{\sum \rvh}\ar[dr]
&\cald\rvx=x\ar[l]
\\
x\ar[r]
&\sum z\ar[r]
&y
}
\\
\color{red}
$=\sum_z P(y|\cald\rvx=x, z)P(z|x, \rvs=1)$
\\
$\xymatrix{\\=}\xymatrix{
\rvs=1\ar[rd]
&&\cald\rvx=x\ar[d]
\\
x\ar[r]
&\sum z\ar[r]
&y
}$
\end{longtable}
\qed

\begin{claim}
\label{cl-decMediationSimple}
\decMediationSimple
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvd=d,\cali\rvd=d')=
\sum_{m}
P(y|d,m)P(m|d')$
\\
\\
\xymatrix{
\cali\rvd=d'\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rr]
&&y}
\end{longtable}
\qed

\begin{claim}
\label{cl-decMediationPlus}
\decMediationPlus
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvd=d,\cali\rvd=d')=
\sum_{\xi, u}
\sum_{m}
P(y|d,m,\xi, u)P(m|d', \xi, u)
\underbrace{P(\xi|u)P(u)}_{P(\xi, u)}$
\\
\\
\xymatrix{
&&*++[F-o]{\sum u}\ar[ddr]
\ar[dl]\ar[d]
\\
\cali\rvd=d'\ar@/_1pc/[rr]
&\sum\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rrr]
&&&y}
\\
\color{red}
$=
\sum_{\xi}
\sum_{m}
P(y|d,m,\xi)P(m|d', \xi)
P(\xi)$
\\
\xymatrix{\\=}
\xymatrix{
\cali\rvd=d'\ar@/_1pc/[rr]
&\sum\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rrr]
&&&y}
\begin{tabular}{l}
We switch from averaging over\\ the
prior of $\xi, u$\\
to averaging over the\\
prior of $\xi$.
\end{tabular}
\end{longtable}
\qed

\begin{claim}
\label{cl-decSeqBackDoor}
\decSeqBackDoor
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx^3=x^3)=
\calq(y|x^3)$
\\
\xymatrix@C=.5pc{
\sum z_0\ar[r]\ar@/^1pc/[rr]
\ar[drrr]
&\sum z_1\ar[r]
\ar[drr]
&\sum z_2
\ar[dr]
\\
&&&y
\\
\cald\rvx_0=x_0\ar[uur]\ar[uurr]
\ar[urrr]
&\cald\rvx_1=x_1\ar[uur]
\ar[urr]
&\cald\rvx_2=x_2
\ar[ur]
}
\xymatrix{\\=}
\xymatrix@C=.9pc{
\sum z_0\ar[r]\ar@/^1pc/[rr]
\ar[drrr]
&\sum z_1\ar[r]
\ar[drr]
&\sum z_2
\ar[dr]
\\
&&&y
\\
x_0\ar[uur]\ar[uurr]
\ar[urrr]
&x_1\ar[uur]
\ar[urr]
&x_2
\ar[ur]
}
\begin{tabular}{l}
We can replace\\
$\cald\rvx_i=x_i$
by $x_i$ 
\\once all nodes
\\in bnet are
\\observed nodes. 
\end{tabular}
\end{longtable}
\qed

\begin{claim}
\label{cl-decSBBackDoor}
\decSBBackDoor
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx =x, \rvs=1)=
\sum_z
P(y|\cald\rvx=x, z)P(z^{<\rvx}|\rvs=1)
P(z^{>\rvx}|x,z^{<\rvx}, \rvs=1)$
\\
\\
\xymatrix{
\rvs=1\ar[r]\ar@/^1pc/[rr]
&\sum z^{<\rvx}\ar[d]\ar[r]
&\sum z^{>\rvx}
\\
\cald\rvx=x\ar[rru]\ar[r]
&y
}
\\
\color{red}
$= \sum_{z^{<\rvx}} P(y|\cald\rvx=x, z^{<\rvx})
P(z^{<\rvx}|\rvs=1)$
\\
\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum z^{<\rvx}\ar[d]
&
\\
\cald\rvx=x\ar[r]
&y
}
\\
\color{red}
$= \sum_z P(y|x, z)
P(z|\rvs=1)$
\\
\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum z\ar[d]
&
\\
x\ar[r]
&y
}
\begin{tabular}{l}
$\cald$ can be removed because there are\\
no sums over unobserved nodes.
\end{tabular}
\\
\color{red}
$= \sum_z P(y|x, z)
P(z)$
\\
\xymatrix{\\=}
\xymatrix{
&\sum z\ar[d]
&
\\
x\ar[r]
&y
}
\begin{tabular}{l}
$\rvs=1$ node can be removed\\ because
this expression must\\ equal
$P(y|x, \rvs=1)$. Furthermore,\\
$\rvy\perp\rvs|(\rvx,\rvz)$ 
in the hypothesis bnet.\\
Hence,  this expression must also
\\ equal $P(y|x)$.
\end{tabular}
\end{longtable}
\qed


%\input{do-calc-proofs/do-calc-proofs-limbo.tex}
