\chapter{Do Calculus proofs}
\label{ch-do-calc-proofs}

In Chapter \ref{ch-do-calc}
of Bayesuvius,
we explained Do Calculus
but referred to this
chapter for proofs
of claims that
use Do Calculus.
In this chapter, we've
aggregated
 all proofs, from
throughout the book,
of claims that use Do Calculus.

Note that even though the 3
rules of Do Calculus
are great for proving
adjustment formulas
for general classes of DAGs,
they are sometimes overkill
for proving
 adjustment formulas
for a single specific DAG.
After all,  the
 3 rules of Do Calculus
are a consequence
of the d-separation theorem.
Hence, all adjustment
formulas should be
provable from first principles,
assuming only
the d-separation theorem
and the standard rules of
probability theory.

We use the
 following conventions.
Random values are underlined
and their values are not.
For example, $\rva=a$ means
the random variable
$\rva$ takes the value $a$.
Diagrams
with nodes that are
underlined represent
Bayesian Networks (bnets)
and the same diagram
with the letters not underlined
represents a specific
instantiation of that bnet.
For example $\rva\rarrow\rvb$
represents the bnet with
conditional probability distribution
$P(b|a)$,
whereas  $a\rarrow b$
represents $P(b|a)$ itself.
Thus, the identity

\beq
P(y|x)= \sum_a P(y|a, x)P(a|x)
\eeq
can be represented graphically
by

\beq
\xymatrix{
x\ar[r]
&
y \quad = \quad}
\xymatrix{
\sum a\ar[dr]
\\
x\ar[r]\ar[u]
&y
}
\eeq
where $\sum a$
means the random variable
$\rva$ is summed over.

Unobserved nodes are
indicated by enclosing them
in a dashed circle.

\begin{claim} (Backdoor
Adjustment Formula)
\label{cl-backdoor-proof}

If
$
\xymatrix{
{\rvz}\ar[d]\ar[rd]
\\
\rvx\ar[r]&\rvy
}$
then

\beq
P(y|\cald \rvx = x)=
\sum_z
P(y|x,z)P(z)
\eeq
\beq
\xymatrix{
\cald\rvx=x\ar[r]
&y
\quad=\quad}
\xymatrix{
\sum z\ar[dr]
\\
x\ar[r]
&y
}
\eeq
\end{claim}

\proof

{\bf * proof 1:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=\sum_z
 P(y|\cald \rvx=x, z)P(z|\cald\rvx =x)$
\\
$\xymatrix{
\sum z\ar[dr]
\\
\cald \rvx=x\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
\sum z\ar[dr]
\\
\cald \rvx=x\ar[r]\ar[u]^0
&y
}
$
\\
\color{red}
$=\sum_z P(y|x,z)P(z|\cald\rvx=x)$
\\
\xymatrix{\\=}
\xymatrix{
\sum z\ar[dr]
\\
\cald \rvx=x\ar[u]^0
&y
\\x\ar[ur]
}
\begin{tabular}{l}
\\
\\
by Rule 2
\end{tabular}
\\
\color{red}
$=\sum_z P(y|x,z)P(z)$
\\
\xymatrix{\\
=}
\xymatrix{
\sum z\ar[dr]
\\
x\ar[r]
&y
}
\begin{tabular}{l}\\
\\
by Rule 3.
\\
No info transmission\\
between $\cald\rvx$ and $\rvz$.
\end{tabular}
\end{longtable}


{\bf * proof 2:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)
=
\sum_z
P(y|\cald\rvx=x, z)
P(z|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z|\cald\rvx=x)$
\\
\quad $P(y|\cald \rvx=x, z)\rarrow
P(y|x, z)$
\\
\quad  by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad 
$\call_\rvx\cald_\emptyset G:
\xymatrix{
\rvz\ar[d]\ar[rd]
\\
\rvx
&\rvy
}$
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z)$
\\
\quad $P(z|\cald \rvx=x)\rarrow
P(z)$
\\
\quad  by Rule 3: 
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\cald_\rvx \cald_\emptyset G:
\xymatrix{
\rvz\ar[rd]
\\
\rvx\ar[r]
&\rvy
}
$
\end{longtable}
.\qed


\begin{claim} (Frontdoor
Adjustment Formula)
\label{cl-frontdoor-proof}

If
$
\xymatrix{
&{\rvc}\ar[ld]\ar[rd]
\\
\rvx\ar[r]&\rvm\ar[r]&\rvy
}$
then
\beq
P(y|\cald \rvx = x)=
\sum_m
\left[
\sum_{c}P(y|c,m)P(c)
\right]P(m|x)
\eeq

\beq
\xymatrix{
\cald\rvx=x\ar[r]
&y
\quad=\quad}
\xymatrix{
&\sum c\ar[dr]
\\
xÂ´\ar[r]
&\sum m\ar[r]&y
}
\eeq
\end{claim}

\proof


{\bf * proof 1:}
\\
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_{m,c}
P(y|\cald\rvx=x, m, c)
P(m|\cald\rvx=x)$
\\
\\
\xymatrix{
&{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]
&\sum m\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
&{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]\ar@/_1.2pc/[rr]_0
&\sum m\ar[r]
&y
}
\\
\\
$\color{red}=
\sum_{m,c}
P(y|\cald\rvx=x, \cald\rvm=m, c)
P(m|\cald\rvx=x)$
\\
\xymatrix{\\=\sum_m }
\xymatrix{
&{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]\ar@/_1.2pc/[rr]_0
&m&y
\\
&\cald\rvm=m\ar[ru]
}
\begin{tabular}{l}
\\
by Rule 2
\end{tabular}
\\
$\color{red}=
\sum_{m,c}
P(y|\cald\rvx=x, \cald\rvm=m, c)
P(m| x)$
\\
\xymatrix{\\=\sum_m }
\xymatrix{
&\sum c\ar[dr]
\\
\cald\rvx=x\ar@/_1pc/[rr]_0
&m
&y
\\
x\ar[ru]
&\cald\rvm=m\ar[ru]
}
\begin{tabular}{l}
\\
by Rule 2
\end{tabular}
\\
$\color{red}=
\sum_{m,c}
P(y|\cald\rvm=m, c)
P(m|x)$
\\
\xymatrix{\\=\sum_m }
\xymatrix{
&\sum c\ar[dr]
\\
&m
&y
\\
x\ar[ru]
&\cald\rvm=m\ar[ru]
}
\begin{tabular}{l}
by Rule 3.\\
No info transmission\\
between $\cald\rvx$ and $\rvy$\\
if condition on $\cald \rvm$.
\end{tabular}
\\
$\color{red}=
\sum_{m,c}
P(y|\cald\rvm=m, c)
P(c|\cald\rvm=m)
P(m|x)$
\\
\xymatrix{\\=\sum_m}
\xymatrix{
&\sum c\ar[dr]
\\
&m
&y
\\
x\ar[ru]
&\cald\rvm=m\ar[ru]\ar@/_2pc/[uu]_0
}
\\
$\color{red}=
\sum_{m,c}
P(y|m, c)
P(c|\cald\rvm=m)
P(m|x)$
\\
\xymatrix{\\=\sum_m}
\xymatrix{
&\sum c\ar[dr]
&\cald\rvm=m\ar[l]^0
\\
&m\ar[r]
&y
\\
x\ar[ru]
}
\begin{tabular}{l}
\\
by Rule 2
\end{tabular}
\\
$\color{red}=
\sum_{m,c}
P(y|m, c)
P(c)
P(m|x)$
\\
\xymatrix{\\=}
\xymatrix{
&\sum c\ar[dr]
\\
x\ar[r]&\sum m\ar[r]
&y
}
\begin{tabular}{l}
\\
by Rule 3.
\\
No info transmission\\
between $\cald\rvm$ and $\rvc$.
\end{tabular}
\end{longtable}



{\bf * proof 2:}
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_m
P(y|\cald\rvx=x, m)
P(m|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m|\cald\rvx=x)$
\\
\quad $P(y|\cald\rvx=x, m)\rarrow
P(y|\cald\rvx=x, \cald m=m)$
\\
\quad by Rule 2: 
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad $\call_\rvm\cald_\rvx G:$
$\xymatrix{
&{\rvc}\ar[rd]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m| x)$
\\
\quad $P(m|\cald\rvx=x)\rarrow P(m|x)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad $\call_\rvx\cald_\emptyset G:$
$\xymatrix{
&{\rvc}\ar[ld]\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvx=x, \cald\rvm=m)
\rarrow
 P(y|\cald\rvm=m)$
\\
\quad by Rule 3: 
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\cald_\rvx\cald_\rvm G:$
$\xymatrix{
&{\rvc}\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_{c}
\sum_m
P(y|\cald\rvm=m, c)
P(c|\cald\rvm=m)
P(m|x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_{c}
\sum_m
P(y|m, c)
P(c|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvm=m, c)
\rarrow
\quad P(y|m, c)$
\\
\quad by Rule 2: 
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\call_\rvm \cald_\emptyset G:$
$\xymatrix{
&{\rvc}\ar[rd]\ar[ld]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_{c}
\sum_m
P(y|m, c)
P(c)
P(m|x)$
\\
\quad $P(c|\cald\rvm=m)
\rarrow
P(c)$
\\
\quad by Rule 3: 
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\cald_\rvm \cald_\emptyset G:$
$\xymatrix{
&{\rvc}\ar[rd]\ar[ld]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\end{longtable}
.\qed


\begin{claim} (from Ref.\cite{hunermund2021})

If
$
\xymatrix{
&\rvw\ar[d]\ar[ddr]\ar@/^1.5pc/@{<-->}[ddr]|\rvu
\\
&\rvh\ar[dr]
\\
\rvx\ar[rr]\ar[uur]\ar@/_1.5pc/@{<-->}[dr]
&&\rvy
\\
&\rve\ar[ru]\ar[lu]
}$
then
\beq
P(y|\cald \rvx = x)=
\sum_e P(y|x,e)P(e)
\eeq

\beq
\xymatrix{
\cald\rvx=x\ar[r]
&y
\quad=\quad}
\xymatrix{
x\ar[rr]
&&y
\\
&\sum e\ar[ru]
}
\eeq
\end{claim}
\proof
\\
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=$
\\
$
\xymatrix{
&\sum w\ar[d]\ar[ddr]\ar@/^1.5pc/@{<-->}[ddr]|{\sum u}
\\
&\sum h\ar[dr]
\\
\cald\rvx=x\ar[rr]\ar[uur]
&&y
\\
&\sum e\ar[ru]
}
\xymatrix{
\\
\\
=}
\xymatrix{
\\
\cald\rvx=x\ar[rr]
&&y
\\
&\sum e\ar[ru]
}$
\\
\color{red}
$=\sum_e
P(y|\cald\rvx=x, e)
P(e|\cald\rvx=x)$
\\
\xymatrix{
\\=}
$
\xymatrix{
\cald\rvx=x\ar[rr]
\ar[dr]_0
&&y
\\
&\sum e\ar[ru]
}$
\\
\color{red}
$=\sum_e
P(y|x, e)
P(e|\cald\rvx=x)$
\\
\xymatrix{
\\=}
$
\xymatrix{
x\ar[rrd]
\\
\cald\rvx=x
\ar[dr]_0
&&y
\\
&\sum e\ar[ru]
}$
\begin{tabular}{l}\\
by Rule 2
\end{tabular}
\\
\color{red}
$=\sum_e
P(y|x, e)
P(e)$
\\
$
\xymatrix{\\=}
\xymatrix{
x\ar[rr]
&&y
\\
&\sum e\ar[ru]
}$
\begin{tabular}{l}\\
by Rule 3.
\\ No information
transmission\\
between $\cald \rvx$
and $\rve$.
\end{tabular}
\end{longtable}
.\qed


\begin{claim}(from Ref.\cite{hunermund2021})

If $
\xymatrix{
&\rvw\ar[dl]\ar[d]
&\rvs\ar[l]
\\
\rvz\ar[r]
&\rvx\ar[r]
&\rvy
}$ then
\beq
P(y|\cald \rvx = x)
=
 \sum_z P(y|x,z,w,\rvs=1)
P(z|w, \rvs=1)
\eeq

\beq
\xymatrix{
\cald\rvx=x\ar[r]
&y
\quad=\quad}
\xymatrix{
&\rvw=w\ar[dl]\ar[dr]
&\rvs=1\ar[d]\ar[dll]
\\
\sum z \ar@/_1.5pc/[rr]
&\rvx=x\ar[r]
&y
}
\eeq
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=P(y|\cald\rvx=x, w, \rvs=1)$
\\
\xymatrix{&\sum w\ar[dl]\ar[dr]
&\sum s \ar[l]
\\
\sum z
&\cald\rvx=x\ar[r]
&y
}
\xymatrix{
\\
=
}
\xymatrix{
&\rvw=w\ar[dl]\ar[dr]
&\rvs=1\ar[l]
\\
\sum z
&\cald\rvx=x\ar[r]
&y
}
\begin{tabular}{l}
by Rule 1
\end{tabular}
\\
\\
\color{red}
$=\sum_z P(y|\cald\rvx=x,z,w,\rvs=1)
P(z|\cald\rvx=x, w, \rvs=1)$
\\
\xymatrix{\\=}
\xymatrix{
&\rvw=w\ar[dl]\ar[dr]
&\rvs=1\ar[l]\ar[d]\ar[dll]
\\
\sum z\ar@/_1.5pc/[rr]
&\cald\rvx=x\ar[r]\ar[l]^0
&y
}
\\
\\
\color{red}
$=\sum_z P(y|\rvx=x,z,w,\rvs=1)
P(z|\cald\rvx=x, w, \rvs=1)$
\\
\xymatrix{\\=}
\xymatrix{
&\rvw=w\ar[dl]\ar[dr]
&\rvs=1\ar[l]\ar[d]\ar[dll]
\\
\sum z\ar@/_1.5pc/[rr]
&\cald\rvx=x\ar[l]^0
&y
\\
&x\ar[ur]
}
\begin{tabular}{l}
\\
by Rule 2
\end{tabular}
\\
\\
\color{red}
$=\sum_z P(y|\rvx=x,z,w,\rvs=1)
P(z| w, \rvs=1)$
\\
\xymatrix{\\=}
\xymatrix{
&\rvw=w\ar[dl]\ar[dr]
&\rvs=1\ar[d]\ar[dll]
\\
\sum z \ar@/_1.5pc/[rr]
&x\ar[r]
&y
}
\begin{tabular}{l}\\
by Rule 3.
\\
No info transmission\\
between $\cald \rvx$ and $\rvz$.
\end{tabular}
\end{longtable}

\begin{claim}(Napkin problem from Ref.\cite{book-why})

If $
\xymatrix{
&*++[F-o]{\rvu_1}\ar[ddl]\ar[ddrr]
\\
&*++[F-o]{\rvu_2}\ar[dl]\ar[dr]
\\
\rvw\ar[r]
&\rvz\ar[r]
&\rvx\ar[r]
&\rvy
}$ then
\beqa
P(y|\cald \rvx = x)
&=&
\eeqa
\end{claim}
\proof
coming soon
\qed
\begin{claim}(from Ref.\cite{book-why})

If $
\xymatrix{
\rvx\ar[d]\ar[drr]
\\
\rvw\ar[r]
&\rvz\ar[r]
&\rvy
\\
*++[F-o]{\rvu}\ar[u]\ar[urr]
}$ then
\beqa
P(y|\cald \rvx = x, \cald\rvz=z)
&=&
\eeqa
\end{claim}
\proof
coming soon
\qed