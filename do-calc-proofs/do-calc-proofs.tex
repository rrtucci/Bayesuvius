\chapter{Do Calculus proofs}
\label{ch-do-calc-proofs}

In Chapter \ref{ch-do-calc}
of Bayesuvius,
we explained Do Calculus
but referred to this
chapter for proofs
of claims that
use Do Calculus.
In this chapter, we've
aggregated
 all proofs, from
throughout the book,
of claims that use Do Calculus.

Note that even though the 3
rules of Do Calculus
are great for proving
adjustment formulae
for general classes of DAGs,
they are sometimes overkill
for proving
 adjustment formulae
for a single specific DAG.
After all,  the
 3 rules of Do Calculus
are a consequence
of the d-separation theorem.
Hence, all adjustment
formulae should be
provable from first principles,
assuming only
the d-separation theorem
and the standard rules of
probability theory.

In this chapter, we use the
 following conventions.

\bnetInstantiations

\hiddenNodes

Selection diagrams
with selection nodes 
 are discussed 
in Chapter \ref{ch-transport}.
\selectionGraphs

Some identities
that are used in this chapter:

\begin{enumerate}
\item
\beq
P(y|x_1, x_2)= 
\sum_a P(y|a, x_1, x_2)P(a|x_1, x_2)
\;.
\eeq

\beq
\xymatrix{
x_1\ar[rrd]
\\
&&y
\\
x_2\ar[urr]
}
\xymatrix{\\=}
\xymatrix{
x_1\ar[rd]\ar[drr]
\\
&\sum a\ar[r]
&y
\\
x_2\ar[ru]\ar[rru]
}
\label{eq-univ-bdoor}
\;.
\eeq
One can describe
this identity as
``giving $\rvy$
a universal backdoor", 
because $\sum a$ is a backdoor
(i.e., input) to $y$, and $\sum a$
is universal in the sense that it
 is entered
by every arrow that enters $y$
except $\sum a$ itself.

\item

\beq
\sum_a 
P(a|x_1, x_2)=1
\eeq

\beq
\xymatrix@R=.3pc{
x_1\ar[dr]
\\
&\sum a\ar[r]_0&&=1
\\
x_2\ar[ur]
}
\label{eq-collider-sum}
\eeq
One can describe this
identity as ``summing over 
the values of a collider node
which has no emerging 
arrows"\footnote{A zeroed 
arrow means the same as no arrow.}.
Eq.(\ref{eq-collider-sum})
can be understood as an 
edge case (when $\rvy=\emptyset$)
of Eq.(\ref{eq-univ-bdoor}).

\item
\beq
\sum_a P(x_2|a)P(a|x_1)=P(x_2|x_1)
\eeq

\beq
\xymatrix{
x_1\ar[r]
&\sum a\ar[r]
&x_2
&=&
x_1\ar[r]
&x_2}
\label{eq-med-sum}
\eeq
One can describe this
identity as
``summing over the 
values of a mediator node".

\item
\beq
P(x)=\sum_a P(x|a)P(a)=
\sum_b P(x|b)P(b)
\eeq

\beq
\xymatrix{
P(x)&=&
\ar[r]_0
&\sum a\ar[r]
&x
&=&
\ar[r]_0
&\sum b\ar[r]
&x
}
\label{eq-diff-priors}
\eeq
One can describe 
this identity 
as ``averaging
over different 
priors".
Eq.(\ref{eq-diff-priors})
can be understood as 
an edge case of Eq.(\ref{eq-med-sum}).

\end{enumerate}

A {\bf do-adjustment 
formula} expresses
a {\bf do-query} (i.e., 
a conditional probability
with do operators
in its condition) by
an equivalent expression
without do operators.
If a do-adjustment formula
exists for a
particular do-query, 
then we say the do-query is
 {\bf do-identifiable}.\footnote{
To prove that a do-query $P(y|\cald\rvx=x, z)$
is do-identifiable
for a graph $G$,
just prove that $\rvy\perp\rvx|\rvz$
in $\call_\rvx G$. 
This is called Rule 2 of Do Calculus,
but it is easy to understand just from
the d-separation theorem.
Info can be transmitted 
between $\rvy$ and $\rvx$ by
either (1) paths
in $\cald_\rvx G$
or (2) paths in $\call_\rvx G$.
$P(y|\cald\rvx=x, z)=
P(y|x, z)$
means the info is being transmitted only
by (1).
So the Rule 2 premise is checking
that no info is being transmitted
by (2). }
See Fig.\ref{fig-iden-noniden}
for some simple
examples of identifiable
and non-identifiable
do-queries.

\begin{figure}[h!]
$$
\begin{array}{ccc}
\xymatrix{
&\rvz\ar[ld]\ar[rd]
\\
\rvx\ar[rr]&&\rvy
}
&\quad\quad&
\xymatrix{
&*++[F-o]{\rvz}\ar[ld]\ar[rd]
\\
\rvx\ar[rr]&&\rvy
}
\\
P(y|\cald\rvx=x)=P(y|x)
&&P(y|\cald\rvx=x)\neq P(y|x)
\end{array}
$$
\caption{Examples of 
identifiable
and non-identifiable
do-queries. $\cald\rvx=x$
in a do-query
means we erase the arrow
$\rvz\rarrow\rvx$
and replace node
$\rvx$ by a delta function
$\delta(x,x')$.
Let $Q(y|x)=\sum_zP(y|x,z)P(z)$.
In both cases,
$P(y|\cald\rvx=x)=Q(y|x)$, 
but in the non-identifiable
case, $Q(y|x)$
is summing over the
unobserved node $\rvz$,
so it is using 
data that is not available.
To distinguish between
these two possibilities for $Q(y|x)$,
we set $Q(y|x)=P(y|x)$
in the identifiable case,
and $Q(y|x)=P(y|\cald\rvx=x)$
in the non-identifiable case.
}
\label{fig-iden-noniden}
\end{figure}

The following is the simplest of
do-adjustment formulae:
\beq
P(y|\cald\rvx=x)=P(y|x)
\eeq
By definition, 
since identifiability
gives permission
to remove $\cald$ operators, all do-identifiable
problems satisfy this simplest 
of adjustment 
formulae. However,
we aim to find 
an adjustment formula that 
utilizes the full distribution
of the {\it observed} nodes. Adjustment
formulae that don't 
utilize the full
distribution 
of the observed nodes are 
throwing
away useful
info
from the dataset, and are less
sensitive to deviations from the DAG model
being hypothesized. 

Given a bnet $G$
and an adjustment formula $AF$
for the query $P(y|\cald\rvx=x, z)$,
a simple identification method (SIM) that we 
use in this chapter to prove 
that $AF$ 
applies to $G$, is
the following:
\begin{enumerate}
\item
From the bnet $G$,
write 
an instantiation
of $G$ 
in which
the arrows entering
node $x$
are amputated,
node $x$
is replaced
by $\cald\rvx=x$,
and all observed and
unobserved nodes, 
except 
$x, y, z$,
are summed over.
\item
Replace all
sums over 
hidden nodes
by sums over 
observed nodes.
\item 
Once all
nodes in the diagram
represent
observed nodes only,
we can replace 
the node $\cald\rvx=x$
by $x$. 
This is 
justified because in
the latest diagram (the one
with no unobserved nodes), unavailable
info  that
belongs to unobserved nodes
is not being used.
After all,
that is the meaning
of 
identifiability:
that we can express
a do-query using
only the info
that is available.
\end{enumerate}

You can check that 
using SIM,
it is not possible to
find an adjustment formula for
the example
of a non-identifiable
query in Fig.\ref{fig-iden-noniden}.
SIM does yield the backdoor adjustment
formula for the
identifiable
query in Fig.\ref{fig-iden-noniden}.


A {\bf do-transport formula}
expresses a do-query in terms
of an equivalent do-query.

This chapter deals with both
do-adjustment and do-transport
formulae.


\begin{claim} 
\label{cl-decBackDoor}
\decBackDoor
\end{claim}

\proof

{\bf * proof 1:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=\sum_z
 P(y|x, z)P(z)$
\\
$\xymatrix{
\sum z\ar[dr]
\\
\cald \rvx=x\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
\sum z\ar[dr]
\\
x\ar[r]
&y
}
$
\begin{tabular}{l}
We can replace\\
$\cald\rvx=x$
by $x$ 
\\once all nodes
\\in bnet are
\\observed nodes. 
\end{tabular}
\end{longtable}


{\bf * proof 2:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)
=
\sum_z
P(y|\cald\rvx=x, z)
P(z|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z|\cald\rvx=x)$
\\
\quad $P(y|\cald \rvx=x, z)\rarrow
P(y|x, z)$
\\
\quad  by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvy\perp\rvx|\rvz$ in
$\call_\rvx\cald_\emptyset G:
\xymatrix{
\rvz\ar[d]\ar[rd]
\\
\rvx
&\rvy
}$
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z)$
\\
\quad $P(z|\cald \rvx=x)\rarrow
P(z)$
\\
\quad  by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvz\perp \rvx$ in
$\cald_\rvx \cald_\emptyset G:
\xymatrix{
\rvz\ar[rd]
\\
\rvx\ar[r]
&\rvy
}
$
\end{longtable}
\qed




\begin{claim}
\label{cl-decFrontDoor}
\decFrontDoor
\end{claim}

\proof


{\bf * proof 1:}
\\
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_{m, c, x'}
P(y|m, c)P(c|x')P(x')
P(m|\cald\rvx=x)$
\\
\\
\xymatrix{
&*++[F-o]{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]
&\sum m\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
\sum x'\ar[r]
&*++[F-o]{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]
&\sum m\ar[r]
&y
}
\\
$\color{red}=
\sum_{m,x'}
P(y|m, x')
P(x')
P(m|x)$
\\
\xymatrix{\\=}
\xymatrix{
&\sum x'\ar[dr]
\\
x\ar[r]&\sum m\ar[r]
&y
}
\begin{tabular}{l}
We can replace\\
$\cald\rvx=x$
by $x$ 
\\once all nodes
\\in bnet are
\\observed nodes. 
\end{tabular}
\end{longtable}



{\bf * proof 2:}
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_m
P(y|\cald\rvx=x, m)
P(m|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m|\cald\rvx=x)$
\\
\quad $P(y|\cald\rvx=x, m)\rarrow
P(y|\cald\rvx=x, \cald m=m)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad $\rvy\perp \rvm|\rvx$ in
$\call_\rvm\cald_\rvx G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m| x)$
\\
\quad $P(m|\cald\rvx=x)\rarrow P(m|x)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvm\perp \rvx$ in
$\call_\rvx\cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[ld]\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvx=x, \cald\rvm=m)
\rarrow
 P(y|\cald\rvm=m)$
\\
\quad by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvy\perp\rvx|\rvm$ in
$\cald_\rvx\cald_\rvm G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|\cald\rvm=m, x')
P(x'|\cald\rvm=m)
P(m|x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|m, x')
P(x'|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvm=m, x')
\rarrow
\quad P(y|m, x')$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvy\perp\rvm|\rvx$ in
$\call_\rvm \cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]\ar[ld]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|m, x')
P(x')
P(m|x)$
\\
\quad $P(x'|\cald\rvm=m)
\rarrow
P(x')$
\\
\quad by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvx\perp\rvm$ in
$\cald_\rvm \cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]\ar[ld]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\end{longtable}
\qed



\begin{claim}
\label{cl-decNapkin}
\decNapkin
\end{claim}
\proof
\\
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=
\sum_{u_1}P(y|\cald\rvx=x, u_1)P(u_1)$
\\
\\
\xymatrix{
&*++[F-o]{\sum u_1}\ar[ddl]\ar[ddrr]
\\
&*++[F-o]{\sum u_2}\ar[dl]
\\
\sum w\ar[r]
&\sum z
&\cald\rvx=x\ar[r]
&\rvy
}
\xymatrix{\\=}
\quad
\xymatrix{
*++[F-o]{\sum u_1}\ar[rd]
\\
\cald\rvx=x\ar[r]&y
}
\\
\color{red}
$
=\sum_{w,z}\sum_{u_1}P(y|\cald\rvx=x, u_1)P(u_1|w,z)
P(w,z)$
\\
\\
\xymatrix{\\=}
\xymatrix{
\sum w,z\ar[r]
&*++[F-o]{\sum u_1}\ar[rd]
\\
&\cald\rvx=x\ar[r]
&y
}
\\
\color{red}
$
=\sum_{w,z}P(y|x,w,z)
P(w,z)$
\\
\xymatrix{
\\=}
\xymatrix{
\sum w,z\ar[rd]
\\
x\ar[r]&y
}\begin{tabular}{l}
We can replace\\
$\cald\rvx=x$
by $x$ 
\\once all nodes
\\in bnet are
\\observed nodes. 
\end{tabular}
\end{longtable}
\qed


\begin{claim}
\label{cl-decWhy}
\decWhy
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvz=z,x)=
\sum_u P(y|\cald\rvz=z,x,u)P(u)
$
\\
\xymatrix{
x\ar[d]\ar[drr]
\\
\sum w
&\cald\rvz=z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[u]\ar[urr]
}
\xymatrix{\\=}
\xymatrix{
x\ar[drr]
\\
&\cald\rvz=z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[urr]
}
\\
\\
\color{red}
$=\sum_w\sum_u
P(y|\cald\rvz=z,x,u)P(u|w)P(w)
$
\\
\xymatrix{\\=}
\xymatrix{
x\ar[drr]
\\
\sum w\ar[d]
&\cald\rvz=z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[urr]
}
\\
\\
\color{red}
$=\sum_w
P(y|z,x,w)P(w)
$
\\
\xymatrix{\\=}
\xymatrix{
x\ar[drr]
\\
\sum w\ar@/_1pc/[rr]
&z\ar[r]
&y
}\begin{tabular}{l}
We can replace\\
$\cald\rvz=z$
by $z$ 
\\once all nodes
\\in bnet are
\\observed nodes. 
\end{tabular}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportTrivial}
\decTransportTrivial
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, z, \rvs=1)=
P(y|x, z, \rvs=1)$
\\
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{
\\=
}
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
x\ar[rr]
&&y
}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportDirect}
\decTransportDirect
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, z, \rvs=1)=
P(y|\cald\rvx=x, z)$
\\
\xymatrix{
\rvs=1\ar[r]
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\begin{tabular}{l}
Because $\rvs\perp\rvy|\rvz$
\end{tabular}
\end{longtable}
Furthermore,
\begin{longtable}{l}
\color{red}
$P(y|\cald \rvx=x, \rvs=1)
=\sum_z P(y|\cald\rvx=x,z)P(z|\rvs=1)$
\\
\xymatrix{
\rvs=1\ar[r]
&\sum z\ar[rd]
\\
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportBox}
\decTransportBox
\end{claim}
\proof
\begin{longtable}{l}
\color{red}$
P(y|\cald\rvx=x, \rvs=1)
=\sum_{a}
P(y|\cald\rvx=x,a)P(a|\rvs=1)$
\\
\xymatrix{
\rvs=1\ar[r]
&*++[F-o]{\sum z}\ar[r]
&\sum a\ar[d]
\\
&\cald \rvx=x\ar[r]
&y
}\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum a\ar[d]
\\
\cald \rvx=x\ar[r]
&y
}
\end{longtable}
\qed

%\decTransportOne merged 
%with decDirectTransport

\begin{claim}
\label{cl-decTransportNon}
\decTransportNon
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P^*(y|\cald\rvx=x)=P^*(y|\cald\rvx=x)$
\\
\\
\xymatrix{
&*++[F-o]{\sum h}\ar[dr]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
Can't replace $\cald\rvx=x$ 
by $x$ because 
$\rvy\not\perp \rvx$ in 
$\call_\rvx G$.
Hence, Rule 2 not satisfied.
\qed


\begin{claim}
\label{cl-decTransportTwo}
\decTransportTwo
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald \rvx=x, \rvs=1)=
\sum_h P(y|\cald\rvx=x, h)P(h)$
\\
\\
\xymatrix{
\rvs=1\ar@/^1.5pc/[rr]
&*++[F-o]{\sum h}\ar[r]\ar[rd]
&\sum z
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&*++[F-o]{\sum h}\ar[rd]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\\
\color{red}
$=P(y|\cald\rvx=x)$
\\
\xymatrix{=}
\xymatrix{
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
\qed
\begin{claim}
\label{cl-decTransportThree}
\decTransportThree
\end{claim}
\proof

\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, \rvs=1)=
\sum_h
\sum_z P(y|h, z)P(h)
P(z|\cald\rvx=x, \rvs=1)$
\\
\\
\xymatrix{
\rvs=1\ar[rd]
&*++[F-o]{\sum \rvh}\ar[dr]
\\
\cald\rvx=x\ar[r]
&\sum z\ar[r]
&y
}
\\
\\
\color{red}
$=\sum_h\sum_z P(y|h,z)P(h|\cald\rvx=x)
P(z|x, \rvs=1)$
\\
\\
\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[rd]
&*++[F-o]{\sum \rvh}\ar[dr]
&\cald\rvx=x\ar[l]
\\
x\ar[r]
&\sum z\ar[r]
&y
}
\\
\color{red}
$=\sum_z P(y|\cald\rvx=x, z)P(z|x, \rvs=1)$
\\
$\xymatrix{\\=}\xymatrix{
\rvs=1\ar[rd]
&&\cald\rvx=x\ar[d]
\\
x\ar[r]
&\sum z\ar[r]
&y
}$
\end{longtable}
\qed

\begin{claim}
\label{cl-decMediationSimple}
\decMediationSimple
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvd=d,\cali\rvd=d')=
\sum_{m}
P(y|d,m)P(m|d')$
\\
\\
\xymatrix{
\cali\rvd=d'\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rr]
&&y}
\end{longtable}
\qed

\begin{claim}
\label{cl-decMediationPlus}
\decMediationPlus
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvd=d,\cali\rvd=d')=
\sum_{\xi, u}
\sum_{m}
P(y|d,m,\xi, u)P(m|d', \xi, u)
\underbrace{P(\xi|u)P(u)}_{P(\xi, u)}$
\\
\\
\xymatrix{
&&*++[F-o]{\sum u}\ar[ddr]
\ar[dl]\ar[d]
\\
\cali\rvd=d'\ar@/_1pc/[rr]
&\sum\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rrr]
&&&y}
\\
\color{red}
$=
\sum_{\xi}
\sum_{m}
P(y|d,m,\xi)P(m|d', \xi)
P(\xi)$
\\
\xymatrix{\\=}
\xymatrix{
\cali\rvd=d'\ar@/_1pc/[rr]
&\sum\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rrr]
&&&y}
\begin{tabular}{l}
We switch from averaging over\\ the
prior of $\xi, u$\\
to averaging over the\\
prior of $\xi$.
\end{tabular}
\end{longtable}
\qed

\begin{claim}
\label{cl-decSeqBackDoor}
\decSeqBackDoor
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx^3=x^3)=
\calq(y|x^3)$
\\
\xymatrix@C=.5pc{
\sum z_0\ar[r]\ar@/^1pc/[rr]
\ar[drrr]
&\sum z_1\ar[r]
\ar[drr]
&\sum z_2
\ar[dr]
\\
&&&y
\\
\cald\rvx_0=x_0\ar[uur]\ar[uurr]
\ar[urrr]
&\cald\rvx_1=x_1\ar[uur]
\ar[urr]
&\cald\rvx_2=x_2
\ar[ur]
}
\xymatrix{\\=}
\xymatrix@C=.9pc{
\sum z_0\ar[r]\ar@/^1pc/[rr]
\ar[drrr]
&\sum z_1\ar[r]
\ar[drr]
&\sum z_2
\ar[dr]
\\
&&&y
\\
x_0\ar[uur]\ar[uurr]
\ar[urrr]
&x_1\ar[uur]
\ar[urr]
&x_2
\ar[ur]
}
\begin{tabular}{l}
We can replace\\
$\cald\rvx_i=x_i$
by $x_i$ 
\\once all nodes
\\in bnet are
\\observed nodes. 
\end{tabular}
\end{longtable}
\qed




%\input{do-calc-proofs/do-calc-proofs-limbo.tex}
