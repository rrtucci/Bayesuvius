\chapter{Do Calculus proofs}
\label{ch-do-calc-proofs}

In Chapter \ref{ch-do-calc}
of Bayesuvius,
we explained Do Calculus
but referred to this
chapter for proofs
of claims that
use Do Calculus.
In this chapter, we've
aggregated
 all proofs, from
throughout the book,
of claims that use Do Calculus.

Note that even though the 3
rules of Do Calculus
are great for proving
adjustment formulae
for general classes of DAGs,
they are sometimes overkill
for proving
 adjustment formulae
for a single specific DAG.
After all,  the
 3 rules of Do Calculus
are a consequence
of the d-separation theorem.
Hence, all adjustment
formulae should be
provable from first principles,
assuming only
the d-separation theorem
and the standard rules of
probability theory.

We use the
 following conventions.
Random variables are underlined
and their values are not.
For example, $\rva=a$ means
the random variable
$\rva$ takes the value $a$.
Diagrams
with nodes that are
underlined represent
Bayesian Networks (bnets)
and the same diagram
with the letters not underlined
represents a specific
instantiation of that bnet.
For example $\rva\rarrow\rvb$
represents the bnet with
conditional probability distribution
$P(b|a)$,
whereas  $a\rarrow b$
represents $P(b|a)$ itself.

If $\rva$ is a root node,
then $\sum a$ signifies
a weighted sum $\sum_a P(a)$.
For example, $\sum a\rarrow b=\sum_a P(a)P(b|a)$.
If $\rva$ is not
a root node
as in $x\rarrow\sum a \rarrow y=
\sum_a P(y|a)P(a|x) $, then
$\sum a$ signifies
a simple unweighted sum $\sum_a$.

Unobserved nodes are
indicated by enclosing them
in a dashed circle. For example,
$\xymatrix{*++[F-o]{u}}$.

Selection diagrams
with selection nodes 
 are discussed 
in Chapter \ref{ch-transport}.
\selectionGraphs

Some identities
that are used in this chapter:

\begin{enumerate}
\item
\beq
P(y|x_1, x_2)= 
\sum_a P(y|a, x_1, x_2)P(a|x_1, x_2)
\;.
\eeq

\beq
\xymatrix{
x_1\ar[rrd]
\\
&&y
\\
x_2\ar[urr]
}
\xymatrix{\\=}
\xymatrix{
x_1\ar[rd]\ar[drr]
\\
&\sum a\ar[r]
&y
\\
x_2\ar[ru]\ar[rru]
}
\label{eq-univ-bdoor}
\;.
\eeq
One can describe
this identity as
``giving $\rvy$
a universal backdoor", 
because $\sum a$ is a backdoor
(i.e., input) to $y$, and $\sum a$
is universal in the sense that it
 is entered
by every arrow that enters $y$
except $\sum a$ itself.

\item

\beq
\sum_a 
P(a|x_1, x_2)=1
\eeq

\beq
\xymatrix@R=.3pc{
x_1\ar[dr]
\\
&\sum a\ar[r]_0&&=1
\\
x_2\ar[ur]
}
\label{eq-collider-sum}
\eeq
One can describe this
identity as ``summing over 
the values of a collider node
which has no emerging 
arrows"\footnote{A zeroed 
arrow means the same as no arrow.}.
Eq.(\ref{eq-collider-sum})
can be understood as an 
edge case (when $\rvy=\emptyset$)
of Eq.(\ref{eq-univ-bdoor}).

\item
\beq
\sum_a P(x_2|a)P(a|x_1)=P(x_2|x_1)
\eeq

\beq
\xymatrix{
x_1\ar[r]
&\sum a\ar[r]
&x_2
&=&
x_1\ar[r]
&x_2}
\label{eq-med-sum}
\eeq
One can describe this
identity as
``summing over the 
values of a mediator node".

\item
\beq
P(x)=\sum_a P(x|a)P(a)=
\sum_b P(x|b)P(b)
\eeq

\beq
\xymatrix{
P(x)&=&
\ar[r]_0
&\sum a\ar[r]
&x
&=&
\ar[r]_0
&\sum b\ar[r]
&x
}
\label{eq-diff-priors}
\eeq
One can describe 
this identity 
as ``averaging
over different 
priors".
Eq.(\ref{eq-diff-priors})
can be understood as 
an edge case of Eq.(\ref{eq-med-sum}).

\end{enumerate}

A {\bf do-adjustment 
formula} expresses
a {\bf do-query} (i.e., 
an conditional probability
with do operators
in its condition) by
an equivalent expression
without do operators.
If a do-adjustment formula
exists for a
particular do-query, 
then we say the do-query is
 {\bf do-identifiable}.\footnote{
To prove that a do-query $P(y|\cald\rvx=x, z)$
is do-identifiable
for a graph $G$,
just prove that $\rvy\perp\rvx|\rvz$
in $\call_\rvx G$. 
This is called Rule 2 of Do Calculus,
but it is easy to understand just from
the d-separation theorem.
Info can be transmitted 
between $\rvy$ and $\rvx$ by
either (1) paths
in $\cald_\rvx G$
or (2) paths in $\call_\rvx G$.
$P(y|\cald\rvx=x, z)=
P(y|x, z)$
means the info is being transmitted only
by (1).
So the Rule 2 premise is checking
that no info is being transmitted
by (2).}
The following is the simplest of
do-adjustment formulae:
\beq
P(y|\cald\rvx=x)=P(y|x)
\eeq
Many problems (e.g., Backdoor, Frontdoor, etc.)
satisfy this simplest of adjustment 
formulae, but in general
we aim to find 
an adjustment formula that 
utilizes the full distribution
of the observed nodes. Adjustment
formulae that don't 
utilize the full
distribution 
of the observed nodes are 
throwing
away useful
info
from the dataset, and are less
sensitive to deviations from the DAG model
being hypothesized.

A {\bf do-transport formula}
expresses a do-query in terms
of an equivalent do-query.

This chapter deals with both
do-adjustment and do-transport
formulae.


\begin{claim} 
\label{cl-decBackDoor}
\decBackDoor
\end{claim}

\proof

{\bf * proof 1:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=\sum_z
 P(y|x, z)P(z)$
\\
$\xymatrix{
\sum z\ar[dr]
\\
\cald \rvx=x\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
\sum z\ar[dr]
\\
x\ar[r]
&y
}
$
\begin{tabular}{l}
We can replace $\cald\rvx=x$\\
by $x$ because $\cald\rvx\perp \rvy$\\
in $\call_{\cald\rvx}G$ so\\
Rule 2 premise is satisfied.
\end{tabular}
\end{longtable}


{\bf * proof 2:}
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)
=
\sum_z
P(y|\cald\rvx=x, z)
P(z|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z|\cald\rvx=x)$
\\
\quad $P(y|\cald \rvx=x, z)\rarrow
P(y|x, z)$
\\
\quad  by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvy\perp\rvx|\rvz$ in
$\call_\rvx\cald_\emptyset G:
\xymatrix{
\rvz\ar[d]\ar[rd]
\\
\rvx
&\rvy
}$
\\
\color{red}
$=\sum_z
P(y|x, z)
P(z)$
\\
\quad $P(z|\cald \rvx=x)\rarrow
P(z)$
\\
\quad  by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvz\perp \rvx$ in
$\cald_\rvx \cald_\emptyset G:
\xymatrix{
\rvz\ar[rd]
\\
\rvx\ar[r]
&\rvy
}
$
\end{longtable}
\qed




\begin{claim}
\label{cl-decFrontDoor}
\decFrontDoor
\end{claim}

\proof


{\bf * proof 1:}
\\
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_{m, c, x'}
P(y|m, c)P(c|x')P(x')
P(m|\cald\rvx=x)$
\\
\\
\xymatrix{
&*++[F-o]{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]
&\sum m\ar[r]
&y
}
\xymatrix{\\=}
\xymatrix{
\sum x'\ar[r]
&*++[F-o]{\sum c}\ar[rd]
\\
\cald \rvx=x\ar[r]
&\sum m\ar[r]
&y
}
\\
$\color{red}=
\sum_{m,x'}
P(y|m, x')
P(x')
P(m|x)$
\\
\xymatrix{\\=}
\xymatrix{
&\sum x'\ar[dr]
\\
x\ar[r]&\sum m\ar[r]
&y
}
\begin{tabular}{l}
We can replace $\cald\rvx=x$\\
by $x$ because $\cald\rvx\perp \rvm$\\
in $\call_{\cald\rvx}G$ so\\
Rule 2 premise is satisfied.
\end{tabular}
\end{longtable}



{\bf * proof 2:}
\begin{longtable}{l}
$\color{red}
P(y|\cald\rvx=x)=
\sum_m
P(y|\cald\rvx=x, m)
P(m|\cald\rvx=x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m|\cald\rvx=x)$
\\
\quad $P(y|\cald\rvx=x, m)\rarrow
P(y|\cald\rvx=x, \cald m=m)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad $\rvy\perp \rvm|\rvx$ in
$\call_\rvm\cald_\rvx G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvx=x, \cald\rvm=m)
P(m| x)$
\\
\quad $P(m|\cald\rvx=x)\rarrow P(m|x)$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvm\perp \rvx$ in
$\call_\rvx\cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[ld]\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_m
P(y|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvx=x, \cald\rvm=m)
\rarrow
 P(y|\cald\rvm=m)$
\\
\quad by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvy\perp\rvx|\rvm$ in
$\cald_\rvx\cald_\rvm G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|\cald\rvm=m, x')
P(x'|\cald\rvm=m)
P(m|x)$
\\
\quad by Probability Axioms
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|m, x')
P(x'|\cald\rvm=m)
P(m|x)$
\\
\quad $P(y|\cald\rvm=m, x')
\rarrow
\quad P(y|m, x')$
\\
\quad by Rule 2:
\begin{tabular}{l}
\ruletwoif\\\ruletwothen
\end{tabular}
\\
\quad
$\rvy\perp\rvm|\rvx$ in
$\call_\rvm \cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]\ar[ld]
\\
\rvx\ar[r]
&\rvm
&\rvy
}$
\\
$\color{red}=
\sum_{x'}
\sum_m
P(y|m, x')
P(x')
P(m|x)$
\\
\quad $P(x'|\cald\rvm=m)
\rarrow
P(x')$
\\
\quad by Rule 3:
\begin{tabular}{l}
\rulethreeif\\\rulethreethen
\end{tabular}
\\
\quad
$\rvx\perp\rvm$ in
$\cald_\rvm \cald_\emptyset G:$
$\xymatrix{
&*++[F-o]{\rvc}\ar[rd]\ar[ld]
\\
\rvx
&\rvm\ar[r]
&\rvy
}$
\end{longtable}
\qed



\begin{claim}
\label{cl-decNapkin}
\decNapkin
\end{claim}
\proof
\\
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x)=
\sum_{u_1}P(y|\cald\rvx=x, u_1)P(u_1)$
\\
\\
\xymatrix{
&*++[F-o]{\sum u_1}\ar[ddl]\ar[ddrr]
\\
&*++[F-o]{\sum u_2}\ar[dl]
\\
\sum w\ar[r]
&\sum z
&\cald\rvx=x\ar[r]
&\rvy
}
\xymatrix{\\=}
\quad
\xymatrix{
*++[F-o]{\sum u_1}\ar[rd]
\\
\cald\rvx=x\ar[r]&y
}
\\
\color{red}
$
=\sum_{w,z}\sum_{u_1}P(y|\cald\rvx=x, u_1)P(u_1|w,z)
P(w,z)$
\\
\\
\xymatrix{\\=}
\xymatrix{
\sum w,z\ar[r]
&*++[F-o]{\sum u_1}\ar[rd]
\\
&\cald\rvx=x\ar[r]
&y
}
\\
\color{red}
$
=\sum_{w,z}P(y|x,w,z)
P(w,z)$
\\
\xymatrix{
\\=}
\xymatrix{
\sum w,z\ar[rd]
\\
x\ar[r]&y
}\begin{tabular}{l}
We can replace $\cald\rvx=x$\\
by $x$ because $\cald\rvx\perp \rvy$\\
in $\call_{\cald\rvx}G$ so\\
Rule 2 premise is satisfied.
\end{tabular}
\end{longtable}
\qed


\begin{claim}
\label{cl-decWhy}
\decWhy
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvz=z,x)=
\sum_u P(y|\cald\rvz=z,x,u)P(u)
$
\\
\xymatrix{
x\ar[d]\ar[drr]
\\
\sum w
&\cald\rvz=z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[u]\ar[urr]
}
\xymatrix{\\=}
\xymatrix{
x\ar[drr]
\\
&\cald\rvz=z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[urr]
}
\\
\\
\color{red}
$=\sum_w\sum_u
P(y|\cald\rvz=z,x,u)P(u|w)P(w)
$
\\
\xymatrix{\\=}
\xymatrix{
x\ar[drr]
\\
\sum w\ar[d]
&\cald\rvz=z\ar[r]
&y
\\
*++[F-o]{\sum u}\ar[urr]
}
\\
\\
\color{red}
$=\sum_w
P(y|z,x,w)P(w)
$
\\
\xymatrix{\\=}
\xymatrix{
x\ar[drr]
\\
\sum w\ar@/_1pc/[rr]
&z\ar[r]
&y
}\begin{tabular}{l}
We can replace $\cald\rvz=z$\\
by $z$ because $\cald\rvz\perp \rvy$\\
in $\call_{\cald\rvz}G$ so\\
Rule 2 premise is satisfied.
\end{tabular}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportTrivial}
\decTransportTrivial
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, z, \rvs=1)=
P(y|x, z, \rvs=1)$
\\
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{
\\=
}
\xymatrix{
&z\ar[rd]
&\rvs=1\ar[d]
\\
x\ar[rr]
&&y
}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportDirect}
\decTransportDirect
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, z, \rvs=1)=
P(y|\cald\rvx=x, z)$
\\
\xymatrix{
\rvs=1\ar[r]
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&z\ar[dr]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\begin{tabular}{l}
Because $\rvs\perp\rvy|\rvz$
\end{tabular}
\end{longtable}
Furthermore,
\begin{longtable}{l}
\color{red}
$P(y|\cald \rvx=x, \rvs=1)
=\sum_z P(y|\cald\rvx=x,z)P(z|\rvs=1)$
\\
\xymatrix{
\rvs=1\ar[r]
&\sum z\ar[rd]
\\
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
\qed

\begin{claim}
\label{cl-decTransportBox}
\decTransportBox
\end{claim}
\proof
\begin{longtable}{l}
\color{red}$
P(y|\cald\rvx=x, \rvs=1)
=\sum_{a}
P(y|\cald\rvx=x,a)P(a|\rvs=1)$
\\
\xymatrix{
\rvs=1\ar[r]
&*++[F-o]{\sum z}\ar[r]
&\sum a\ar[d]
\\
&\cald \rvx=x\ar[r]
&y
}\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[r]
&\sum a\ar[d]
\\
\cald \rvx=x\ar[r]
&y
}
\end{longtable}
\qed

%\decTransportOne merged 
%with decDirectTransport

\begin{claim}
\label{cl-decTransportNon}
\decTransportNon
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P^*(y|\cald\rvx=x)=P^*(y|\cald\rvx=x)$
\\
\\
\xymatrix{
&*++[F-o]{\sum h}\ar[dr]
&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&&\rvs=1\ar[d]
\\
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
Can't replace $\cald\rvx=x$ 
by $x$ because 
$\rvy\not\perp \rvx$ in 
$\call_\rvx G$.
Hence, Rule 2 not satisfied.
\qed


\begin{claim}
\label{cl-decTransportTwo}
\decTransportTwo
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald \rvx=x, \rvs=1)=
\sum_h P(y|\cald\rvx=x, h)P(h)$
\\
\\
\xymatrix{
\rvs=1\ar@/^1.5pc/[rr]
&*++[F-o]{\sum h}\ar[r]\ar[rd]
&\sum z
\\
\cald\rvx=x\ar[rr]
&&y
}
\xymatrix{\\=}
\xymatrix{
&*++[F-o]{\sum h}\ar[rd]
&
\\
\cald\rvx=x\ar[rr]
&&y
}
\\
\color{red}
$=P(y|\cald\rvx=x)$
\\
\xymatrix{=}
\xymatrix{
\cald\rvx=x\ar[rr]
&&y
}
\end{longtable}
\qed
\begin{claim}
\label{cl-decTransportThree}
\decTransportThree
\end{claim}
\proof

\begin{longtable}{l}
\color{red}
$P(y|\cald\rvx=x, \rvs=1)=
\sum_h
\sum_z P(y|h, z)P(h)
P(z|\cald\rvx=x, \rvs=1)$
\\
\\
\xymatrix{
\rvs=1\ar[rd]
&*++[F-o]{\sum \rvh}\ar[dr]
\\
\cald\rvx=x\ar[r]
&\sum z\ar[r]
&y
}
\\
\\
\color{red}
$=\sum_h\sum_z P(y|h,z)P(h|\cald\rvx=x)
P(z|x, \rvs=1)$
\\
\\
\xymatrix{\\=}
\xymatrix{
\rvs=1\ar[rd]
&*++[F-o]{\sum \rvh}\ar[dr]
&\cald\rvx=x\ar[l]
\\
x\ar[r]
&\sum z\ar[r]
&y
}
\\
\color{red}
$=\sum_z P(y|\cald\rvx=x, z)P(z|x, \rvs=1)$
\\
$\xymatrix{\\=}\xymatrix{
\rvs=1\ar[rd]
&&\cald\rvx=x\ar[d]
\\
x\ar[r]
&\sum z\ar[r]
&y
}$
\end{longtable}
\qed

\begin{claim}
\decMediationSimple
\label{cl-decMediationSimple}
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvd=d,\cali\rvd=d')=
\sum_{m}
P(y|d,m)P(m|d')$
\\
\\
\xymatrix{
\cali\rvd=d'\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rr]
&&y}
\end{longtable}
\qed

\begin{claim}
\label{cl-decMediationPlus}
\decMediationPlus
\end{claim}
\proof
\begin{longtable}{l}
\color{red}
$P(y|\cald\rvd=d,\cali\rvd=d')=
\sum_{\xi, u}
\sum_{m}
P(y|d,m,\xi, u)P(m|d', \xi, u)
\underbrace{P(\xi|u)P(u)}_{P(\xi, u)}$
\\
\\
\xymatrix{
&&*++[F-o]{\sum u}\ar[ddr]
\ar[dl]\ar[d]
\\
\cali\rvd=d'\ar@/_1pc/[rr]
&\sum\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rrr]
&&&y}
\\
\color{red}
$=
\sum_{\xi}
\sum_{m}
P(y|d,m,\xi)P(m|d', \xi)
P(\xi)$
\\
\xymatrix{\\=}
\xymatrix{
\cali\rvd=d'\ar@/_1pc/[rr]
&\sum\xi\ar[rrd]\ar[r]
&\sum m\ar[rd]
\\
\cald\rvd=d\ar[rrr]
&&&y}
\begin{tabular}{l}
We switch from averaging over\\ the
prior of $\xi, u$\\
to averaging over the\\
prior of $\xi$.
\end{tabular}
\end{longtable}
\qed




%\input{do-calc-proofs/do-calc-proofs-limbo.tex}
