\chapter{Linear Deterministic Bnets 
with External 
Noise (LDEN Bnets)}\label{ch-LDEN}

A {\bf Linear Deterministic (LD) bnet} is a bnet with TPMs
of the form

\beq
\color{blue}
P(b|\{\rva_j=a_j\}_{\forall j})=
\indi\left(
b =\sum_{j}
g_j a_j\right)
\eeq
or, equivalently, with 
{\bf structural  equations}
of the form

\beq\color{blue}
\rvb =\sum_{j} g_j \rva_j
\quad\quad\quad
{\color{black}
\xymatrix{
\rva_1\ar[dr]|{g_1}
&\rva_2\ar[d]|{g_2}
&\rva_3\ar[dl]|{g_3}
\\
&\rvb
}}
\eeq
for every node $\rvb$
of the bnet,
where $\{\rva_j\}_{\forall j}$
are the parent nodes of $\rvb$,
and the {\bf gains} $g_j$
are real numbers.

In this chapter, we will consider 
bnets which were referred to,
prior to the invention of bnets, as:
Sewall Wright's {\bf Path Analysis (PA)}
 and
{\bf linear Structural Equations Models (SEM)}.
Judea Pearl in his
books calls them
{\bf linear Structural Causal Models (SCM)},
because they are very 
convenient for doing causal analysis.
We will refer  to
them as {\bf Linear  Deterministic with 
External Noise
 (LDEN) bnets}.
This chapter
is devoted to LDEN bnets,
except that we will
say a few words
about non-linear DEN
bnets at the end.


A {\bf DEN bnet}
is a special kind of bnet.
To 
build a DEN bnet,
start with a 
deterministic bnet $G$.
The deterministic
nodes of $G$ are called
the {\bf endogenous (internal) variables}.
Now make a bigger bnet $\ol{G}$
called a DEN bnet
by 
adding to each node $\rva$ of $G$ a
non-deterministic  
root node $\rvu_\rva$
pointing into $\rva$ only.
The nodes $\rvu_\rva$ are called
the {\bf exogenous (external) variables}.
The exogenous
variables make their children noisy.
They are assumed 
to be unobserved
and their TPMs are prior
probability distributions.
Since they are 
root nodes, they are 
mutually independent.
When we
draw
a DEN bnet,
we will sometimes
not draw the exogenous nodes,
leaving them implicit.

A {\bf linear DEN (LDEN) bnet} is 
a DEN bnet
whose deterministic nodes
have a TPM that is a linear 
function of the states
of the parent nodes.

This chapter 
uses the notation
$\av{\rvx, \rvy}$
for the
covariance
of any two random variables $\rvx, \rvy$.
This $\av{\rvx, \rvy}$ notation
is defined in Chapter \ref{ch-conventions}.


\section{Example
of LDEN bnet}


\begin{figure}[h!]
$$\xymatrix{
&\rvx\ar[dl]_\beta\ar[dr]^\alp
\\
\rvw\ar[dr]_\epsilon&&\rvz\ar[ll]_\gamma\ar[dl]^\delta
\\
&\rvy
}$$
\caption{
Example of a LDEN bnet wherein
$\rvx$ splits
into two nodes $\rvz$
and $\rvw$,
then merges into node $\rvy$.
There is also an arrow
$\rvz\rarrow \rvw$.
Exogenous
nodes are not shown.
The Greek letters
represent 
real numbers.
}
\label{fig-scm-diamond}
\end{figure}

The TPMs, printed in blue,
for the LDEN bnet
Fig.\ref{fig-scm-diamond},
are as follows.

\beq\color{blue}
P(y|w, z, u_\rvy)=
\indi(y=\epsilon w +\delta z
+ u_\rvy)
\eeq

\beq\color{blue}
P(w|x, z, u_\rvw)=
\indi(w=\beta x +\gamma z + u_\rvw)
\eeq

\beq\color{blue}
P(z|x, u_\rvz)=
\indi(z=\alpha x + u_\rvz)
\eeq

\beq\color{blue}
P(x|u_\rvx)=
\indi(x=u_\rvx)
\eeq

Hence,
\beqa
y&=&
\epsilon w +\delta z
+ u_\rvy
\\
&=&
\epsilon (\beta x +\gamma z + u_\rvw)
 +\delta z
+ u_\rvy
\\
&=&
(\epsilon\gamma + \delta)z
+ \epsilon\beta x
+\epsilon u_\rvw+ u_\rvy
\\
&=&
(\epsilon\gamma + \delta)z
+ \epsilon\beta u_\rvx
+\epsilon u_\rvw+ u_\rvy\;.
\eeqa
Therefore

\beq
\left(\pder{y}{z}\right)_{u.-u_\rvz}=
\epsilon\gamma + \delta
\;,
\eeq
where the
partial
derivative holds fixed
all
exogenous
variables except
$u_\rvz$.
Note that
this partial
derivative is a 
sum of terms,
and that each of those terms
represents a different
directed path
from $\rvz$ to $\rvy(\rvz)$.
This
is a general
property
of LDEN bnets.

\section{LDEN equations and their 2 solutions}


LDEN bnets are described by 
a system of linear equations 
(known as the {\bf structural equations}) of the form

\beq
\rvx_i = \sum_{j=0}^{nx-1} \alp_{i|j} 
\rvx_j + \rvu_i
\eeq
for $i=0, 1, \dots, nx-1$,
where the 
$\rvx_i$ are the internal nodes,
the $\alp_{i|j}$
are
the {\bf path coefficients} 
(a.k.a. {\bf arrow gains}), and the
$\rvu_i$ 
are the external nodes 
that inject noise into the system.
Some of the $\alp_{i|j}$ may
be zero,
in which case
the
corresponding arrow
$\rvx_j\rarrow \rvx_i$
would not be drawn.
The $\rvu_i$ are
root nodes with
zero covariance
with each other.

We can view this as either

\begin{enumerate}
\item UNK-CM (unknown covariance matrix) solution

a linear system 
of equations with the unknowns 
$\rvx_i$. We can solve for these
unknowns using basic Linear Algebra.
Once we solve for the unknowns,
we can calculate the covariances $\av{\rvx_j, \rvx_k}$.

\item UNK-G (unknown gains) solution

a linear system 
of equations with the
unknowns $\alp_{i|j}$. We can solve for these
unknowns using basic Linear Algebra.

\end{enumerate}

Next, we will find the 2
solutions UNK-CM and UNK-G 
explicitly for arbitrary LDEN
bnets.
We will present these solutions 
gradually, first for fully connected 
LDEN bnets, and then for the
general case that does not require
full connectivity.

\section{Fully connected 
LDEN bnets}
The bnets that will be
considered in this section
will all be fully connected.
Fully connected
bnets are
defined in Chapter \ref{ch-bnet-def}.

In this section, we will assume that
the nodes $\rvx_j$ are ordered topologically,
with the root nodes first.
This means that $\rvx_i$ happens after
$\rvx_j$ if $i>j$.
When the nodes are ordered topologically,
$\alp_{i|j}=0$ if $j\geq i$.

In the fully connected case, $\alp_{i|j}\neq 0$
for all $j<i$,
and for any node $\rvx_i$, all previous nodes
are parents of $\rvx_i$ and we draw arrows  
$\rvx_j\rarrow\rvx_i$ for $j=0, 1, \ldots, i-1$.

In the not
fully connected case,
some of the $\alp_{i|j}$ 
with $j<i$ are zero,
in which case
the
corresponding arrow
$\rvx_j\rarrow \rvx_i$
is not drawn.



\subsection{Fully connected 
LDEN bnet with $nx=2$}

\begin{figure}[h!]
$$
\xymatrix{
\rvx_0
\ar[d]^{\alp{1|0}}
\\
\rvx_1
}$$
\caption{
Fully connected 
LDEN bnet with two $\rvx_j$
nodes
(exogenous nodes $\rvu_j$
not shown).}
\label{fig-fully-conn-2}
\end{figure}

Consider the 
LDEN bnet of Fig.\ref{fig-fully-conn-2}.
This bnet represents the 
following structural equations:
\begin{subequations}
\label{eq-fully-conn-2}
\beqa
\rvx_0&=&\rvu_0
\\
\rvx_1&=&\alp_{1|0}\rvx_0  + \rvu_1
\;.
\eeqa
\end{subequations}

\begin{enumerate}
\item UNK-CM solution

Note that
\begin{subequations}
\beqa
\rvx_0 &=&\rvu_0
\\
\rvx_1 &=& \alp_{1|0}\rvu_0 + \rvu_1
\eeqa
\end{subequations}
Thus, the $\rvx_i$ can be 
expressed in terms of the $\rvu_i$.
Using the fact that $\av{\rvu_i,\rvu_j}=0$
for $i\neq j$, we get

\beq
\av{\rvx_0, \rvx_0}=\s^2_{\rvu_0}
\eeq

\beq
\av{\rvx_1, \rvx_0} =
\alp_{1|0}\s^2_{\rvu_0}
\eeq

\beq
\av{\rvx_1, \rvx_1}=
\alp^2_{1|0}\s^2_{\rvu_0}
+
\s^2_{\rvu_1}
\eeq



\item UNK-G solution

Note that

\beq
\av{\rvx_0, \rvu_1}=0
\eeq
because the path from $\rvx_0$ to 
$\rvu_1$ is blocked by a collider. 
Therefore,
\beq
\av{\rvx_0, \rvx_1}=
\alp_{1|0}\av{\rvx_0, \rvx_0}
\;
\eeq
so\footnote{We are using the notation 
$\pder{\rvb}{\rva}=
\frac{\av{\rva,\rvb}}{\av{\rva, \rva}}$,
for any two random variables $\rva,\rvb$}

\beq
\alp_{1|0}=\frac{\av{\rvx_0, \rvx_1}}
{\av{\rvx_0, \rvx_0}}=
\pder{\rvx_1}{\rvx_0}
\eeq
Thus, $\alp_{1|0}$
can be estimated  
from the covariances $\av{\rvx_i, \rvx_j}$.
\end{enumerate}

\subsection{Fully connected 
LDEN bnet with $nx=3$}

\begin{figure}[h!]
$$
\xymatrix{
\rvx_0\ar[d]_{\alp_{1|0}}
\ar[dr]^{\alp_{2|0}}
\\
\rvx_1\ar[r]_{\alp_{2|1}}
&\rvx_2
}$$
\caption{
Fully connected LDEN bnet with 
three $\rvx_j$ nodes
(exogenous nodes $\rvu_j$
not shown).}
\label{fig-fully-conn-3}
\end{figure}

Consider the LDEN bnet
of Fig.\ref{fig-fully-conn-3}.
This bnet represents the 
following structural equations:
\begin{subequations}
\label{eq-fully-conn-3}
\beqa
\rvx_0 &=& \rvu_0
\\
\rvx_1&=&\alp_{1|0}\rvx_0 + \rvu_1
\\
\rvx_2&=&\alp_{2|0}\rvx_0 +
\alp_{2|1}\rvx_1 +
\rvu_2
\;.
\eeqa
\end{subequations}

\begin{enumerate}
\item UNK-CM solution

Let
\beq
\rvx=
\left[
\begin{array}{c}
\rvx_0
\\
\rvx_1
\\
\rvx_2
\end{array}
\right]\;,
\quad
\rvu=
\left[
\begin{array}{c}
\rvu_0
\\
\rvu_1
\\
\rvu_2
\end{array}
\right]
\eeq
and

\beq
A=\left[
\begin{array}{ccc}
0&0&0
\\
\alp_{1|0}&0&0
\\
\alp_{2|0}&\alp_{2|1}&0
\end{array}
\right]
\eeq
Note that

\beq
\rvx = A\rvx + \rvu
\eeq
so

\beq
\rvx = (1-A)^{-1}\rvu
\eeq
Thus, the $\rvx_i$ can
be expressed in terms of the $\rvu_i$.

If we define the covariance matrix by


\beq
C= \av{\rvx,\rvx^T}\;,\quad C_{i,j}=
\av{\rvx_i, \rvx_j}
\eeq
then\footnote{We are using the notation
$diag(a)=$ diagonal matrix
with $a\in\RR^n$ along its diagonal.}
\beqa
C
&=&
(1-A)^{-1}\av{\rveps, \rveps^T}
[(1-A)^{-1}]^T
\\
&=&
(1-A)^{-1}diag(\s^2_{\rveps_i})
[(1-A)^{-1}]^T
\eeqa

If we define the Jacobian matrix $J$ by
\beq
J_{i,j}= \pder{\rvx_i}{\rvx_j}
\eeq
then

\beqa
J
&=&
C[diag(\av{\rvx_i, \rvx_i})]^{-1}
\\
&=&
(1-A)^{-1}diag(\s^2_{\rveps_i})
[(1-A)^{-1}]^T[diag(\av{\rvx_i, \rvx_i})]^{-1}
\eeqa

$C$ has the nice property that
it is a symmetric matrix, whereas
$J$ has the nice property
that its diagonal elements are all 1.

\item UNK-G solution

Note that
\begin{subequations}
\label{eq-fully-conn-3-covs}
\beqa
\av{\rvx_0, \rvx_1}&=&
\alp_{1|0}\av{\rvx_0, \rvx_0}
\\
\av{\rvx_0, \rvx_2}&=&
\alp_{2|0}\av{\rvx_0, \rvx_0}
+
\alp_{2|1}\av{\rvx_0, \rvx_1}
\\
\av{\rvx_1, \rvx_2}&=&
\alp_{2|0}\av{\rvx_1, \rvx_0}
+
\alp_{2|1}\av{\rvx_1, \rvx_1}
\eeqa
\end{subequations}
Hence
\beq
\alp_{1|0} = \frac{\av{\rvx_0, \rvx_1}}
{\av{\rvx_0, \rvx_0}}
=
\pder{\rvx_1}{\rvx_0}
\eeq

\beq
\left[
\begin{array}{c}
\av{\rvx_0, \rvx_2}
\\
\av{\rvx_1, \rvx_2}
\end{array}
\right]
=
\left[
\begin{array}{cc}
\av{\rvx_0, \rvx_0}
&
\av{\rvx_0, \rvx_1}
\\
\av{\rvx_1, \rvx_0}
&
\av{\rvx_1, \rvx_1}
\end{array}
\right]
\left[
\begin{array}{c}
\alp_{2|0}
\\
\alp_{2|1}
\end{array}
\right]
\eeq
Let

\beq
\alp^{(2)}=
\left[
\begin{array}{c}
\alp_{2|0}
\\
\alp_{2|1}
\end{array}\right]
\;,\quad
\rvx^{(2)}= \left[
\begin{array}{c}
\rvx_0
\\
\rvx_1
\end{array}
\right]
\;,\quad
\av{\rvx^{(2)},\rvx_2}
=\left[
\begin{array}{c}
\av{\rvx_0,\rvx_2}
\\
\av{\rvx_1,\rvx_2}
\end{array}
\right]
\eeq
Define the covariance matrix $C^{(2)}$
for the third row of $A$ by

\beq
C^{(2)}=
\left[
\begin{array}{cc}
\av{\rvx_0, \rvx_0}
&
\av{\rvx_0, \rvx_1}
\\
\av{\rvx_1, \rvx_0}
&
\av{\rvx_1, \rvx_1}
\end{array}
\right]
\eeq
Then

\beq
\av{ \rvx^{(2)},\rvx_2}=C^{(2)}\alp^{(2)}
\eeq
so


\beq
\alp^{(2)}=
[C^{(2)}]^{-1}\av{\rvx^{(2)},\rvx_2}
\eeq
Alternatively, let

\beq
\nabla^{(2)}\rvx_2=
\left[
\begin{array}{c}
\partial_{\rvx_0}\rvx_2
\\
\partial_{\rvx_1}\rvx_2
\end{array}
\right]
\eeq
Define the 
Jacobian matrix for the third row of $A$ by

\beq
J_{i,j}^{(2)}=\pder{\rvx_i}{\rvx_j}
\eeq
for $i,j\in\{0,1\}$.
Then

\beq
\nabla^{(2)}\rvx_2=
J^{(2)T}\alp^{(2)}
\eeq
so

\beq
\alp^{(2)}=
[J^{(2)T}]^{-1}\nabla^{(2)}\rvx_2
\eeq
From  the $C^{(r)}$ and the $J^{(r)}$ expressions for $r=1,2$,
we see that the $\alp_{i|j}$
can be expressed in terms of the
covariances $\av{\rvx_i, \rvx_j}$.

\end{enumerate}

\subsection{Fully
connected 
LDEN bnet with arbitrary $nx$} 

Let $\rvx.=(x_i)_{i=0, 1,
 \ldots, nx-1}$
and $\rvx_{<i}=
(x_k)_{k=0, 1, \ldots, i-1}$.
Consider
a fully connected
LDEN bnet
with  deterministic internal nodes labeled
$\rvx_i$.
The $\rvx_i$ labels 
are assumed
to be in  topological order
(i.e., the parents of
node $\rvx_i$ are $\rvx_{<i}$).
Let the TPMs,
printed in blue, for the nodes $\rvx.$
of the 
LDEN bnet, be
as follows.

\beq\color{blue}
P(x_i|x_{<i}, u_i)=
\indi(
x_i=\sum_{j<i}\alp_{i|j}x_j
 + u_i)
\;,
\label{eq-linear-pa-tpm}
\eeq
for some parameters $\alp_{i|j}\in \RR$.
The external 
nodes $\rvu.$  are assumed
to be independent so

\beq
P(u.)=\prod_i P(u_i)
\eeq
and

\beq
\av{\rvu_i, \rvu_j}=0
\text{  if $i\neq j$}
\;.
\eeq
Note that

\beqa
P(x.)&=&\sum_{u.}P(u.)
\prod_i P(x_i|x_{<i}, u_i)
\\
&=&
E_{\rvu.}[\prod_i P(x_i|x_{<i}, u_i)]
\;.
\eeqa


In terms of random variables,
this system
is described by the following 
structural equations:

\beq
\rvx_i=\sum_{j<i}\alp_{i|j}\rvx_j
 + \rvu_i
\;.
\eeq

\begin{enumerate}
\item UNK-CM solution

The structural equations can be
written in matrix form
as follows.
Define a strictly lower triangular
matrix $A$
with the arrow gains $\alp_{i|j}\in \RR$
as entries.
For example, for $nx=4$,

\beq
A=
\left[
\begin{array}{cccc}
0&0&0&0
\\
\alp_{1|0}&0&0&0
\\
\alp_{2|0}&\alp_{2|1}&0&0
\\
\alp_{3|0}&\alp_{3|1}&\alp_{3|2}&0
\end{array}\right]
\;.
\eeq
If we now represent the multinodes
$\rvx.$ and $\rvu.$ as column vectors
$\rvx$ and $\rvu$, we get

\beq
\rvx = A \rvx +\rvu
\label{eq-mat-fully-conn}
\;.
\eeq
Note that

\beq
\rvx=(1-A)^{-1}\rvu
\label{eq-x-one-minus-a-u}
\eeq
so the $\rvx_i$ can be expressed 
in terms of the $\rvu_i$. 

Just like we did for the
case $nx=3$, we can now
use Eq.(\ref{eq-x-one-minus-a-u}) to
express,
in terms of $A$ and the $\av{\rvu_i, \rvu_i}=
\s^2_{\rvu_i}$, the covariance
matrix $C=\av{\rvx, \rvx^T}$
and the Jacobian matrix 
$J$ with $J_{i,j}=\pder{\rvx_i}{\rvx_j}$.
. 

\item UNK-G solution

Note that

\beq
\rvx_i=f_i(\rvu_{\leq i})
\;.
\eeq
Therefore,
if $i>k$,

\beq
\av{\rvx_k,\rvu_i}
=\av{f_k(\rvu_{\leq k}),\rvu_i}=0
\;.
\eeq
Thus, if $i>k$, 

\beqa
\av{\rvx_k, \rvx_i}&=&
\sum_{j<i}\alp_{i|j}\av{\rvx_k, \rvx_j}
+
\av{\rvx_k, \rvu_i}
\\
&=&
\sum_{j<i}\alp_{i|j}\av{\rvx_k, \rvx_j}
\;.
\label{eq-alp-covs-gen}
\eeqa
As shown for the cases $nx=2, 3$
above,
Eqs.(\ref{eq-alp-covs-gen}) can be 
expressed as a system of equations
for each row of the matrix $A$,
and those systems of equations can be 
solved to express the $\alp_{i|j} $
in terms of the covariances $\av{\rvx_i, \rvx_j}$.

Dividing both sides of 
Eq.(\ref{eq-alp-covs-gen}) by $\av{\rvx_k, \rvx_k}$, we get, for $i>k$,
\beq
\pder{\rvx_i}{\rvx_k}=
\sum_{j<i}\alp_{i|j}\pder{\rvx_j}{\rvx_k}
\label{eq-alp-jacobian-gen}
\eeq


\end{enumerate}

\section{Not fully connected LDEN bnets}

When the LDEN bnet is not
fully connected, some $\alp_{i|j}$
might be zero for $i>j$, and the
corresponding arrow $\rvx_j\rarrow\rvx_i$
is not drawn. If that is the case,
the formulae that we gave above,
for the fully connected LDEN bnet,
for the UNK-CM solution, still apply,
but the formulae that we gave above, for the UNK-G solution,
must be modified as follows.

The problem with the previously
presented UNK-G solution is that,
when we solve for the $\alp_{i|j}$
in each row of $A$,
we are sometimes solving for $\alp_{i|j}$
which we know a priori are equal to zero.
So basically, we are solving a system of equations with more equations than unknowns,
what is called an \qt{overdetermined} system
of equations. A simple solution
to this quandary is to add to the set
of unknown variables $\alp_{i|j}$,
a few of the covariances too.
That way, we can get a system
of equations with the same number of
equations as number of unknowns.
So which of the covariances
should be made into unknowns?
A very natural choice
is to make the covariance $\av{\rvx_i, \rvx_j}$
an unknown if $\alp_{i|j}=0$
for some $i>j$.
This is what I do in Ref.\cite{scumpy},
and it works like a charm.
A fully connected LDEN bnet with $N$ nodes
has $N^2/2-N/2$ arrows. If $M$ of those are 
missing, our final result 
will be $M$ constraints among the 
covariances, and $N^2/2-N/2 - M$
equations expressing the non-zero $\alp_{i|j}$
in terms of covariances.


\section{LDEN bnet with conditioned nodes}

Conditioning on a node $\rvx$ 
of an LDEN bnet means assuming that $\rvx$  is
fixed at a specific value $x$.
Normally, we assume 

\beq
\av{\rveps_i, \rveps_j}=0
\quad\text{if $i\neq j$}
\label{eq-epsi-epsj}
\eeq
However, when we condition on some nodes $\{\rvx_i: i\in \calc\}$, the constraint
Eq.(\ref{eq-epsi-epsj}) must be modified. Instead, we assume

 \beq\av{\rveps_i, \rveps_j}=0
 \quad \text{if
 $i\in \calc$ or $j\in \calc$}.
 \eeq
 The reason this makes sense is as follows.
 The $\rveps_i$ for $i\in \calc$
 no longer serve a function because 
 they are futilely pumping noise into a fixed node,
 so we may set those $\rveps_i$ to a constant. 
 On the other hand,
 the  $\rveps_i$ with $i \not \in \calc$, might have become correlated among themselves
 as a result  of the conditioning.
 For example.
  we might have conditioned on a collider, and opened an unblocked path between two of those $\rveps_i$ with $i\neq \calc$. 
See Ref.\cite{scumpy}
for examples where this occurs.

\section{SCuMpy}
Check out my free open source
software SCuMpy \cite{scumpy}.
SCuMpy ia a Python library for doing both symbolic and numeric calculations for linear Structural Causal Models (SCM) (i.e., LDEN bnets).


\section{Non-linear DEN bnets}
This chapter 
is dedicated to
linear DEN bnets. This
implicitly
assumes that 
the deterministic
nodes $\rvx.$
of the 
DEN bnet have
an interval of
real values as their
possible states.
A trivial
but very useful
generalization
of linear DEN bnets is to
replace Eq.(\ref{eq-linear-pa-tpm})
for the TPMs
of the
deterministic nodes
of the bnet by

\beq\color{blue}
P(x_i|x_{<i}, u_i)=
\indi(
x_i=f_i(x_{<i}, u_i))
\;,
\label{eq-nonlinear-pa-tpm}
\eeq
with structural equations

\beq
\rvx_i=f_i(\rvx_{<i}, \rvu_i)
\;,
\label{eq-pa-nonlinear-struc}
\eeq
for $i=0, 1, \ldots, nx-1$.
Here the $f_i$ are 
possibly non-linear
functions
that depend on
the states
$x_{<i}$ and $u_i$
of nodes $\rvx_{<i}$
and $\rvu_i$.
If a node $\rvx_i$
has no arrows
entering it (i.e., is
a root node), then

\beq\color{blue}
P(x_i|x_{<i}, u_i)=P(x_i)=\delta(x_i, a)
\eeq
and

\beq
\rvx_i=a
\eeq
for some $a\in S_{\rvx_i}$.


Besides a linear function, the
$f_i()$
might equal a
continuous function
such as a polynomial,
or a discrete-valued Boolean
function
such as an OR gate.



