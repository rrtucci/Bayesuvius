\chapter{Noisy-OR gate}\label{ch-noisy-or}
The Noisy-OR gate was first
proposed by Judea Pearl in his 1988 book
 Ref.\cite{pearl-1988book}.
\begin{figure}[h!]
$$\xymatrix{
\rvx_0\ar@/_1pc/[ddrr]
&&\rvx_1\ar@/_1pc/[dd]
&&\rvx_2\ar@/_1pc/[ddll]
\\
&\ul{\pi}_0\ar[dr]
&\ul{\pi}_1\ar[d]
&\ul{\pi}_2\ar[dl]
\\
&\ul{\lam}\ar[r]
&\rvy
}$$
\caption{Noisy-OR gate $\rvy\in\bool$
with $n=3$, Boolean inputs $(\rvx_i)_{i=0,1,2}$
and parameters 
$\ul{\lam}, (\ul{\pi})_{i=0,1,2}$.
}
\label{fig-noisy-or-simple}
\end{figure}

Let

$\ul{\lam}\in [0, 1]=${\bf gate lea.k.a.ge}.

$y\in \bool$ = gate  output

$\rvx^n=(\rvx_i)_{i=0,1, \ldots, n-1}$, where
$\rvx_i\in\bool$ are
 gate inputs.

$\ul{\pi}^n=(\ul{\pi}_i)_{i=0,1, \ldots, n-1}$, where
$\ul{\pi}_i\in[0,1]$ are
 gate parameters.


The TPM, printed in blue,
 for the Noisy-OR gate $\rvy$ 
shown in Fig.\ref{fig-noisy-or-simple},
 is as follows.

\beq\color{blue}
P(y=1|x^n, \lam, \pi^n)=
1-(1-\lam)\prod_i[1-\pi_i x_i]
\label{eq-noisy-or-tmp-1}
\eeq
\beq\color{blue}
P(y=0|x^n, \lam, \pi^n)=
1-P(y=1|x^n, \lam, \pi^n)
\eeq

Note
that if $\lam=0$ and $\pi_i=1$ for all $i$,
then this becomes 
a deterministic OR-gate. Indeed,

\beq
P(y=1|x^n, \lam=0, \pi^n=1^n)= 1-\prod_i[1-x_i]=
\V_{i=0}^{n-1}x_i
\;,
\eeq
so 

\beq
P(y|x^n, \lam=0, \pi^n=1^n)=
\delta(y, \V_{i=0}^{n-1}x_i)
\;.
\eeq

\section{3 ways to interpret
the parameters $\pi_i$}
\begin{enumerate}
\item
Note that if $\lam=0$ and $x^n$ is one hot (i.e., 
$x^n=e^n_i$, where $e^n_i$
is the vector with all components 
zero except for the $i$-th
component which equals 1), then

\beq
P(y=1|x^n=e^n_i, \lam=0, \pi^n)=
1-[1-\pi_i]=\pi_i
\;.
\eeq
This gives an interpretation to the
parameters $\pi_i$.

\item

\begin{figure}[h!]
$$\xymatrix{
\rvh_0\ar[ddr]
&&\rvh_1\ar@/_1pc/[dd]
&&\rvh_2\ar[ddl]
\\
\rvx_0\ar[rd]
&&\rvx_1\ar[d]
&&\rvx_2\ar[ld]
\\
&\rvA_0\ar[dr]
&\rvA_1\ar[d]
&\rvA_2\ar[dl]
\\
&\ul{\lam}\ar[r]
&\rvy
}$$
\caption{Fig.\ref{fig-noisy-or-simple}
after replacing parameters 
$(\ul{\pi}_i)_{i=0,1,2}$
by 
hidden nodes
$(\rvh_i)_{i=0,1,2}$.}
\label{fig-noisy-or-hid}
\end{figure}


Another way of
interpreting the 
parameters $\pi_i$
is to associate 
each of them with a hidden 
variable
$\rvh_i\in \bool$
whose average equals $\pi_i$.
More precisely, 
consider Fig.\ref{fig-noisy-or-hid}.

Let $\rvx_i, \rvh_i, \rvA_i, \rvy\in \bool$.

The TPMs, printed  in blue, for the
bnet
Fig.\ref{fig-noisy-or-hid},
are as follows:

\beq\color{blue}
P(h_i)=\pi_i\delta(h_i,1)
+(1-\pi_i)\delta(h_i,0)
\eeq

\beq\color{blue}
P(A_i|h_i, x_i)= \delta(A_i, h_i\A x_i)
= \delta(A_i, h_i x_i)
\eeq

\beqa\color{blue}
P(y=1|A^n)&=& 
\color{blue}
1-(1-\lam)
 \A_{i=0}^{n-1}
\ol{A}_i
\\
&=&
\color{blue}
 1 - (1-\lam) \prod_i(1-A_i)
\eeqa

\beq\color{blue}
P(y=0|A^n)=1-P(y=1|A^n)
\eeq


Note that

\begin{align}
P(y=1|x^n, \lam)
&=
\sum_{h^n}
\sum_{A^n}
\left[
 1 - (1-\lam) 
\prod_i(1-A_i)\right]
[\prod_i \delta(A_i, h_i x_i)]P(h^n)
\\
&=
E_{\rvh^n}\left[
[ 1 - (1-\lam) \prod_i(1-h_i x_i)
\right]
\;.
\end{align}
But


\beq
E_{\rvh_i}[h_i x_i]=
\sum_{h_i=0,1} P(h_i)h_i x_i
=
\pi_i x_i
\eeq
so


\beq
P(y=1|x^n, \lam)=
1 - (1-\lam) \prod_i(1-\pi_i x_i)
\;.
\eeq



\item

\begin{figure}[h!]
$$\xymatrix{
\ul{\vech}_0\ar[ddr]
&&\ul{\vech}_1\ar@/_1pc/[dd]
&&\ul{\vech}_2\ar[ddl]
\\
\rvx_0\ar[rd]
&&\rvx_1\ar[d]
&&\rvx_2\ar[ld]
\\
&\rvA_0\ar[dr]
&\rvA_1\ar[d]
&\rvA_2\ar[dl]
\\
&\ul{\lam}\ar[r]
&\rvy
}$$
\caption{ Fig.\ref{fig-noisy-or-hid}
after replacing the hidden nodes 
$(\rvh_i)_{i=0,1,2}$
by 
vectors 
of samples $(\vec{\rvh}_i)_{i=0,1,2}$.}
\label{fig-noisy-or-sams}
\end{figure}

Another way to
interpret the 
parameters $\pi_i$
is to associate each of 
them with a vector of samples
$\vec{\rvh}_i$
whose average is $\pi_i$.
More precisely,
consider Fig.\ref{fig-noisy-or-sams}.

Suppose  $\rvh_i\in \bool$ and
define

\beq
P_{\rvh_i}(h_i)=
\pi_i\delta(h_i, 1)
+
(1-\pi_i)\delta(h_i, 0)
\;.
\eeq
Suppose $\vec{\rvh}_i=(\rvh_i[\sigma])_
{s=0, 1, \ldots, nsam-1}$ 
and  the 
Boolean samples $\rvh_i[\sigma]\in \bool$
 are i.i.d. with
$\rvh_i[\sigma]\sim P_{\rvh_i}$
for all $\sigma$.

Note that for each $i$,
an estimate 
$\HAT{P}_{\rvh_i}(h_i)$
of
$P_{\rvh_i}(h_i)$
can be 
obtained
from the vector of samples
$\vec{\rvh}_i$ 
as follows:


\beq
\HAT{P}_{\rvh_i}(h_i)=
\frac{1}{nsam}
\sum_{\sigma=0}^{nsam-1} \indi(h_i[\sigma]=h_i)
\;.
\eeq


Let $\rvx_i, \rvh_i[\sigma], \rvA_i, \rvy\in \bool$.

The TPMs, printed  in blue, for the
bnet
Fig.\ref{fig-noisy-or-sams},
are as follows:

\beq\color{blue}
P(\vech_i)=\prod_{\sigma=0}^{nsam-1}
P_\rvh(h_i[\sigma])
\eeq

\beqa\color{blue}
P(A_i\cond \vech_i, x_i)
&=&\color{blue}
\delta(A_i, \frac{1}{nsam}\sum_\sigma
 h_i[\sigma]\A x_i)
\\
&=&\color{blue}
\delta(A_i, 
 \pi_i x_i)
\eeqa

\beqa\color{blue}
P(y=1|A^n)&=& 
\color{blue}
1-(1-\lam)
 \A_{i=0}^{n-1}
\ol{A}_i
\\
&=&
\color{blue}
 1 - (1-\lam) \prod_i(1-A_i)
\eeqa

\beq\color{blue}
P(y=0|A^n)=1-P(y=1|A^n)
\eeq



Note that

\begin{align}
P(y=1|x^n, \lam, \vech^n)
&=
\sum_{A^n}
\left[
 1 - (1-\lam) \prod_i
(1-A_i)\right]\prod_i
\delta(A_i, \pi_i x_i)
\\
&=
1 - (1-\lam) \prod_i(1-\pi_i x_i)
\;.
\end{align}


\end{enumerate}