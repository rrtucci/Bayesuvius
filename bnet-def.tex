\section{Definition of a Bayesian Network}
\label{ch-bnet-def}

A {\bf directed graph} $G=(V,E)$
consists of two sets, $V$
and $E$. $V$ contains
the {\bf vertices (nodes)}
and $E$ contains the {\bf edges (arrows)}.
An arrow $a\rarrow b$ is an
ordered pair 
$(a,b)$ where $a, b\in V$.

The {\bf parents} 
of a node $x$ are 
those nodes $a$
such that there are arrows 
$a\rarrow x$.
The {\bf children} of a node
$x$
are those nodes $b$
such that there are arrows $x\rarrow b$.
A {\bf root node}
is a node with no parents.
A {\bf leaf node}
is a node with no children.
The {\bf neighbors}
of a node $x$
is the set of parents and 
children of $x$.

A {\bf path} is a 
set of nodes that 
are connected 
by arrows, so 
that all nodes
have 1 or 2 neighbors,
but only two nodes ({\bf open path})
or zero nodes ({\bf closed path})
have only one neighbor.
A {\bf directed path}
is a path in
which all the arrows point
in the same direction.
A {\bf loop}
is a closed path;i.e.,
a path in which all
nodes have exactly 2 neighbors.
A {\bf cycle} is a directed loop.
A {\bf Directed Acyclic Graph (DAG)}
is a directed graph that has no
cycles. 


A {\bf fully connected directed graph}
is 
a directed graph
in which 
every node has all other 
nodes as neighbors.
Figs.\ref{fig-full-conn-4-line}
and
\ref{fig-full-conn-4-square}
show 2 different
ways of drawing
the same directed graph,
a fully connected graph with 4 nodes.
Note that a convenient
way
to label
the nodes of a fully
connected directed
graph
with $N$ nodes
is to point
arrows
from 
$\rvx_k$ to $\rvx_j$
where $j=0, 1, 2,\ldots, N-1$
and 
$k=j-1, j-2, \ldots, 0$.


\begin{figure}[h!]
$$
\xymatrix{
\rvx_3
&\rvx_2\ar[l]
&\rvx_1\ar[l]\ar@/_1pc/[ll]
&\rvx_0\ar[l]\ar@/_2pc/[ll]\ar@/_2pc/[lll]
}
$$
\caption{Fully 
connected directed  graph with 4 nodes,
drawn as a line.}
\label{fig-full-conn-4-line}
\end{figure}

\begin{figure}[h!]
$$
\xymatrix{
\rvx_0\ar[r]\ar[d]\ar[rd]&\rvx_1\ar[d]\ar[ld]
\\
\rvx_2\ar[r]&\rvx_3
}
$$
\caption{Fully 
connected directed  graph with 4 nodes,
drawn as a square.}
\label{fig-full-conn-4-square}
\end{figure}

A {\bf connected graph}
is a graph for which there
is no way of separating
the nodes into
two sets so that there is no arrow 
from one set to the other.
A {\bf tree}
is a directed graph
in which all nodes
have a single parent
except for a single 
node called the ``root" node
which has no parents.
A {\bf polytree}
is a DAG with
no loops.





\hrule

A {\bf Bayesian network (bnet)}
consists of a DAG 
and a 
{\bf Transition 
Probability Matrix (TPM)}
associated 
with each node
of the graph.
A TPM is often 
called a {\bf Conditional Probability
Table 
(CPT)}.
The {\bf structure} of a bnet
is its DAG alone, sans the TPMs.
The 
{\bf skeleton} of a bnet is the
undirected graph beneath the bnet's
DAG.



In 
this book,
random  variables are
 indicated by 
underlined letters and their values 
by non-underlined letters.
 Each node of a bnet is
 labelled by a random variable.
 Thus, $\rvx=x$ means that node 
$\rvx$ is in state $x$.


\hrule\noindent
{\bf Some sets of nodes 
associated 
with each node $\rva$
of a bnet}
\begin{itemize}
\item
$ch(\rva)=$ children of $\rva$.
\item
$pa(\rva)=$ parents of $\rva$.
\item
$nb(\rva)=pa(\rva)\cup ch(\rva)=$ 
neighbors of $\rva$.
\item
$de(\rva)=\cup_{n=1}^{\infty}ch^n(\rva)=$
$ch(\rva)\cup ch\circ ch(\rva)\cup\ldots$, 
descendants of $\rva$. 
\item
$an(\rva)=\cup_{n=1}^{\infty}pa^n(\rva)=$
$pa(\rva)\cup pa\circ pa(\rva)\cup\ldots$, 
ancestors of $\rva$.
\end{itemize}
\hrule
In this book,
we will use 
$\rva.$
to indicate
a {\bf multi-node (node set,
node array)} $\rva.=
(\rva_j)_{j=0, 1, \ldots , na-1}$.
We will often
treat multinodes as if
they were sets, and
combine them with
the usual
set
operators.
For instance,
for two
multinodes $\rva.$
and $\rvb.$,
we define
$\rva.\cup\rvb.$,
$\rva.\cap\rvb.$,
$\rva.-\rvb.$
and
$\rva.\subset\rvb.$
in the obvious way.
We 
will indicate
a singleton set (single
node multi-node) $\rva.=\{\rva\}$
simply by $\rva.=\rva$.
For instance,
$\rva.-\rvb=\rva.-\{\rvb\}$.
\hrule

The TPM of a node
$\rvx$ of a bnet
is a matrix of
probabilities 
$P(\rvx=x|pa(\rvx)=a.)$.

A bnet
with nodes $\rvx.$
represents
a probability
distribution

\beq
P(x.)=
\prod_j
P(\rvx_j=x_j|
(\rvx_k=x_k)_{k: \rvx_k\in pa(\rvx_j)})
\;.
\label{eq-chain-rule-bnet}
\eeq

Note that
for a fully connected bnet
with $N$ nodes,
Eq.(\ref{eq-chain-rule-bnet})
becomes

\beq
P(x.)=
\prod_{j=0}^{N-1}
P(x_j| 
(x_k)_{k=j-1, j-2, \ldots, 0})
\;.
\label{eq-chain-rule-cond-probs}
\eeq
For example, if $N=4$,
Eq.(\ref{eq-chain-rule-cond-probs})
 becomes

\beq
P(x_0, x_1,x_2, x_3)=
P(x_3|x_2, x_1, x_0)
P(x_2|x_1, x_0)
P(x_1|x_0)
P(x_0)
\;.
\eeq
We see that 
Eq.(\ref{eq-chain-rule-cond-probs})
is just the chain rule for 
conditional probabilities.

\hrule
Given an arbitrarily
 large dataset of samples for 
the random variables 
$(\rvx_i)_{i=0, 1, \ldots, N-1}$,
there may be
several bnets (differing
perhaps in the direction
of some arrows) that
fit the data well. However, 
according to Pearl's causality theory, 
only one of these bnets is used
by Nature.
I like to refer to that
single one as the
{\bf  causally correct (CC) 
Bayesian network}.\footnote{
The uniqueness of a CC bnet can be taken to be
an implicit axiom of causality theory. Alternatively,
instead of assuming uniqueness,
one can assume that out 
of all possible CC bnets for
an experiment,
one can find the ``best"
one. Here the definition
of ``best" is not unique and depends on a 
non-unique
figure of merit defined in terms
of Pearl do interventions.} 
In this book,
whenever we speak 
of
causal issues,
we will assume, often
without mentioning it,
that the CC
bnet is being used.\footnote{We 
won't use the term ``causal bnet" in this
book. Pearl defines a causal bnet to be
a CC bnet that is also a ``SCM" (i.e., 
a bnet whose internal nodes are
deterministic and external ones are 
probabilistic.)}



